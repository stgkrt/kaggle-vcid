{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 1d-ex000"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:41.388632Z","iopub.status.busy":"2023-04-11T00:41:41.388166Z","iopub.status.idle":"2023-04-11T00:41:43.938183Z","shell.execute_reply":"2023-04-11T00:41:43.937024Z","shell.execute_reply.started":"2023-04-11T00:41:41.388578Z"},"trusted":true},"outputs":[],"source":["import gc\n","import os\n","import random\n","import time\n","import math\n","\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# model\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import timm\n","from torchvision.models.feature_extraction import create_feature_extractor\n","import torchvision.transforms.functional as TF\n","\n","# data loader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from torch.utils.data import DataLoader, Dataset\n","\n","# training\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau, ExponentialLR, CyclicLR\n","\n","# metric\n","from sklearn.metrics import fbeta_score, roc_auc_score\n","\n","import wandb\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:43.940925Z","iopub.status.busy":"2023-04-11T00:41:43.940483Z","iopub.status.idle":"2023-04-11T00:41:43.958735Z","shell.execute_reply":"2023-04-11T00:41:43.957018Z","shell.execute_reply.started":"2023-04-11T00:41:43.94088Z"},"trusted":true},"outputs":[],"source":["BASE_DIR = \"/working/\"\n","INPUT_DIR = os.path.join(BASE_DIR, \"input\", \"vesuvius-challenge-ink-detection\")\n","EXP_NAME = \"exp000\"\n","CFG = dict(\n","    DEBUG=True,\n","    \n","    # exp setting\n","    EXP_CATEGORY=\"1d\",\n","    EXP_NAME=EXP_NAME,\n","   \n","    # model\n","    img_size = [128, 128],\n","    \n","    # data\n","    SURFACE_LIST = [list(range(10, 50, 1))],\n","    \n","    # directory\n","    TRAIN_DIR = os.path.join(INPUT_DIR, \"train\"),\n","    OUTPUT_DIR = os.path.join(BASE_DIR, \"output\", EXP_NAME),\n","    \n","    TRAIN_DIR_LIST = [[\"1\", \"2_0\", \"2_1\", \"2_2\"], \n","                       [\"1\", \"2_0\", \"2_1\", \"3\"],\n","                       [\"1\", \"2_0\",  \"2_2\", \"3\"],\n","                       [\"1\", \"2_1\", \"2_2\", \"3\"],\n","                       [\"2_0\", \"2_1\", \"2_2\", \"3\"],\n","                       ],\n","    VALID_DIR_LIST = [[\"3\"], [\"2_2\"], [\"2_1\"], [\"2_0\"],[\"1\"]],\n","    \n","    \n","    random_seed=42, \n",")\n","if CFG[\"DEBUG\"]:\n","    CFG[\"OUTPUT_DIR\"] = os.path.join(BASE_DIR, \"output\", \"debug\")\n","    CFG[\"SURFACE_LIST\"] = [list(range(25, 45, 1))]\n","print(CFG)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not CFG[\"DEBUG\"]:\n","    os.makedirs(CFG[\"OUTPUT_DIR\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def init_logger(log_file=os.path.join(CFG[\"OUTPUT_DIR\"], 'train.log')):\n","    \"\"\"Output Log.\"\"\"\n","    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","LOGGER = init_logger()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not CFG[\"DEBUG\"]:\n","    WANDB_CONFIG = {'competition': 'vcid', '_wandb_kernel': 'taro'}\n","    os.environ[\"WANDB_SILENT\"] = \"true\"\n","    wandb.init(project=WANDB_CONFIG[\"competition\"], config=CFG, group=CFG[\"EXP_CATEGORY\"], name=CFG[\"EXP_NAME\"], reinit=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def logging_metrics_epoch(CFG, fold, epoch, slice_idx,train_loss_avg, valid_loss_avg, score, threshold, auc_score):\n","    wandb.log({f\"train/fold{fold}\": train_loss_avg,\n","                f\"valid/fold{fold}\": valid_loss_avg,\n","                f\"score/fold{fold}\":score,\n","                f\"score threshold/fold{fold}\":threshold,\n","                f\"auc/fold{fold}\":auc_score,\n","                f\"epoch/fold{fold}\":epoch+slice_idx*CFG[\"n_epoch\"],\n","                })\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:43.962726Z","iopub.status.busy":"2023-04-11T00:41:43.962423Z","iopub.status.idle":"2023-04-11T00:41:43.996799Z","shell.execute_reply":"2023-04-11T00:41:43.995583Z","shell.execute_reply.started":"2023-04-11T00:41:43.962698Z"},"trusted":true},"outputs":[],"source":["def seed_everything(seed=CFG[\"random_seed\"]):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.000826Z","iopub.status.busy":"2023-04-11T00:41:44.000079Z","iopub.status.idle":"2023-04-11T00:41:44.010016Z","shell.execute_reply":"2023-04-11T00:41:44.009127Z","shell.execute_reply.started":"2023-04-11T00:41:44.000749Z"},"trusted":true},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# metric"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.012555Z","iopub.status.busy":"2023-04-11T00:41:44.011593Z","iopub.status.idle":"2023-04-11T00:41:44.023483Z","shell.execute_reply":"2023-04-11T00:41:44.022677Z","shell.execute_reply.started":"2023-04-11T00:41:44.012515Z"},"trusted":true},"outputs":[],"source":["def fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n","    y_true_count = targets.sum()\n","    ctp = preds[targets==1].sum()\n","    cfp = preds[targets==0].sum()\n","    beta_squared = beta * beta\n","\n","    c_precision = ctp / (ctp + cfp + smooth)\n","    c_recall = ctp / (y_true_count + smooth)\n","    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n","\n","    return dice\n","\n","def calc_fbeta_auc(mask, mask_pred):\n","    mask = mask.astype(int).flatten()\n","    mask_pred = mask_pred.flatten()\n","\n","    best_th = 0\n","    best_dice = 0\n","    dice_list = [] \n","    # for th in np.array(range(10, 50+1, 5)) / 100:\n","    for th in np.array(range(10, 100+1, 5)) / 100:\n","        # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n","        dice = fbeta_numpy(mask, (mask_pred >= th).astype(int), beta=0.5)\n","        dice_list.append(dice)\n","        # print(f'\\t th: {th}, fbeta: {dice}')\n","        if dice > best_dice:\n","            best_dice = dice\n","            best_th = th\n","    \n","    auc = roc_auc_score(mask, mask_pred)\n","    # Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n","    return best_dice, best_th, auc, dice_list\n","\n","\n","def calc_cv(mask_gt, mask_pred):\n","    best_dice, best_th, auc, dice_list = calc_fbeta_auc(mask_gt, mask_pred)\n","\n","    return best_dice, best_th, auc, dice_list"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class VCID_1DNet(nn.Module):\n","    def __init__(self, CFG_):\n","        super().__init__()\n","        channel = CFG_[\"img_size\"][0]*CFG_[\"img_size\"][1]\n","        # data_length = len(CFG_[\"SURFACE_LIST\"][0])\n","        hdn = 32\n","        self.conv1 = nn.Conv1d(channel, hdn, kernel_size=13, stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm1d(hdn)\n","        self.do1 = nn.Dropout(0.2)\n","        self.conv2 = nn.Conv1d(hdn, hdn*2, kernel_size=7, stride=1, padding=1)\n","        self.bn2 = nn.BatchNorm1d(hdn*2)\n","        self.do2 = nn.Dropout(0.2)\n","        self.conv3 = nn.Conv1d(hdn*2, hdn*2, kernel_size=5, stride=1, padding=1)\n","        self.bn3 = nn.BatchNorm1d(hdn*2)\n","        self.do3 = nn.Dropout(0.2)\n","        self.conv4 = nn.Conv1d(hdn*2, hdn*2, kernel_size=3, stride=1, padding=1)\n","        self.bn4 = nn.BatchNorm1d(hdn*2)\n","        self.do4 = nn.Dropout(0.2)\n","        self.fc = nn.Linear(hdn*2, channel)\n","        \n","    def forward(self, x):\n","        x = self.do1(F.relu(self.bn1(self.conv1(x))))\n","        x = self.do2(F.relu(self.bn2(self.conv2(x))))\n","        x = self.do3(F.relu(self.bn3(self.conv3(x))))\n","        x = self.do4(F.relu(self.bn4(self.conv4(x))))\n","        x = F.adaptive_avg_pool1d(x, 1).reshape(x.shape[0], -1)\n","        x = self.fc(x)\n","        return x\n"," "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## model check"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_channel = CFG[\"img_size\"][0]*CFG[\"img_size\"][1]\n","x = torch.randn(1, input_channel, len(CFG[\"SURFACE_LIST\"][0]))\n","print(x.shape)\n","model = VCID_1DNet(CFG)\n","output = model(x)\n","print(output.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class VCID_Dataset(Dataset):\n","    def __init__(self, CFG, data_dir_list, surface_list, surface_volumes=None, mode=\"train\", transform=None):\n","        # get config\n","        self.mode = mode\n","        self.img_size = CFG[\"img_size\"]\n","        if self.mode==\"train\":  self.DATADIR = CFG[\"TRAIN_DIR\"]\n","        elif self.mode==\"valid\":    self.DATADIR = CFG[\"TRAIN_DIR\"]\n","        elif self.mode == \"test\":   self.DATADIR = CFG[\"TEST_DIR\"]\n","        self.data_dir_list = data_dir_list\n","        self.surface_list = surface_list\n","        self.transform = transform\n","        \n","        # get imgs\n","        print(\"initializing dataset...\")\n","        self.imgs = []\n","        for data_dir in self.data_dir_list:\n","            img_path = os.path.join(self.DATADIR, data_dir, \"mask.png\")\n","            # print(img_path)\n","            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","            img = img.reshape(img.shape[0], img.shape[1], 1) # (h, w, channel=1)\n","            assert img is not None, \"img is None. data path is wrong\"\n","            self.imgs.append(img)  \n","        \n","        # get and split surface\n","        if surface_volumes is None:\n","            self.surface_vols = self.read_surfacevols()\n","            print(\"read surface_vols done.\")\n","        else:\n","            print(\"using loaded surface_vols\")\n","            self.surface_vols = surface_volumes\n","       \n","        # split grid\n","        print(\"splitting grid...\")\n","        self.get_all_grid()\n","        print(\"get all grid done.\")\n","        self.fileter_grid()\n","        print(\"filter grid done.\")\n","        self.get_flatten_grid()\n","        print(\"get flatten grid done.\")\n","        print(\"split grid done.\") \n","       \n","        # get label imgs\n","        if self.mode == \"train\" or self.mode == \"valid\":\n","            self.labels = []\n","            for data_dir in self.data_dir_list:\n","                label_path = os.path.join(self.DATADIR, data_dir, \"inklabels.png\")\n","                assert os.path.exists(label_path), f\"{label_path} is not exist.\"\n","                # read label\n","                label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n","                label = label.reshape(label.shape[0], label.shape[1], 1) # (h, w, channel=1)\n","                self.labels.append(label)# 画像サイズがそれぞれ違うので単純にconcatできずlist化しているs\n","        print(\"initializing dataset done.\")\n","\n","    def get_surface_volumes(self):\n","        return self.surface_vols\n","\n","    def read_surfacevols(self):\n","        \"\"\" read surface volume by data_dir_list and surface_list \n","            Returns:surface_vuls (list): surface volume list [array(h,w,channel=surface_num), array(), ...]\n","        \"\"\"\n","        surface_vols = []\n","        print(\"reading surface volume...\")\n","        for data_dir in self.data_dir_list:\n","            surface_vol_ = None\n","            for read_idx, surface_idx in enumerate(self.surface_list):\n","                print(\"\\r\", f\"reading idx : {read_idx+1}/{len(self.surface_list)}\", end=\"\")\n","                surface_path = os.path.join(self.DATADIR, data_dir, \"surface_volume\", f\"{surface_idx:02}.tif\")\n","                surface_vol = cv2.imread(surface_path, cv2.IMREAD_GRAYSCALE)\n","                surface_vol = surface_vol.reshape(surface_vol.shape[0], surface_vol.shape[1], 1) # (h, w, channel=1)\n","                if surface_vol_ is None:\n","                    surface_vol_ = surface_vol\n","                else:\n","                    surface_vol_ = np.concatenate([surface_vol_, surface_vol], axis=2) # (h, w, channel=surface_num)\n","            surface_vols.append(surface_vol_)\n","            print(f\"  => read surface volume done. [{data_dir}]\")\n","        return surface_vols\n","\n","    def get_grid_img(self, img, grid_idx):\n","        \"\"\" crop grid img from original img\"\"\"\n","        img_grid = img[grid_idx[0]*self.img_size[0] : (grid_idx[0]+1)*self.img_size[0],\n","                        grid_idx[1]*self.img_size[1] : (grid_idx[1]+1)*self.img_size[1]]\n","        return img_grid\n","    \n","    def get_grid_img_and_mask(self, img, mask, grid_idx):\n","        \"\"\" crop grid img from original img\"\"\"\n","        img_grid = img[grid_idx[0]*self.img_size[0] : (grid_idx[0]+1)*self.img_size[0],\n","                        grid_idx[1]*self.img_size[1] : (grid_idx[1]+1)*self.img_size[1]]\n","        mask_grid = mask[grid_idx[0]*self.img_size[0] : (grid_idx[0]+1)*self.img_size[0],\n","                         grid_idx[1]*self.img_size[1] : (grid_idx[1]+1)*self.img_size[1]]\n","        return img_grid/255., mask_grid/255.\n","    \n","    def get_all_grid(self):\n","        \"\"\" get all grid indices by img size and grid size\n","        \"\"\"\n","        self.grid_indices = []\n","        for img in self.imgs:\n","            self.x_grid_size = img.shape[0] // self.img_size[0]\n","            self.y_grid_size = img.shape[1] // self.img_size[1]\n","            grid_img = []\n","            for i in range(self.x_grid_size):\n","                for j in range(self.y_grid_size):\n","                    grid_img.append([i, j])\n","            self.grid_indices.append(grid_img)\n","        return self.grid_indices\n","          \n","    def fileter_grid(self):\n","        \"\"\" get grid indices which mask is not 0 by all grid indices\"\"\"\n","        grid_indices_all = []\n","        for img, grid_indices in zip(self.imgs, self.grid_indices):\n","            grid_indices_copy = grid_indices.copy()\n","            for grid_idx in grid_indices:\n","                img_grid = self.get_grid_img(img, grid_idx)\n","                if img_grid.sum() == 0:\n","                    grid_indices_copy.remove(grid_idx)\n","            grid_indices_all.append(grid_indices_copy)\n","        self.grid_indices = grid_indices_all\n","        return self.grid_indices\n","\n","    def get_flatten_grid(self):\n","        \"\"\" get flatten index list by grid indices\n","            Returns:flatten_grid (list): flatten index list [[img_idx, grid_idx], [img_idx, grid_idx], ...]\n","        \"\"\"\n","        flatten_grid = []\n","        for img_idx, grid_indices in enumerate(self.grid_indices):\n","            for grid_idx in grid_indices:\n","                grid_imgidx_list = [img_idx]\n","                grid_imgidx_list.extend(grid_idx)\n","                flatten_grid.append(grid_imgidx_list)\n","        self.flatten_grid = flatten_grid\n","        return self.flatten_grid\n","   \n","    def get_flatten_img(self, img):\n","        \"\"\" get flatten img and mask by flatten_grid\n","            Returns:flatten_img (array): flatten img array(h*w, channel=surface_num)\n","                    flatten_mask (array): flatten mask array(h*w, channel=1)\n","        \"\"\"\n","        flatten_img = img.reshape(img.shape[0]*img.shape[1], img.shape[2])\n","        return flatten_img\n","    \n","    def __len__(self):\n","        return len(self.flatten_grid)\n","\n","    def __getitem__(self, idx):\n","        # get indices\n","        img_grid_idx = self.flatten_grid[idx]\n","        img_idx = img_grid_idx[0]\n","        grid_idx = img_grid_idx[1:]\n","        # get img & surface_vol\n","        mask = self.imgs[img_idx]\n","        surface_vol = self.surface_vols[img_idx]\n","        mask, surface_vol = self.get_grid_img_and_mask(mask, surface_vol, grid_idx)\n","        # multiple small mask \n","        assert surface_vol.shape[0]==mask.shape[0] and surface_vol.shape[1]==mask.shape[1] , \"surface_vol_list shape is not same as img shape\"\n","        img = surface_vol\n","        img = self.get_flatten_img(img)\n","        img = torch.tensor(img, dtype=torch.float32)\n","        if self.mode == \"train\" or self.mode == \"valid\":\n","            mask = self.get_flatten_img(mask)\n","            mask = torch.tensor(mask, dtype=torch.float32)\n","            return img, mask, grid_idx\n","        else:\n","            return img, grid_idx       "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.115468Z","iopub.status.busy":"2023-04-11T00:41:44.115176Z","iopub.status.idle":"2023-04-11T00:41:44.124975Z","shell.execute_reply":"2023-04-11T00:41:44.123696Z","shell.execute_reply.started":"2023-04-11T00:41:44.115434Z"},"trusted":true},"outputs":[],"source":["# valid_dirs = CFG[\"VALID_DIR_LIST\"][0]\n","# surface_list = CFG[\"SURFACE_LIST\"][0]\n","# print(\"dataset\")\n","# dataset_notrans = VCID_Dataset(CFG, valid_dirs, surface_list, mode=\"train\")\n","# surface_volumes = dataset_notrans.surface_vols\n","# print(\"dataloader\")\n","# dataloader_notrans = DataLoader(dataset_notrans, 4, shuffle=False, num_workers=0)\n","\n","# for batch_idx, (imgs, labels, grid_idx) in enumerate(dataloader_notrans):\n","#     print(imgs.shape)\n","#     print(labels.shape) \n","#     break\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# train valid fn"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.151325Z","iopub.status.busy":"2023-04-11T00:41:44.150944Z","iopub.status.idle":"2023-04-11T00:41:44.163092Z","shell.execute_reply":"2023-04-11T00:41:44.161981Z","shell.execute_reply.started":"2023-04-11T00:41:44.151287Z"},"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets, _) in enumerate(train_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float()     \n","        preds = model(images)\n","        assert preds is not None, f\"preds is None, {preds}, {images}, {targets}\"\n","        loss = criterion(preds, targets)\n","        preds = torch.sigmoid(preds)\n","        assert loss is not None, f\"loss is None, {loss}, {preds}, {targets}\"\n","        losses.update(loss.item(), CFG[\"batch_size\"]) \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = preds.detach().cpu().numpy().ravel().tolist()\n","        loss.backward() # パラメータの勾配を計算\n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        del preds, images, targets\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.165502Z","iopub.status.busy":"2023-04-11T00:41:44.164813Z","iopub.status.idle":"2023-04-11T00:41:44.178372Z","shell.execute_reply":"2023-04-11T00:41:44.177351Z","shell.execute_reply.started":"2023-04-11T00:41:44.16546Z"},"trusted":true},"outputs":[],"source":["def valid_fn(model, valid_loader, criterion=None):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","    test_grid_idx = []\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets, grid_idx) in enumerate(valid_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float()\n","        with torch.no_grad():\n","            preds = model(images)\n","            assert preds is not None, f\"preds is None, {preds}, {images}, {targets}\"\n","            if not criterion is None:\n","                loss = criterion(preds, targets)\n","                assert loss is not None, f\"loss is None, {loss}, {preds}, {targets}\"\n","            preds = torch.sigmoid(preds)\n","        if not criterion is None:\n","            losses.update(loss.item(), CFG[\"batch_size\"])\n","        batch_time.update(time.time() - end)\n","\n","        targets = targets.detach().cpu().numpy()\n","        preds = preds.detach().cpu().numpy()\n","        \n","        preds = preds.reshape(CFG[\"img_size\"][0], CFG[\"img_size\"][1], 1)\n","        targets = targets.reshape(CFG[\"img_size\"][0], CFG[\"img_size\"][1], 1)\n","        \n","        test_preds.extend([preds[idx, :,:,:].transpose(1,2,0) for idx in range(preds.shape[0])])\n","        test_targets.extend([targets[idx, :,:,:].transpose(1,2,0) for idx in range(targets.shape[0])])\n","        test_grid_idx.extend([[x_idx, y_idx] for x_idx, y_idx in zip(grid_idx[0].tolist(), grid_idx[1].tolist())])\n","\n","        if (batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(valid_loader)-1)) and (not criterion is None):\n","            print('EVAL: [{0}/{1}] '\n","                'Elapsed {remain:s} '\n","                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                .format(\n","                    batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                    remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                ))\n","        del preds, images, targets\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    if criterion is None:\n","        return test_targets, test_preds, test_grid_idx\n","    else:\n","        return test_targets, test_preds, test_grid_idx, losses.avg"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# training loop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def concat_grid_img(img_list, label_list, grid_idx_list, valid_dir_list, slide_pos=[0,0]):\n","    # concat pred img and label to original size\n","    img_path = os.path.join(CFG[\"TRAIN_DIR\"], valid_dir_list[0], \"mask.png\")\n","    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","    img = img.reshape(img.shape[0], img.shape[1], 1)\n","    pred_img = np.zeros_like(img).astype(np.float32)\n","    label_img = np.zeros_like(img).astype(np.float32)\n","    for img_idx, grid_idx in enumerate(grid_idx_list):\n","        pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","                grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += img_list[img_idx]\n","        \n","        label_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","                grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += label_list[img_idx]\n","    return pred_img, label_img"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def save_and_plot_oof(mode, fold, slice_idx, valid_preds_img, valid_targets_img, valid_preds_binary):\n","    cv2.imwrite(os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\", f\"fold{fold}_{mode}_slice{slice_idx}_valid_pred_img.png\"), valid_preds_img*255)\n","    cv2.imwrite(os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\", f\"fold{fold}_{mode}_slice{slice_idx}_valid_predbin_img.png\"), valid_preds_binary*255)\n","    cv2.imwrite(os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\", f\"fold{fold}_{mode}_slice{slice_idx}_valid_targets_img.png\"), valid_targets_img*255)\n","    \n","    # plot preds & binary preds\n","    # plt.figure(dpi=100)\n","    # plt.subplot(1,3,1)\n","    # plt.imshow(valid_preds_img)\n","    # plt.subplot(1,3,2)\n","    # plt.imshow(valid_preds_binary)\n","    # plt.subplot(1,3,3)\n","    # plt.imshow(valid_targets_img)\n","    # plt.show()\n","                "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.193974Z","iopub.status.busy":"2023-04-11T00:41:44.193163Z","iopub.status.idle":"2023-04-11T00:41:44.213205Z","shell.execute_reply":"2023-04-11T00:41:44.212125Z","shell.execute_reply.started":"2023-04-11T00:41:44.193933Z"},"trusted":true},"outputs":[],"source":["def training_loop(CFG):\n","    best_score_list = []\n","    best_threshold_list = []\n","    best_epoch_list = []\n","    slice_ave_score_list = []\n","    slice_ave_auc_list = []\n","    slice_ave_score_threshold_list = []\n","    for fold in CFG[\"folds\"]:\n","        print(f\"-- fold{fold} training start --\")\n"," \n","        # set model & learning fn\n","        model = VCID_1DNet(CFG)\n","        model = model.to(device)\n","        valid_img_slice = []\n","        # criterion = nn.BCELoss()\n","        # criterion = ComboLoss()\n","        weights = torch.tensor([0.3]).cuda()\n","        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=weights)\n","        optimizer = AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"], amsgrad=False)\n","        scheduler = CosineAnnealingLR(optimizer, T_max=CFG[\"T_max\"], eta_min=CFG[\"min_lr\"], last_epoch=-1)\n","        # scheduler = ExponentialLR(optimizer, gamma=0.60)\n","        scheduler = CyclicLR(optimizer, base_lr=CFG[\"base_lr\"], max_lr=CFG[\"max_lr\"],\n","                            step_size_up=CFG[\"step_size_up\"], step_size_down=CFG[\"step_size_down\"], \n","                            cycle_momentum=False, mode='triangular2')\n","        \n","        # training\n","        best_score = -np.inf\n","        best_auc = -np.inf\n","        best_valloss = np.inf\n","        best_auc_valloss = np.inf\n","        best_threshold = -1\n","        start_time = time.time()\n","        best_epoch = -1\n","        best_auc_epoch = -1\n","        valid_slice_ave = None       \n","        # separate train/valid data \n","        train_dirs = CFG[\"TRAIN_DIR_LIST\"][fold]\n","        valid_dirs = CFG[\"VALID_DIR_LIST\"][fold]\n","        train_dataset = VCID_Dataset(CFG, train_dirs, surface_list, mode=\"train\")\n","        valid_dataset = VCID_Dataset(CFG, valid_dirs, surface_list, mode=\"valid\")\n","        train_loader = DataLoader(train_dataset, batch_size=CFG[\"batch_size\"], shuffle = True,\n","                                    num_workers = CFG[\"num_workers\"], pin_memory = True)\n","        valid_loader = DataLoader(valid_dataset, batch_size=CFG[\"batch_size\"], shuffle = False,\n","                                    num_workers = CFG[\"num_workers\"], pin_memory = True)\n","        for epoch in range(1, CFG[\"n_epoch\"] + 1):\n","            epochs_ = epoch + CFG[\"n_epoch\"]\n","            print(f'- epoch:{epochs_} -')\n","            train_loss_avg = train_fn(train_loader, model, criterion, epochs_ ,optimizer, scheduler)\n","            valid_targets, valid_preds, valid_grid_idx, valid_loss_avg = valid_fn(model, valid_loader, criterion)\n","            \n","            # target, predをconcatして元のサイズに戻す\n","            valid_preds_img, valid_targets_img  = concat_grid_img(valid_preds, valid_targets, valid_grid_idx, valid_dirs)\n","            valid_score, valid_threshold, auc, dice_list = calc_cv(valid_targets_img, valid_preds_img)\n","            valid_preds_binary = (valid_preds_img > valid_threshold).astype(np.uint8)\n","            \n","            elapsed = time.time() - start_time\n","            print(f\"\\t epoch:{epochs_}, avg train loss:{train_loss_avg:.4f}, avg valid loss:{valid_loss_avg:.4f}\")\n","            print(f\"\\t score:{valid_score:.4f}(th={valid_threshold:3f}), auc={auc:4f}::: time:{elapsed:.2f}s\")\n","            if not CFG[\"DEBUG\"]:\n","                logging_metrics_epoch(CFG, fold, epoch, train_loss_avg, valid_loss_avg, valid_score, valid_threshold, auc)\n","            scheduler.step()\n","            # validationスコアがbestを更新したらモデルを保存する\n","            if valid_score > best_score:\n","                best_epoch = epochs_\n","                best_valloss = valid_loss_avg\n","                best_score = valid_score\n","                best_threshold = valid_threshold\n","                model_name = CFG[\"model_name\"]\n","                model_path = os.path.join(CFG[\"OUTPUT_DIR\"], f'{model_name}_fold{fold}.pth')\n","                torch.save(model.state_dict(), model_path) \n","                print(f'Epoch {epochs_} - Save Best Score: {best_score:.4f}. Model is saved.')\n","                print(\"dice_list: \", dice_list)\n","                # save oof\n","                # save_and_plot_oof(\"score\", fold, valid_preds_img, valid_targets_img, valid_preds_binary)\n","            \n","            if auc > best_auc:\n","                best_auc = auc\n","                best_auc_epoch = epochs_\n","                best_auc_valloss = valid_loss_avg\n","                model_name = CFG[\"model_name\"]\n","                model_path = os.path.join(CFG[\"OUTPUT_DIR\"], f'{model_name}_auc_fold{fold}.pth')\n","                torch.save(model.state_dict(), model_path) \n","                print(f'Epoch {epochs_} - Save Best AUC: {best_auc:.4f}. Model is saved.')\n","        \n","        valid_sliceave_score, valid_sliceave_threshold, ave_auc, dice_list = calc_cv(valid_targets_img, valid_preds_img)\n","        \n","        slice_ave_score_list.append(valid_sliceave_score)\n","        slice_ave_auc_list.append(ave_auc)\n","        slice_ave_score_threshold_list.append(valid_sliceave_threshold)\n"," \n","        valid_slice_binary = (valid_slice_ave > valid_sliceave_threshold).astype(np.uint8)\n","        save_and_plot_oof(\"oof\", fold, 999, valid_slice_ave, valid_targets_img, valid_slice_binary)\n","        print(f'[fold{fold}] slice ave score:{valid_sliceave_score:.4f}(th={valid_sliceave_threshold:3f}), auc={ave_auc:4f}')\n","        \n","        print(f'[fold{fold}] BEST Epoch {best_epoch} - Save Best Score:{best_score:.4f}. Best loss:{best_valloss:.4f}')\n","        print(f'[fold{fold}] BEST AUC Epoch {best_auc_epoch} - Save Best Score:{best_auc:.4f}. Best loss:{best_auc_valloss:.4f}')\n","            \n","        best_score_list.append(best_score)\n","        best_threshold_list.append(best_threshold)\n","        best_epoch_list.append(best_epoch)\n","        del model, train_loader, train_dataset, valid_loader, valid_dataset, valid_preds_img, valid_targets_img, valid_preds_binary\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        \n","    for fold, (best_score, best_threshold, best_epoch) in enumerate(zip(best_score_list, best_threshold_list, best_epoch_list)):\n","        print(f\"fold[{fold}] BEST SCORE = {best_score:.4f} thr={best_threshold} (epoch={best_epoch})\")\n","        print(f\"fold[{fold}] slice ave score:{slice_ave_score_list[fold]:.4f}(th={slice_ave_score_threshold_list[fold]:3f}), auc={slice_ave_auc_list[fold]:4f}\")\n","    return best_score_list, best_threshold_list, best_epoch_list"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# slice inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def slide_inference(CFG):\n","    start_time = time.time()\n","    slice_ave_score_list, slice_ave_auc_list, slice_ave_score_threshold_list = [], [], []\n","    for fold in CFG[\"folds\"]:\n","        print(f\"-- fold{fold} slide inference start --\")\n"," \n","        # set model & learning fn\n","        model = SegModel(CFG)\n","        # model_path = os.path.join(CFG[\"OUTPUT_DIR\"], f'{CFG[\"model_name\"]}_fold{fold}.pth')\n","        model_path = os.path.join(CFG[\"OUTPUT_DIR\"], f'{CFG[\"model_name\"]}_auc_fold{fold}.pth')\n","        model.load_state_dict(torch.load(model_path))\n","        model = model.to(device)\n","        valid_img_slice = None\n","        for slice_idx, surface_list in enumerate(SURFACE_LIST):\n","            print(\"surface_list: \", surface_list)\n","            surface_volumes = None\n","            for slide_pos in CFG[\"slide_pos_list\"]:\n","                print(\"slide pos:\", slide_pos)\n","                valid_dirs = CFG[\"VALID_DIR_LIST\"][fold]\n","                valid_dataset = VCID_Dataset(CFG, valid_dirs, surface_list, surface_volumes, slide_pos, mode=\"valid\", transform=valid_transforms)\n","                surface_volumes = valid_dataset.get_surface_volumes()\n","                valid_loader = DataLoader(valid_dataset, batch_size=CFG[\"batch_size\"], shuffle = False,\n","                                            num_workers = CFG[\"num_workers\"], pin_memory = True)\n","\n","                valid_targets, valid_preds, valid_grid_idx = valid_fn(model, valid_loader)\n","                \n","                # target, predをconcatして元のサイズに戻す\n","                valid_preds_img, valid_targets_img  = concat_grid_img(valid_preds, valid_targets, valid_grid_idx, valid_dirs, slide_pos)\n","                valid_score, valid_threshold, auc, dice_list = calc_cv(valid_targets_img, valid_preds_img)\n","                valid_preds_binary = (valid_preds_img > valid_threshold).astype(np.uint8)\n","                save_and_plot_oof(\"slide\", fold, slice_idx, valid_preds_img, valid_targets_img, valid_preds_binary) \n","                \n","                elapsed = time.time() - start_time\n","                print(f\"\\t score:{valid_score:.4f}(th={valid_threshold:3f}), auc={auc:4f}::: time:{elapsed:.2f}s\")\n","                # valid_img_slice.append(valid_preds_img)\n","                if valid_img_slice is None:\n","                    valid_img_slice = valid_preds_img\n","                else:\n","                    valid_img_slice += valid_preds_img\n","            # valid_slice_ave = np.zeros((valid_preds_img.shape[0], valid_preds_img.shape[1], 1))\n","        # for idx in range(len(SURFACE_LIST)*len(CFG[\"slide_pos_list\"])):\n","        #     valid_pred_slice = valid_img_slice[idx]\n","        #     valid_slice_ave += valid_pred_slice\n","        valid_img_slice /= len(SURFACE_LIST)*len(CFG[\"slide_pos_list\"])\n","        valid_sliceave_score, valid_sliceave_threshold, ave_auc, dice_list = calc_cv(valid_targets_img, valid_img_slice)\n","        \n","        slice_ave_score_list.append(valid_sliceave_score)\n","        slice_ave_auc_list.append(ave_auc)\n","        slice_ave_score_threshold_list.append(valid_sliceave_threshold)\n","\n","        valid_slice_binary = (valid_img_slice > valid_sliceave_threshold).astype(np.uint8)\n","        save_and_plot_oof(\"average\", fold, 555, valid_img_slice, valid_targets_img, valid_slice_binary)\n","        print(f'[fold{fold}] slice ave score:{valid_sliceave_score:.4f}(th={valid_sliceave_threshold:3f}), auc={ave_auc:4f}')\n","         \n","        del model, valid_loader, valid_dataset, valid_preds_img, valid_targets_img, valid_preds_binary\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    return slice_ave_score_list, slice_ave_auc_list, slice_ave_score_threshold_list\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# main"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.21531Z","iopub.status.busy":"2023-04-11T00:41:44.214927Z","iopub.status.idle":"2023-04-11T00:48:24.178417Z","shell.execute_reply":"2023-04-11T00:48:24.176805Z","shell.execute_reply.started":"2023-04-11T00:41:44.215273Z"},"trusted":true},"outputs":[],"source":["%%time\n","best_score_list, best_threshold_list, best_epoch_list = training_loop(CFG)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","# OOF SCORE INFER"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","slice_ave_score_list, slice_ave_auc_list, slice_ave_score_threshold_list = slide_inference(CFG)\n","for fold in CFG[\"folds\"]:\n","    print(f\"fold[{fold}] slice ave score:{slice_ave_score_list[fold]:.4f}(th={slice_ave_score_threshold_list[fold]:3f}), auc={slice_ave_auc_list[fold]:4f}\")\n","    wandb.log({\"OOF SCORE\" : {f\"slice average score\":slice_ave_score_list[fold],\n","                            f\"slice average threshold\":slice_ave_score_threshold_list[fold],\n","                            f\"slice_average auc\":slice_ave_auc_list[fold],\n","                            \"fold\":fold,\n","                            }})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-04-11T00:48:24.180209Z","iopub.status.idle":"2023-04-11T00:48:24.181024Z","shell.execute_reply":"2023-04-11T00:48:24.180784Z","shell.execute_reply.started":"2023-04-11T00:48:24.18074Z"},"trusted":true},"outputs":[],"source":["import yaml\n","with open(os.path.join(CFG[\"OUTPUT_DIR\"], \"Config.yaml\"), \"w\") as f:\n","    yaml.dump(CFG, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not CFG[\"DEBUG\"]:\n","    wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","pred_flatten_list = []\n","mask_flatten_list = []\n","for fold in [0,1,2,3,4]:\n","    pred_path = os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\", f\"fold{fold}_average_slice555_valid_pred_img.png\")\n","    mask_path = os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\", f\"fold{fold}_average_slice555_valid_targets_img.png\")\n","    print(pred_path)\n","    pred_img = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n","    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","    print(pred_img.shape)\n","    print(mask_img.shape)\n","    plt.figure()\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(pred_img)\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(mask_img)\n","    plt.show()\n","    pred_flatten_list.extend(pred_img.flatten())\n","    mask_flatten_list.extend(mask_img.flatten())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mask_flatten_list = np.array(mask_flatten_list)/255.\n","mask = np.array(mask_flatten_list).astype(int)\n","pred = np.array(pred_flatten_list)/255.\n","\n","plt.figure()\n","plt.subplot(1, 2, 1)\n","plt.hist(pred, bins=100)\n","plt.subplot(1, 2, 2)\n","plt.hist(mask)\n","plt.show()\n","\n","for th in np.array(range(10, 100+1, 5)) / 100:\n","    dice = fbeta_numpy(mask, (pred >= th).astype(int), beta=0.5)\n","    print(f\"th={th:.2f}, dice={dice:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
