{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:41.388632Z","iopub.status.busy":"2023-04-11T00:41:41.388166Z","iopub.status.idle":"2023-04-11T00:41:43.938183Z","shell.execute_reply":"2023-04-11T00:41:43.937024Z","shell.execute_reply.started":"2023-04-11T00:41:41.388578Z"},"trusted":true},"outputs":[],"source":["import gc\n","import os\n","import random\n","import time\n","import math\n","\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# model\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import timm\n","from torchvision.models.feature_extraction import create_feature_extractor\n","import torchvision.transforms.functional as TF\n","\n","# data loader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from torch.utils.data import DataLoader, Dataset\n","\n","# training\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau, ExponentialLR\n","\n","# metric\n","from sklearn.metrics import fbeta_score, roc_auc_score\n","\n","import wandb"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# config"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'EXP_CATEGORY': 'LAYER_CHANGE', 'INPUT_DIR': '/working/input/vesuvius-challenge-ink-detection', 'RANDOM_SLIDE': True, 'TRAIN_DIR': '/working/input/vesuvius-challenge-ink-detection/train', 'TRAIN_DIR_LIST': [['1', '2_0', '2_1', '2_2'], ['1', '2_0', '2_1', '3'], ['1', '2_0', '2_2', '3'], ['1', '2_1', '2_2', '3'], ['2_0', '2_1', '2_2', '3']], 'T_max': 5, 'VALID_DIR_LIST': [['3'], ['2_2'], ['2_1'], ['2_0'], ['1']], 'base_lr': 0.0001, 'batch_size': 8, 'folds': [0, 1, 2, 3, 4], 'img_size': [256, 256], 'input_img_size': [512, 512], 'inp_channels': 4, 'lr': 0.001, 'max_lr': 0.0005, 'min_lr': 1e-08, 'model_name': 'tf_efficientnet_b6', 'channel_nums': [576, 200, 72, 40, 32], 'n_epoch': 25, 'num_workers': 2, 'out_channels': 1, 'out_indices': [0, 1, 2, 3, 4], 'pretrained': True, 'print_freq': 1000, 'random_seed': 21, 'slide_pos_list': [[0, 0], [128, 0], [0, 128], [128, 128]], 'step_size_down': 10, 'step_size_up': 5, 'SURFACE_LIST': [[30, 33, 36, 39], [26, 29, 32, 35], [29, 32, 35, 38], [27, 30, 33, 36], [28, 31, 34, 37]], 'surface_num': 4, 'weight_decay': 1e-06}\n"]}],"source":["import yaml\n","OUTPUT_DIR = \"/working/output\" \n","EXP_NAME = \"exp089\"\n","with open(os.path.join(OUTPUT_DIR, EXP_NAME, \"Config.yaml\")) as file:\n","    CFG = yaml.safe_load(file)\n","CFG[\"SURFACE_LIST\"] = [\n","    # list(range(31, 41, 3)),\n","    # list(range(25, 35, 3)),\n","    list(range(30, 40, 3)),\n","    list(range(26, 36, 3)),\n","    list(range(29, 39, 3)),\n","    list(range(27, 37, 3)),\n","    list(range(28, 38, 3)),\n","]\n","# CFG[\"SURFACE_LIST\"] = [\n","    # list(range(25, 35, 3)),\n","    # list(range(30, 40, 3)),\n","    # list(range(26, 36, 3)),\n","    # list(range(29, 39, 3)),\n","    # list(range(27, 37, 3)),\n","    # list(range(28, 38, 3)),\n","# ]\n","# CFG[\"slide_pos\"] = [[0,0]]\n","print(CFG)\n","CFG[\"OUTPUT_DIR\"] = os.path.join(OUTPUT_DIR, EXP_NAME)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# utils"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:43.962726Z","iopub.status.busy":"2023-04-11T00:41:43.962423Z","iopub.status.idle":"2023-04-11T00:41:43.996799Z","shell.execute_reply":"2023-04-11T00:41:43.995583Z","shell.execute_reply.started":"2023-04-11T00:41:43.962698Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["def seed_everything(seed=CFG[\"random_seed\"]):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.000826Z","iopub.status.busy":"2023-04-11T00:41:44.000079Z","iopub.status.idle":"2023-04-11T00:41:44.010016Z","shell.execute_reply":"2023-04-11T00:41:44.009127Z","shell.execute_reply.started":"2023-04-11T00:41:44.000749Z"},"trusted":true},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# metric"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.012555Z","iopub.status.busy":"2023-04-11T00:41:44.011593Z","iopub.status.idle":"2023-04-11T00:41:44.023483Z","shell.execute_reply":"2023-04-11T00:41:44.022677Z","shell.execute_reply.started":"2023-04-11T00:41:44.012515Z"},"trusted":true},"outputs":[],"source":["def fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n","    y_true_count = targets.sum()\n","    ctp = preds[targets==1].sum()\n","    cfp = preds[targets==0].sum()\n","    beta_squared = beta * beta\n","\n","    c_precision = ctp / (ctp + cfp + smooth)\n","    c_recall = ctp / (y_true_count + smooth)\n","    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n","\n","    return dice\n","\n","def calc_fbeta_auc(mask, mask_pred):\n","    mask = mask.astype(int).flatten()\n","    mask_pred = mask_pred.flatten()\n","\n","    best_th = 0\n","    best_dice = 0\n","    dice_list = [] \n","    # for th in np.array(range(10, 50+1, 5)) / 100:\n","    for th in np.array(range(10, 100+1, 5)) / 100:\n","        # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n","        dice = fbeta_numpy(mask, (mask_pred >= th).astype(int), beta=0.5)\n","        dice_list.append(dice)\n","        # print(f'\\t th: {th}, fbeta: {dice}')\n","        if dice > best_dice:\n","            best_dice = dice\n","            best_th = th\n","    \n","    auc = roc_auc_score(mask, mask_pred)\n","    # Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n","    return best_dice, best_th, auc, dice_list\n","\n","\n","def calc_cv(mask_gt, mask_pred):\n","    best_dice, best_th, auc, dice_list = calc_fbeta_auc(mask_gt, mask_pred)\n","\n","    return best_dice, best_th, auc, dice_list"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# model"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, CFG):\n","        super().__init__()\n","        self.encoder = timm.create_model(CFG[\"model_name\"], in_chans=CFG[\"inp_channels\"], \n","                                         features_only=True, out_indices=CFG[\"out_indices\"], pretrained=CFG[\"pretrained\"])\n","    def forward(self, img):\n","        skip_connection_list = self.encoder(img)\n","        return skip_connection_list\n","\n","class UpConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","        self.bn1 = nn.BatchNorm2d(in_channels)\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 2, padding=\"same\")\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","    def forward(self, x):\n","        x = self.up(x)\n","        x = self.bn1(x)\n","        x = self.conv(x)\n","        x = self.bn2(x)\n","        return x\n","\n","\n","#下に1層を使わない\n","class Decoder(nn.Module):\n","    def __init__(self, CFG):\n","        super().__init__()\n","        self.UpConv_0 = UpConv(CFG[\"channel_nums\"][0], CFG[\"channel_nums\"][1])\n","        self.UpConv_1 = UpConv(CFG[\"channel_nums\"][1]*2, CFG[\"channel_nums\"][2])\n","        self.UpConv_2 = UpConv(CFG[\"channel_nums\"][2]*2, CFG[\"channel_nums\"][3])\n","        self.UpConv_3 = UpConv(CFG[\"channel_nums\"][3]*2, CFG[\"channel_nums\"][4])\n","    \n","    def forward(self, skip_connection_list):\n","        emb = self.UpConv_0(skip_connection_list[-1])\n","        emb_cat = torch.cat([skip_connection_list[-2], emb], dim = 1)\n","        \n","        emb = self.UpConv_1(emb_cat)\n","        emb_cat = torch.cat([skip_connection_list[-3], emb], dim = 1)\n","        \n","        emb = self.UpConv_2(emb_cat)\n","        emb_cat = torch.cat([skip_connection_list[-4], emb], dim = 1)\n","        \n","        emb = self.UpConv_3(emb_cat)\n","        emb_cat = torch.cat([skip_connection_list[-5], emb], dim = 1)\n","        \n","        return emb_cat\n","\n","class SegModel(nn.Module):\n","    def __init__(self, CFG):\n","        super().__init__()\n","        self.encoder = Encoder(CFG)\n","        self.decoder = Decoder(CFG)\n","        self.head = nn.Sequential(\n","            nn.Conv2d(CFG[\"channel_nums\"][-1]*2, CFG[\"out_channels\"], kernel_size=1, stride=1, padding=0),\n","            # nn.BatchNorm2d(CFG[\"out_channels\"]),\n","            # nn.Sigmoid()\n","        )\n","    def forward(self, img):\n","        skip_connection_list = self.encoder(img)\n","        emb = self.decoder(skip_connection_list)\n","        output = self.head(emb)\n","        return output\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.05649Z","iopub.status.busy":"2023-04-11T00:41:44.056177Z","iopub.status.idle":"2023-04-11T00:41:44.063611Z","shell.execute_reply":"2023-04-11T00:41:44.062381Z","shell.execute_reply.started":"2023-04-11T00:41:44.05646Z"},"trusted":true},"outputs":[],"source":["train_transforms = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.VerticalFlip(p=0.5),\n","    A.RandomRotate90(p=0.5),\n","    A.RandomCrop(int(CFG[\"img_size\"][0]*0.8), int(CFG[\"img_size\"][1]*0.8), p=0.5),\n","    A.Blur(blur_limit=3, p=0.3),\n","    A.Resize(CFG[\"img_size\"][0], CFG[\"img_size\"][1]),\n","    ToTensorV2(),\n","])\n","\n","valid_transforms = A.Compose([\n","    ToTensorV2(),\n","])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["class VCID_Dataset(Dataset):\n","    def __init__(self, CFG, data_dir_list, surface_list, surface_volumes=None, slide_pos=[0,0], mode=\"train\", transform=None):\n","        # get config\n","        self.mode = mode\n","        self.RANDOM_SLIDE = CFG[\"RANDOM_SLIDE\"]\n","        self.img_size = CFG[\"img_size\"]\n","        if self.mode==\"train\":  self.DATADIR = CFG[\"TRAIN_DIR\"]\n","        elif self.mode==\"valid\":    self.DATADIR = CFG[\"TRAIN_DIR\"]\n","        elif self.mode == \"test\":   self.DATADIR = CFG[\"TEST_DIR\"]\n","        self.data_dir_list = data_dir_list\n","        self.surface_list = surface_list\n","        self.slide_pos = slide_pos\n","        self.transform = transform\n","        # self.cleha = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","        # get imgs\n","        # print(\"initializing dataset...\")\n","        self.imgs = []\n","        for data_dir in self.data_dir_list:\n","            img_path = os.path.join(self.DATADIR, data_dir, \"mask.png\")\n","            # print(img_path)\n","            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","            img = img.reshape(img.shape[0], img.shape[1], 1) # (h, w, channel=1)\n","            assert img is not None, \"img is None. data path is wrong\"\n","            self.imgs.append(img)  \n","        \n","        # get and split surface\n","        if surface_volumes is None:\n","            self.surface_vols = self.read_surfacevols()\n","        else:\n","            # print(\"using loaded surface_vols\")\n","            self.surface_vols = surface_volumes\n","       \n","        # split grid\n","        self.get_all_grid()\n","        self.fileter_grid()\n","        self.get_flatten_grid()\n","        # print(\"split grid done.\") \n","       \n","        # get label imgs\n","        if self.mode == \"train\" or self.mode == \"valid\":\n","            self.labels = []\n","            for data_dir in self.data_dir_list:\n","                label_path = os.path.join(self.DATADIR, data_dir, \"inklabels.png\")\n","                assert os.path.exists(label_path), f\"{label_path} is not exist.\"\n","                # read label\n","                label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n","                label = label.reshape(label.shape[0], label.shape[1], 1) # (h, w, channel=1)\n","                self.labels.append(label)# 画像サイズがそれぞれ違うので単純にconcatできずlist化しているs\n","        # print(\"initializing dataset done.\")\n","\n","    def get_surface_volumes(self):\n","        return self.surface_vols\n","\n","    def read_surfacevols(self):\n","        \"\"\" read surface volume by data_dir_list and surface_list \n","            Returns:surface_vuls (list): surface volume list [array(h,w,channel=surface_num), array(), ...]\n","        \"\"\"\n","        surface_vols = []\n","        # print(\"reading surface volume...\")\n","        for data_dir in self.data_dir_list:\n","            surface_vol_ = None\n","            for read_idx, surface_idx in enumerate(self.surface_list):\n","                # print(\"\\r\", f\"reading idx : {read_idx+1}/{len(self.surface_list)}\", end=\"\")\n","                surface_path = os.path.join(self.DATADIR, data_dir, \"surface_volume\", f\"{surface_idx:02}.tif\")\n","                surface_vol = cv2.imread(surface_path, cv2.IMREAD_GRAYSCALE)\n","                # surface_vol = self.cleha.apply(surface_vol)\n","                surface_vol = surface_vol.reshape(surface_vol.shape[0], surface_vol.shape[1], 1) # (h, w, channel=1)\n","                if surface_vol_ is None:\n","                    surface_vol_ = surface_vol\n","                else:\n","                    surface_vol_ = np.concatenate([surface_vol_, surface_vol], axis=2) # (h, w, channel=surface_num)\n","            surface_vols.append(surface_vol_)\n","            # print(f\"  => read surface volume done. [{data_dir}]\")\n","        return surface_vols\n","\n","\n","    def get_grid_img(self, img, grid_idx):\n","        \"\"\" crop grid img from original img\"\"\"\n","        img_grid = img[(grid_idx[0]*self.img_size[0]) + self.slide_pos[0] : ((grid_idx[0]+1)*self.img_size[0]) + self.slide_pos[0],\n","                        (grid_idx[1]*self.img_size[1]) + self.slide_pos[1] : ((grid_idx[1]+1)*self.img_size[1]) + self.slide_pos[1]]\n","        return img_grid\n","    \n","    def get_grid_img_and_mask(self, img, mask, grid_idx):\n","        \"\"\" crop grid img from original img\"\"\"\n","        if self.RANDOM_SLIDE and self.mode==\"train\" and random.random() < 0.5:\n","            if (grid_idx[0]!=0 and grid_idx[1]!=0) and (grid_idx[0]!=img.shape[0]//self.img_size[0] and grid_idx[1]!=img.shape[1]//self.img_size[1]):\n","                rand_pos = [np.random.randint(0, self.img_size[0]//4) - self.img_size[0]//4, np.random.randint(0, self.img_size[1]//4)-self.img_size[1]//4]\n","            else:\n","                rand_pos = [0, 0]\n","        else:\n","            rand_pos = [0, 0]\n","        self.rand_pos = rand_pos\n","        img_grid = img[(grid_idx[0]*self.img_size[0]) + self.slide_pos[0] + rand_pos[0] : ((grid_idx[0]+1)*self.img_size[0]) + self.slide_pos[0] + rand_pos[0],\n","                        (grid_idx[1]*self.img_size[1]) + self.slide_pos[1] + rand_pos[1] : ((grid_idx[1]+1)*self.img_size[1]) + self.slide_pos[1] + rand_pos[1]]\n","        mask_grid = mask[(grid_idx[0]*self.img_size[0]) + self.slide_pos[0] + rand_pos[0] : ((grid_idx[0]+1)*self.img_size[0]) + self.slide_pos[0] + rand_pos[0],\n","                         (grid_idx[1]*self.img_size[1]) + self.slide_pos[1] + rand_pos[1] : ((grid_idx[1]+1)*self.img_size[1]) + self.slide_pos[1] + rand_pos[1]]\n","        return img_grid/255., mask_grid/255.\n","    \n","    def get_masked_img(self, img, mask):\n","        \"\"\" multiply mask to surface_volumes \"\"\"\n","        masked_img = None\n","        for channel in range(img.shape[2]):\n","            img_channel = img[:,:,channel].reshape(img.shape[0], img.shape[1],1)\n","            masked = img_channel*mask\n","            if masked_img is None:\n","                masked_img = masked.reshape(masked.shape[0], masked.shape[1], 1)\n","            else:\n","                masked = masked.reshape(masked.shape[0], masked.shape[1], 1)\n","                masked_img = np.concatenate([masked_img, masked], axis=2)\n","        return masked_img\n","    \n","    \n","    def get_all_grid(self):\n","        \"\"\" get all grid indices by img size and grid size\n","        \"\"\"\n","        self.grid_indices = []\n","        for img in self.imgs:\n","            self.x_grid_size = (img.shape[0] - self.slide_pos[0]) // self.img_size[0]\n","            self.y_grid_size = (img.shape[1] - self.slide_pos[1]) // self.img_size[1]\n","            grid_img = []\n","            for i in range(self.x_grid_size):\n","                for j in range(self.y_grid_size):\n","                    grid_img.append([i, j])\n","            self.grid_indices.append(grid_img)\n","        return self.grid_indices\n","          \n","    def fileter_grid(self):\n","        \"\"\" get grid indices which mask is not 0 by all grid indices\"\"\"\n","        grid_indices_all = []\n","        for img, grid_indices in zip(self.imgs, self.grid_indices):\n","            grid_indices_copy = grid_indices.copy()\n","            for grid_idx in grid_indices:\n","                img_grid = self.get_grid_img(img, grid_idx)\n","                if img_grid.sum() == 0:\n","                    grid_indices_copy.remove(grid_idx)\n","            grid_indices_all.append(grid_indices_copy)\n","        self.grid_indices = grid_indices_all\n","        return self.grid_indices\n","\n","    def get_flatten_grid(self):\n","        \"\"\" get flatten index list by grid indices\n","            Returns:flatten_grid (list): flatten index list [[img_idx, grid_idx], [img_idx, grid_idx], ...]\n","        \"\"\"\n","        flatten_grid = []\n","        for img_idx, grid_indices in enumerate(self.grid_indices):\n","            for grid_idx in grid_indices:\n","                grid_imgidx_list = [img_idx]\n","                grid_imgidx_list.extend(grid_idx)\n","                flatten_grid.append(grid_imgidx_list)\n","        self.flatten_grid = flatten_grid\n","        return self.flatten_grid\n","    \n","    def channel_shuffle(self, img):\n","        img = img.transpose(2, 0, 1)\n","        np.random.shuffle(img)\n","        return img.transpose(1, 2, 0)\n","\n","    def __len__(self):\n","        return len(self.flatten_grid)\n","\n","    def __getitem__(self, idx):\n","        # get indices\n","        img_grid_idx = self.flatten_grid[idx]\n","        img_idx = img_grid_idx[0]\n","        grid_idx = img_grid_idx[1:]\n","        # get img & surface_vol\n","        mask = self.imgs[img_idx]\n","        surface_vol = self.surface_vols[img_idx]\n","        # mask = self.get_grid_img(mask, grid_idx)/255.\n","        # surface_vol = self.get_grid_img(surface_vol, grid_idx)/255.\n","        mask, surface_vol = self.get_grid_img_and_mask(mask, surface_vol, grid_idx)\n","        # multiple small mask \n","        assert surface_vol.shape[0]==mask.shape[0] and surface_vol.shape[1]==mask.shape[1] , \"surface_vol_list shape is not same as img shape\"\n","        img = surface_vol\n","        # transform\n","        if self.mode == \"test\":\n","            if self.transform:\n","                img = self.transform(image=img)[\"image\"]\n","            else:\n","                img = img.transpose(2, 0, 1)\n","                img = torch.tensor(img, dtype=torch.float32)\n","            return img, grid_idx\n","        elif self.mode == \"train\" or self.mode==\"valid\":\n","            # get label(segmentation mask)\n","            label = self.labels[img_idx]\n","            label = self.get_grid_img(label, grid_idx)\n","            # if self.mode == \"train\":\n","            #     img = self.channel_shuffle(img)\n","            if self.transform:\n","                transformed = self.transform(image=img, mask=label)\n","                img = transformed[\"image\"]\n","                label = transformed[\"mask\"]\n","                label = label.permute(2, 0, 1)/255. # (channel, h, w)\n","                # label = TF.resize(img=label, size=(self.img_size[0]//2, self.img_size[1]//2))\n","            else:\n","                img = img.transpose(2, 0, 1) # (channel, h, w)\n","                label = label.transpose(2, 0, 1)/255. # (channel, h, w){}\n","                img = torch.tensor(img, dtype=torch.float32)\n","                label = torch.tensor(label, dtype=torch.float32)\n","                # label = TF.resize(img=label, size=(self.img_size[0]//2, self.img_size[1]//2))\n","            assert img is not None and label is not None, f\"img or label is None {img} {label}, {img_idx}, {grid_idx}, {self.rand_pos}\"\n","            return img, label, grid_idx"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# train valid fn"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.151325Z","iopub.status.busy":"2023-04-11T00:41:44.150944Z","iopub.status.idle":"2023-04-11T00:41:44.163092Z","shell.execute_reply":"2023-04-11T00:41:44.161981Z","shell.execute_reply.started":"2023-04-11T00:41:44.151287Z"},"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets, _) in enumerate(train_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float()     \n","        preds = model(images)\n","        \n","        # preds = torch.sigmoid(preds)\n","        loss = criterion(preds, targets)\n","        \n","        losses.update(loss.item(), CFG[\"batch_size\"]) \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = preds.detach().cpu().numpy().ravel().tolist()\n","        loss.backward() # パラメータの勾配を計算\n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        del preds, images, targets\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.165502Z","iopub.status.busy":"2023-04-11T00:41:44.164813Z","iopub.status.idle":"2023-04-11T00:41:44.178372Z","shell.execute_reply":"2023-04-11T00:41:44.177351Z","shell.execute_reply.started":"2023-04-11T00:41:44.16546Z"},"trusted":true},"outputs":[],"source":["def valid_fn(model, valid_loader, criterion=None):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","    test_grid_idx = []\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets, grid_idx) in enumerate(valid_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float()\n","        with torch.no_grad():\n","            preds = model(images)\n","            preds = TF.resize(img=preds, size=(CFG[\"input_img_size\"][0], CFG[\"input_img_size\"][1]))\n","            if not criterion is None:\n","                loss = criterion(preds, targets)\n","        if not criterion is None:\n","            losses.update(loss.item(), CFG[\"batch_size\"])\n","        batch_time.update(time.time() - end)\n","\n","        preds = torch.sigmoid(preds)\n","        targets = targets.detach().cpu().numpy()\n","        preds = preds.detach().cpu().numpy()\n","        \n","        test_preds.extend([preds[idx, :,:,:].transpose(1,2,0) for idx in range(preds.shape[0])])\n","        test_targets.extend([targets[idx, :,:,:].transpose(1,2,0) for idx in range(targets.shape[0])])\n","        test_grid_idx.extend([[x_idx, y_idx] for x_idx, y_idx in zip(grid_idx[0].tolist(), grid_idx[1].tolist())])\n","\n","        if (batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(valid_loader)-1)) and (not criterion is None):\n","            print('EVAL: [{0}/{1}] '\n","                'Elapsed {remain:s} '\n","                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                .format(\n","                    batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                    remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                ))\n","        del preds, images, targets\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    if criterion is None:\n","        return test_targets, test_preds, test_grid_idx\n","    else:\n","        return test_targets, test_preds, test_grid_idx, losses.avg"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# training loop"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# def concat_grid_img(img_list, label_list, grid_idx_list, valid_dir_list, slide_pos=[0,0], tta=\"default\"):\n","#     # concat pred img and label to original size\n","#     img_path = os.path.join(CFG[\"TRAIN_DIR\"], valid_dir_list[0], \"mask.png\")\n","#     img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","#     img = img.reshape(img.shape[0], img.shape[1], 1)\n","#     pred_img = np.zeros_like(img).astype(np.float32)\n","#     label_img = np.zeros_like(img).astype(np.float32)\n","#     for img_idx, grid_idx in enumerate(grid_idx_list):\n","#         img_ = img_list[img_idx]\n","#         label_ = label_list[img_idx]\n","#         img_ = cv2.resize(img_, dsize=(CFG[\"img_size\"][0], CFG[\"img_size\"][1]))\n","#         label_ = cv2.resize(label_, (CFG[\"img_size\"][0], CFG[\"img_size\"][1]))\n","#         img_ = img_[:, :, np.newaxis]\n","#         label_ = label_[:, :, np.newaxis]\n","#         if tta==\"default\":\n","#             pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","#                     grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += img_\n","#             label_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","#                     grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += label_\n","#         elif tta==\"vflip\":\n","#             pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","#                     grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += np.flipud(img_)\n","#             label_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","#                     grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += np.flipud(label_)\n","#         elif tta==\"hflip\":\n","#             pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","#                     grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += np.fliplr(img_)\n","#             label_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","#                     grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += np.fliplr(label_)\n","#         else:\n","#             pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","#                     grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += img_\n","#             label_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","#                     grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += label_\n","        \n","#     return pred_img, label_img\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def concat_grid_img(img_list, label_list, grid_idx_list, valid_dir_list, slide_pos=[0,0], tta=\"default\"):\n","    # concat pred img and label to original size\n","    img_path = os.path.join(CFG[\"TRAIN_DIR\"], valid_dir_list[0], \"mask.png\")\n","    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","    img = img.reshape(img.shape[0], img.shape[1], 1)\n","    pred_img = np.zeros_like(img).astype(np.float32)\n","    label_path = os.path.join(CFG[\"TRAIN_DIR\"], valid_dir_list[0], \"inklabels.png\")\n","    label_img = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n","    label_img = label_img.reshape(label_img.shape[0], label_img.shape[1], 1)\n","    label_img = (label_img > 0).astype(np.float32)\n","    for img_idx, grid_idx in enumerate(grid_idx_list):\n","        img_ = img_list[img_idx]\n","        img_ = cv2.resize(img_, dsize=(CFG[\"img_size\"][0], CFG[\"img_size\"][1]))\n","        img_ = img_[:, :, np.newaxis]\n","        if tta==\"default\":\n","            pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","                    grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += img_\n","        elif tta==\"vflip\":\n","            pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","                    grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += np.flipud(img_)\n","        elif tta==\"hflip\":\n","            pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","                    grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += np.fliplr(img_)\n","        elif tta==\"vhflip\":\n","            pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","                    grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += np.flipud(np.fliplr(img_))\n","        elif tta==\"hvflip\":\n","            pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","                    grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += np.fliplr(np.flipud(img_))\n","        else:\n","            pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","                    grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += img_\n","        \n","    return pred_img, label_img\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def save_and_plot_oof(mode, fold, slice_idx, valid_preds_img, valid_targets_img, valid_preds_binary):\n","    cv2.imwrite(os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\", f\"fold{fold}_{mode}_slice{slice_idx}_valid_pred_img.png\"), valid_preds_img*255)\n","    # cv2.imwrite(os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\", f\"fold{fold}_{mode}_slice{slice_idx}_valid_predbin_img.png\"), valid_preds_binary*255)\n","    # cv2.imwrite(os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\", f\"fold{fold}_{mode}_slice{slice_idx}_valid_targets_img.png\"), valid_targets_img*255)\n","    # plt.figure()\n","    # plt.imshow(valid_preds_img, cmap=\"gray\")\n","    # plt.show() "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# slice inference"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def get_tta_aug(aug_type):\n","    if aug_type==\"default\":\n","        return A.Compose([\n","            A.Resize(CFG[\"input_img_size\"][0], CFG[\"input_img_size\"][1], p=1.0),\n","            ToTensorV2(),\n","            ])\n","    elif aug_type==\"hflip\":\n","        return A.Compose([\n","            A.HorizontalFlip(p=1.0),\n","            A.Resize(CFG[\"input_img_size\"][0], CFG[\"input_img_size\"][1], p=1.0), \n","            ToTensorV2(),\n","        ])\n","    elif aug_type==\"vflip\":\n","        return A.Compose([\n","            A.VerticalFlip(p=1.0),\n","            A.Resize(CFG[\"input_img_size\"][0], CFG[\"input_img_size\"][1], p=1.0),\n","            ToTensorV2(),\n","        ])\n","    elif aug_type==\"hvflip\":\n","        return A.Compose([\n","            A.HorizontalFlip(p=1.0),\n","            A.VerticalFlip(p=1.0),\n","            A.Resize(CFG[\"input_img_size\"][0], CFG[\"input_img_size\"][1], p=1.0),\n","            ToTensorV2(),\n","        ])\n","    elif aug_type==\"vhflip\":\n","        return A.Compose([\n","            A.VerticalFlip(p=1.0),\n","            A.HorizontalFlip(p=1.0),\n","            A.Resize(CFG[\"input_img_size\"][0], CFG[\"input_img_size\"][1], p=1.0),\n","            ToTensorV2(),\n","        ])\n","    else:\n","        return A.Compose([\n","            A.Resize(CFG[\"input_img_size\"][0], CFG[\"input_img_size\"][1], p=1.0),\n","            ToTensorV2(),\n","            ])\n","        "]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def slide_inference(CFG, tta_list):\n","    start_time = time.time()\n","    slice_ave_score_list, slice_ave_auc_list, slice_ave_score_threshold_list = [], [], []\n","    for fold in CFG[\"folds\"]:\n","        print(f\"-- fold{fold} slide inference start --\")\n"," \n","        # set model & learning fn\n","        model = SegModel(CFG)\n","        model_path = os.path.join(CFG[\"OUTPUT_DIR\"], f'{CFG[\"model_name\"]}_auc_fold{fold}.pth')\n","        # model_path = os.path.join(CFG[\"OUTPUT_DIR\"], f'{CFG[\"model_name\"]}_fold{fold}.pth')\n","        model.load_state_dict(torch.load(model_path))\n","        model = model.to(device)\n","        valid_img_slice = None\n","        for slice_idx, surface_list in enumerate(CFG[\"SURFACE_LIST\"]):\n","            print(\"surface_list: \", surface_list)\n","            surface_volumes = None\n","            for slide_pos in CFG[\"slide_pos_list\"]:\n","                print(\"slide pos:\", slide_pos)\n","                valid_dirs = CFG[\"VALID_DIR_LIST\"][fold]\n","                for tta in tta_list:\n","                    print(f\"tta:{tta}\")\n","                    valid_transforms = get_tta_aug(tta)\n","                    valid_dataset = VCID_Dataset(CFG, valid_dirs, surface_list, surface_volumes, slide_pos,\n","                                                 mode=\"valid\", transform=valid_transforms)\n","                    surface_volumes = valid_dataset.get_surface_volumes()\n","                    valid_loader = DataLoader(valid_dataset, batch_size=CFG[\"batch_size\"], shuffle = False,\n","                                                num_workers = CFG[\"num_workers\"], pin_memory = True)\n","\n","                    valid_targets, valid_preds, valid_grid_idx = valid_fn(model, valid_loader)\n","\n","                    # target, predをconcatして元のサイズに戻す\n","                    valid_preds_img, valid_targets_img  = concat_grid_img(valid_preds, valid_targets, valid_grid_idx, valid_dirs, slide_pos, tta)\n","                    valid_score, valid_threshold, auc, dice_list = calc_cv(valid_targets_img, valid_preds_img)\n","                    valid_preds_binary = (valid_preds_img > valid_threshold).astype(np.uint8)\n","                    # save_and_plot_oof(\"slide_tta_add\", fold, slice_idx, valid_preds_img, valid_targets_img, valid_preds_binary) \n","\n","                    elapsed = time.time() - start_time\n","                    print(f\"\\t score:{valid_score:.4f}(th={valid_threshold:3f}), auc={auc:4f}::: time:{elapsed:.2f}s\")\n","                    if valid_img_slice is None:\n","                        valid_img_slice = valid_preds_img\n","                    else:\n","                        valid_img_slice += valid_preds_img\n","\n","        valid_img_slice /= (len(CFG[\"SURFACE_LIST\"])*len(CFG[\"slide_pos_list\"])*len(tta_list))\n","        valid_sliceave_score, valid_sliceave_threshold, ave_auc, dice_list = calc_cv(valid_targets_img, valid_img_slice)\n","        \n","        slice_ave_score_list.append(valid_sliceave_score)\n","        slice_ave_auc_list.append(ave_auc)\n","        slice_ave_score_threshold_list.append(valid_sliceave_threshold)\n","\n","        valid_slice_binary = (valid_img_slice > valid_sliceave_threshold).astype(np.uint8)\n","        save_and_plot_oof(\"tta_add_average_layer\", fold, 555, valid_img_slice, valid_targets_img, valid_slice_binary)\n","        print(f'[fold{fold}] slice ave score:{valid_sliceave_score:.4f}(th={valid_sliceave_threshold:3f}), auc={ave_auc:4f}')\n","         \n","        del model, valid_loader, valid_dataset, valid_preds_img, valid_targets_img, valid_preds_binary\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    return slice_ave_score_list, slice_ave_auc_list, slice_ave_score_threshold_list\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# main"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","# OOF SCORE INFER"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-- fold0 slide inference start --\n","surface_list:  [30, 33, 36, 39]\n","slide pos: [0, 0]\n","tta:default\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:444: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:744.)\n","  self.padding, self.dilation, self.groups)\n"]},{"name":"stdout","output_type":"stream","text":["\t score:0.4961(th=0.150000), auc=0.881144::: time:43.88s\n","tta:hflip\n","\t score:0.4628(th=0.150000), auc=0.872367::: time:68.58s\n","tta:vflip\n","\t score:0.4623(th=0.150000), auc=0.877029::: time:92.57s\n","slide pos: [128, 0]\n","tta:default\n","\t score:0.5339(th=0.150000), auc=0.889984::: time:117.42s\n","tta:hflip\n","\t score:0.4996(th=0.150000), auc=0.880152::: time:142.26s\n","tta:vflip\n","\t score:0.5122(th=0.150000), auc=0.887851::: time:167.41s\n","slide pos: [0, 128]\n","tta:default\n","\t score:0.4777(th=0.150000), auc=0.883706::: time:192.51s\n","tta:hflip\n","\t score:0.4467(th=0.150000), auc=0.879633::: time:217.57s\n","tta:vflip\n","\t score:0.4545(th=0.150000), auc=0.884067::: time:242.77s\n","slide pos: [128, 128]\n","tta:default\n","\t score:0.5030(th=0.150000), auc=0.891331::: time:267.99s\n","tta:hflip\n","\t score:0.4668(th=0.150000), auc=0.885003::: time:293.24s\n","tta:vflip\n","\t score:0.4911(th=0.150000), auc=0.890115::: time:317.97s\n","surface_list:  [26, 29, 32, 35]\n","slide pos: [0, 0]\n","tta:default\n","\t score:0.5811(th=0.300000), auc=0.907487::: time:351.98s\n","tta:hflip\n","\t score:0.5605(th=0.200000), auc=0.902246::: time:376.35s\n","tta:vflip\n","\t score:0.5822(th=0.200000), auc=0.904747::: time:400.67s\n","slide pos: [128, 0]\n","tta:default\n","\t score:0.6081(th=0.250000), auc=0.916447::: time:425.31s\n","tta:hflip\n","\t score:0.5767(th=0.200000), auc=0.907924::: time:449.94s\n","tta:vflip\n","\t score:0.6016(th=0.200000), auc=0.911261::: time:474.84s\n","slide pos: [0, 128]\n","tta:default\n","\t score:0.5592(th=0.250000), auc=0.908178::: time:499.16s\n","tta:hflip\n","\t score:0.5478(th=0.200000), auc=0.904833::: time:523.87s\n","tta:vflip\n","\t score:0.5851(th=0.200000), auc=0.906484::: time:548.37s\n","slide pos: [128, 128]\n","tta:default\n","\t score:0.5933(th=0.300000), auc=0.916983::: time:573.31s\n","tta:hflip\n","\t score:0.5654(th=0.200000), auc=0.912630::: time:597.31s\n","tta:vflip\n","\t score:0.5993(th=0.200000), auc=0.913710::: time:621.70s\n","surface_list:  [29, 32, 35, 38]\n","slide pos: [0, 0]\n","tta:default\n","\t score:0.5472(th=0.200000), auc=0.896113::: time:655.03s\n","tta:hflip\n","\t score:0.5036(th=0.150000), auc=0.885657::: time:679.02s\n","tta:vflip\n","\t score:0.5110(th=0.200000), auc=0.891771::: time:702.98s\n","slide pos: [128, 0]\n","tta:default\n","\t score:0.5799(th=0.250000), auc=0.902078::: time:727.63s\n","tta:hflip\n","\t score:0.5408(th=0.200000), auc=0.891135::: time:751.74s\n","tta:vflip\n","\t score:0.5517(th=0.200000), auc=0.897824::: time:776.16s\n","slide pos: [0, 128]\n","tta:default\n","\t score:0.5188(th=0.200000), auc=0.897409::: time:800.50s\n","tta:hflip\n","\t score:0.4821(th=0.150000), auc=0.893259::: time:824.79s\n","tta:vflip\n","\t score:0.4701(th=0.150000), auc=0.895624::: time:849.27s\n","slide pos: [128, 128]\n","tta:default\n","\t score:0.5506(th=0.200000), auc=0.901669::: time:873.97s\n","tta:hflip\n","\t score:0.5153(th=0.150000), auc=0.897160::: time:898.49s\n","tta:vflip\n","\t score:0.5188(th=0.200000), auc=0.898083::: time:922.93s\n","surface_list:  [27, 30, 33, 36]\n","slide pos: [0, 0]\n","tta:default\n","\t score:0.5714(th=0.300000), auc=0.908421::: time:955.23s\n","tta:hflip\n","\t score:0.5572(th=0.200000), auc=0.900917::: time:979.41s\n","tta:vflip\n","\t score:0.5817(th=0.200000), auc=0.904038::: time:1003.63s\n","slide pos: [128, 0]\n","tta:default\n","\t score:0.6029(th=0.300000), auc=0.914507::: time:1028.14s\n","tta:hflip\n","\t score:0.5745(th=0.250000), auc=0.905069::: time:1052.49s\n","tta:vflip\n","\t score:0.5877(th=0.250000), auc=0.911161::: time:1076.60s\n","slide pos: [0, 128]\n","tta:default\n","\t score:0.5448(th=0.250000), auc=0.907732::: time:1101.07s\n","tta:hflip\n","\t score:0.5390(th=0.200000), auc=0.904202::: time:1125.42s\n","tta:vflip\n","\t score:0.5538(th=0.200000), auc=0.906010::: time:1149.79s\n","slide pos: [128, 128]\n","tta:default\n","\t score:0.5606(th=0.300000), auc=0.914678::: time:1174.34s\n","tta:hflip\n","\t score:0.5517(th=0.200000), auc=0.910060::: time:1198.73s\n","tta:vflip\n","\t score:0.5597(th=0.200000), auc=0.913452::: time:1222.87s\n","surface_list:  [28, 31, 34, 37]\n","slide pos: [0, 0]\n","tta:default\n","\t score:0.5652(th=0.300000), auc=0.903990::: time:1258.23s\n","tta:hflip\n","\t score:0.5524(th=0.200000), auc=0.895800::: time:1282.64s\n","tta:vflip\n","\t score:0.5556(th=0.200000), auc=0.898588::: time:1307.02s\n","slide pos: [128, 0]\n","tta:default\n","\t score:0.6027(th=0.300000), auc=0.907190::: time:1331.45s\n","tta:hflip\n","\t score:0.5711(th=0.200000), auc=0.898774::: time:1355.69s\n","tta:vflip\n","\t score:0.5742(th=0.200000), auc=0.905491::: time:1380.21s\n","slide pos: [0, 128]\n","tta:default\n","\t score:0.5403(th=0.200000), auc=0.904556::: time:1404.80s\n","tta:hflip\n","\t score:0.5108(th=0.200000), auc=0.900087::: time:1429.30s\n","tta:vflip\n","\t score:0.5195(th=0.200000), auc=0.900894::: time:1453.63s\n","slide pos: [128, 128]\n","tta:default\n","\t score:0.5672(th=0.300000), auc=0.908209::: time:1478.19s\n","tta:hflip\n","\t score:0.5490(th=0.200000), auc=0.903899::: time:1502.63s\n","tta:vflip\n","\t score:0.5491(th=0.250000), auc=0.906411::: time:1527.10s\n","[fold0] slice ave score:0.6168(th=0.200000), auc=0.923646\n","-- fold1 slide inference start --\n","surface_list:  [30, 33, 36, 39]\n","slide pos: [0, 0]\n","tta:default\n","\t score:0.5939(th=0.250000), auc=0.875200::: time:1580.17s\n","tta:hflip\n","\t score:0.5927(th=0.200000), auc=0.875488::: time:1613.30s\n","tta:vflip\n","\t score:0.6116(th=0.300000), auc=0.875003::: time:1646.10s\n","slide pos: [128, 0]\n","tta:default\n","\t score:0.5804(th=0.250000), auc=0.822897::: time:1677.91s\n","tta:hflip\n","\t score:0.5724(th=0.200000), auc=0.823851::: time:1709.94s\n","tta:vflip\n","\t score:0.5777(th=0.250000), auc=0.827082::: time:1741.93s\n","slide pos: [0, 128]\n","tta:default\n","\t score:0.5892(th=0.250000), auc=0.870446::: time:1775.49s\n","tta:hflip\n","\t score:0.5892(th=0.250000), auc=0.871866::: time:1808.28s\n","tta:vflip\n","\t score:0.6025(th=0.250000), auc=0.871307::: time:1841.66s\n","slide pos: [128, 128]\n","tta:default\n","\t score:0.5659(th=0.250000), auc=0.825534::: time:1874.02s\n","tta:hflip\n","\t score:0.5691(th=0.200000), auc=0.828902::: time:1906.42s\n","tta:vflip\n","\t score:0.5898(th=0.250000), auc=0.831696::: time:1939.05s\n","surface_list:  [26, 29, 32, 35]\n","slide pos: [0, 0]\n","tta:default\n","\t score:0.6130(th=0.250000), auc=0.878802::: time:1976.90s\n","tta:hflip\n","\t score:0.6109(th=0.250000), auc=0.878861::: time:2010.35s\n","tta:vflip\n","\t score:0.6121(th=0.300000), auc=0.876222::: time:2044.07s\n","slide pos: [128, 0]\n","tta:default\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_1722/1517537277.py\u001b[0m in \u001b[0;36mslide_inference\u001b[0;34m(CFG, tta_list)\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;31m# target, predをconcatして元のサイズに戻す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mvalid_preds_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_targets_img\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mconcat_grid_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_grid_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslide_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mvalid_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_targets_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_preds_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mvalid_preds_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_preds_img\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mvalid_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;31m# save_and_plot_oof(\"slide_tta_add\", fold, slice_idx, valid_preds_img, valid_targets_img, valid_preds_binary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_1722/963134502.py\u001b[0m in \u001b[0;36mcalc_cv\u001b[0;34m(mask_gt, mask_pred)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mbest_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_fbeta_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_1722/963134502.py\u001b[0m in \u001b[0;36mcalc_fbeta_auc\u001b[0;34m(mask, mask_pred)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mbest_th\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         )\n\u001b[1;32m    574\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    340\u001b[0m         )\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    961\u001b[0m     \"\"\"\n\u001b[1;32m    962\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 963\u001b[0;31m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0;31m# sort scores and corresponding truth values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m     \u001b[0mdesc_score_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mergesort\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdesc_score_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdesc_score_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margsort\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \"\"\"\n\u001b[0;32m-> 1114\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%%time\n","tta_list = [\"default\", \"hflip\", \"vflip\"]\n","# tta_list = [\"hfvlip\", \"vhflip\"]\n","slice_ave_score_list, slice_ave_auc_list, slice_ave_score_threshold_list = slide_inference(CFG, tta_list)\n","for fold in CFG[\"folds\"]:\n","    print(f\"fold[{fold}] slice ave score:{slice_ave_score_list[fold]:.4f}(th={slice_ave_score_threshold_list[fold]:3f}), auc={slice_ave_auc_list[fold]:4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","OUTPUT_DIR = CFG[\"OUTPUT_DIR\"]\n","pred_flatten_list = []\n","mask_flatten_list = []\n","for fold in [0,1,2,3,4]:\n","    # mask_path = os.path.join(OUTPUT_DIR, \"imgs\", f\"fold{fold}_average_tta3_spos_slice555_valid_targets_img.png\")\n","    valid_dir_list = CFG[\"VALID_DIR_LIST\"][fold]\n","    mask_path = os.path.join(CFG[\"TRAIN_DIR\"], valid_dir_list[0], \"inklabels.png\")\n","    pred_path = os.path.join(OUTPUT_DIR, \"imgs\", f\"fold{fold}_tta_add_average_layer_slice555_valid_pred_img.png\")\n","    pred_img = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n","    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","    print(pred_img.shape) \n","    print(mask_img.shape)\n","    plt.figure()\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(pred_img)\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(mask_img)\n","    plt.show()\n","    pred_flatten_list.extend(pred_img.flatten())\n","    mask_flatten_list.extend(mask_img.flatten())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mask_flatten_list = np.array(mask_flatten_list)/255.\n","mask = np.array(mask_flatten_list).astype(int)\n","pred = np.array(pred_flatten_list)/255.\n","\n","plt.figure()\n","plt.subplot(1, 2, 1)\n","plt.hist(pred, bins=100)\n","plt.subplot(1, 2, 2)\n","plt.hist(mask)\n","plt.show()\n","\n","for th in np.array(range(10, 100+1, 5)) / 100:\n","    dice = fbeta_numpy(mask, (pred >= th).astype(int), beta=0.5)\n","    print(f\"th={th:.2f}, dice={dice:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
