{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de1871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T10:58:47.555511Z",
     "iopub.status.busy": "2023-04-29T10:58:47.554880Z",
     "iopub.status.idle": "2023-04-29T10:58:53.012527Z",
     "shell.execute_reply": "2023-04-29T10:58:53.011340Z"
    },
    "papermill": {
     "duration": 5.473346,
     "end_time": "2023-04-29T10:58:53.015145",
     "exception": false,
     "start_time": "2023-04-29T10:58:47.541799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "import sys\n",
    "import gc\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as albu\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import KFold, StratifiedGroupKFold, StratifiedKFold\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca276139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T10:58:53.037500Z",
     "iopub.status.busy": "2023-04-29T10:58:53.036936Z",
     "iopub.status.idle": "2023-04-29T10:58:53.044392Z",
     "shell.execute_reply": "2023-04-29T10:58:53.043293Z"
    },
    "papermill": {
     "duration": 0.020968,
     "end_time": "2023-04-29T10:58:53.046427",
     "exception": false,
     "start_time": "2023-04-29T10:58:53.025459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_train = True\n",
    "\n",
    "EXP_NAME = \"expy001\"\n",
    "ROOT_DIR = Path(\"/working\")\n",
    "DATA_DIR = Path(\"/working/input/vesuvius-challenge-ink-detection\")\n",
    "OUTPUT_DIR = Path(f\"/working/output/{EXP_NAME}\")\n",
    "\n",
    "def to_pickle(filename, obj):\n",
    "    with open(filename, mode=\"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def unpickle(filename):\n",
    "    with open(filename, mode=\"rb\") as fo:\n",
    "        p = pickle.load(fo)\n",
    "    return p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9077ff3",
   "metadata": {
    "papermill": {
     "duration": 0.010872,
     "end_time": "2023-04-29T10:58:53.066929",
     "exception": false,
     "start_time": "2023-04-29T10:58:53.056057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61370a7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T10:58:53.087880Z",
     "iopub.status.busy": "2023-04-29T10:58:53.087544Z",
     "iopub.status.idle": "2023-04-29T10:58:53.099798Z",
     "shell.execute_reply": "2023-04-29T10:58:53.098667Z"
    },
    "papermill": {
     "duration": 0.0259,
     "end_time": "2023-04-29T10:58:53.102572",
     "exception": false,
     "start_time": "2023-04-29T10:58:53.076672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "print(\"cpu count:\", multiprocessing.cpu_count())\n",
    "\n",
    "\n",
    "class Config:\n",
    "    N_LABEL = 10\n",
    "    N_FOLD = 5\n",
    "    RANDOM_SATE = 42\n",
    "    LR = 2.0e-03\n",
    "    MAX_LR = 2.0e-3\n",
    "    PATIENCE = 50\n",
    "    EPOCH = 35\n",
    "    BATCH_SIZE = 4\n",
    "    SKIP_EVALUATE_NUM = 0\n",
    "    BACK_BONE = \"seresnext50_32x4d\"\n",
    "    RUN_FOLD_COUNT = 10\n",
    "    IMG_SIZE = 672\n",
    "    T_MAX = 8\n",
    "    ETA_MIN = 1.0e-3\n",
    "    SCHEDULER_GAMMA = 1.0\n",
    "    ACCUMULATION_STEMP = 2\n",
    "    NUM_WORKERS = multiprocessing.cpu_count()\n",
    "    IN_CHANNELS = 4\n",
    "    PREDICT_STRIDE = 10\n",
    "\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(seed=Config.RANDOM_SATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9241bdb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T10:58:53.123436Z",
     "iopub.status.busy": "2023-04-29T10:58:53.123133Z",
     "iopub.status.idle": "2023-04-29T10:58:53.132174Z",
     "shell.execute_reply": "2023-04-29T10:58:53.131035Z"
    },
    "papermill": {
     "duration": 0.022251,
     "end_time": "2023-04-29T10:58:53.134730",
     "exception": false,
     "start_time": "2023-04-29T10:58:53.112479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "glob.glob(str(DATA_DIR / \"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc7f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T10:58:53.156516Z",
     "iopub.status.busy": "2023-04-29T10:58:53.156207Z",
     "iopub.status.idle": "2023-04-29T10:58:53.163475Z",
     "shell.execute_reply": "2023-04-29T10:58:53.162343Z"
    },
    "papermill": {
     "duration": 0.02091,
     "end_time": "2023-04-29T10:58:53.165629",
     "exception": false,
     "start_time": "2023-04-29T10:58:53.144719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def rle(output, thr):\n",
    "    flat_img = np.where(output > thr, 1, 0).astype(np.uint8)\n",
    "    starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n",
    "    ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n",
    "    starts_ix = np.where(starts)[0] + 2\n",
    "    ends_ix = np.where(ends)[0] + 2\n",
    "    lengths = ends_ix - starts_ix\n",
    "    return starts_ix, lengths\n",
    "\n",
    "\n",
    "def concat_tile(im_list_2d):\n",
    "    return cv2.vconcat([cv2.hconcat(im_list_h) for im_list_h in im_list_2d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5723fb24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T10:58:53.187577Z",
     "iopub.status.busy": "2023-04-29T10:58:53.186549Z",
     "iopub.status.idle": "2023-04-29T10:58:53.195332Z",
     "shell.execute_reply": "2023-04-29T10:58:53.194075Z"
    },
    "papermill": {
     "duration": 0.021926,
     "end_time": "2023-04-29T10:58:53.197585",
     "exception": false,
     "start_time": "2023-04-29T10:58:53.175659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mid = 65 // 2\n",
    "start = mid - Config.IN_CHANNELS * 3 // 2\n",
    "end = mid + Config.IN_CHANNELS * 3 // 2\n",
    "idxs = range(start, end, 3)\n",
    "print([i for i in idxs])\n",
    "\n",
    "idxs2 = range(start - 1, end - 1, 3)\n",
    "print([i for i in idxs2])\n",
    "\n",
    "idxs3 = range(start + 1, end + 1, 3)\n",
    "print([i for i in idxs3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ef66a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T10:58:53.219952Z",
     "iopub.status.busy": "2023-04-29T10:58:53.219238Z",
     "iopub.status.idle": "2023-04-29T10:58:55.905254Z",
     "shell.execute_reply": "2023-04-29T10:58:55.904000Z"
    },
    "papermill": {
     "duration": 2.700028,
     "end_time": "2023-04-29T10:58:55.908179",
     "exception": false,
     "start_time": "2023-04-29T10:58:53.208151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "\n",
    "img = mms.fit_transform(cv2.imread(str(DATA_DIR / f\"train/2/ir.png\"), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f91e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T10:58:55.929925Z",
     "iopub.status.busy": "2023-04-29T10:58:55.929595Z",
     "iopub.status.idle": "2023-04-29T10:58:55.934604Z",
     "shell.execute_reply": "2023-04-29T10:58:55.933564Z"
    },
    "papermill": {
     "duration": 0.018297,
     "end_time": "2023-04-29T10:58:55.936836",
     "exception": false,
     "start_time": "2023-04-29T10:58:55.918539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "e = math.e\n",
    "def sigmoid(a):\n",
    "    s = 1 / (1 + e**-a)\n",
    "    return s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78a03b10",
   "metadata": {},
   "source": [
    "# Load imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08efbc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T10:58:55.959624Z",
     "iopub.status.busy": "2023-04-29T10:58:55.958800Z",
     "iopub.status.idle": "2023-04-29T11:01:05.790759Z",
     "shell.execute_reply": "2023-04-29T11:01:05.789549Z"
    },
    "papermill": {
     "duration": 129.846065,
     "end_time": "2023-04-29T11:01:05.793224",
     "exception": false,
     "start_time": "2023-04-29T10:58:55.947159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_train:\n",
    "\n",
    "    img1 = []\n",
    "    for i in tqdm(idxs):\n",
    "        img1.append(cv2.imread(str(DATA_DIR / f\"train/1/surface_volume/{i:02}.tif\"), 0))\n",
    "\n",
    "    img2 = []\n",
    "    for i in tqdm(idxs):\n",
    "        img2.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/2/surface_volume/{i:02}.tif\"), 0)[\n",
    "                0:4943, :\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    img3 = []\n",
    "    for i in tqdm(idxs):\n",
    "        img3.append(cv2.imread(str(DATA_DIR / f\"train/3/surface_volume/{i:02}.tif\"), 0))\n",
    "\n",
    "    img4 = []\n",
    "    for i in tqdm(idxs):\n",
    "        img4.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/2/surface_volume/{i:02}.tif\"), 0)[\n",
    "                4943:9886, :\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    img5 = []\n",
    "    for i in tqdm(idxs):\n",
    "        img5.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/2/surface_volume/{i:02}.tif\"), 0)[\n",
    "                9886:, :\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    img1 = np.stack(img1)\n",
    "    img2 = np.stack(img2)\n",
    "    img3 = np.stack(img3)\n",
    "    img4 = np.stack(img4)\n",
    "    img5 = np.stack(img5)\n",
    "\n",
    "    img1_1 = []\n",
    "    for i in tqdm(idxs2):\n",
    "        img1_1.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/1/surface_volume/{i:02}.tif\"), 0)\n",
    "        )\n",
    "\n",
    "    img2_1 = []\n",
    "    for i in tqdm(idxs2):\n",
    "        img2_1.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/2/surface_volume/{i:02}.tif\"), 0)[\n",
    "                0:4943, :\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    img3_1 = []\n",
    "    for i in tqdm(idxs2):\n",
    "        img3_1.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/3/surface_volume/{i:02}.tif\"), 0)\n",
    "        )\n",
    "\n",
    "    img4_1 = []\n",
    "    for i in tqdm(idxs):\n",
    "        img4_1.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/2/surface_volume/{i:02}.tif\"), 0)[\n",
    "                4943:9886, :\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    img5_1 = []\n",
    "    for i in tqdm(idxs):\n",
    "        img5_1.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/2/surface_volume/{i:02}.tif\"), 0)[\n",
    "                9886:, :\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    img1_1 = np.stack(img1_1)\n",
    "    img2_1 = np.stack(img2_1)\n",
    "    img3_1 = np.stack(img3_1)\n",
    "    img4_1 = np.stack(img4_1)\n",
    "    img5_1 = np.stack(img5_1)\n",
    "\n",
    "    img1_2 = []\n",
    "    for i in tqdm(idxs3):\n",
    "        img1_2.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/1/surface_volume/{i:02}.tif\"), 0)\n",
    "        )\n",
    "\n",
    "    img2_2 = []\n",
    "    for i in tqdm(idxs3):\n",
    "        img2_2.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/2/surface_volume/{i:02}.tif\"), 0)[\n",
    "                0:4943, :\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    img3_2 = []\n",
    "    for i in tqdm(idxs3):\n",
    "        img3_2.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/3/surface_volume/{i:02}.tif\"), 0)\n",
    "        )\n",
    "\n",
    "    img4_2 = []\n",
    "    for i in tqdm(idxs):\n",
    "        img4_2.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/2/surface_volume/{i:02}.tif\"), 0)[\n",
    "                4943:9886, :\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    img5_2 = []\n",
    "    for i in tqdm(idxs):\n",
    "        img5_2.append(\n",
    "            cv2.imread(str(DATA_DIR / f\"train/2/surface_volume/{i:02}.tif\"), 0)[\n",
    "                9886:, :\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    img1_2 = np.stack(img1_2)\n",
    "    img2_2 = np.stack(img2_2)\n",
    "    img3_2 = np.stack(img3_2)\n",
    "    img4_2 = np.stack(img4_2)\n",
    "    img5_2 = np.stack(img5_2)\n",
    "\n",
    "    img1_label = cv2.imread(str(DATA_DIR / f\"train/1/inklabels.png\"), 0)\n",
    "    img2_label = cv2.imread(str(DATA_DIR / f\"train/2/inklabels.png\"), 0)[0:4943, :]\n",
    "    img3_label = cv2.imread(str(DATA_DIR / f\"train/3/inklabels.png\"), 0)\n",
    "    img4_label = cv2.imread(str(DATA_DIR / f\"train/2/inklabels.png\"), 0)[4943:9886, :]\n",
    "    img5_label = cv2.imread(str(DATA_DIR / f\"train/2/inklabels.png\"), 0)[9886:, :]\n",
    "\n",
    "\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    img1_ir = abs(mms.fit_transform(cv2.imread(str(DATA_DIR / f\"train/1/ir.png\"), 0))-1) * cv2.imread(str(DATA_DIR / f\"train/1/inklabels.png\"), 0)\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    img2_ir = (abs(mms.fit_transform(cv2.imread(str(DATA_DIR / f\"train/2/ir.png\"), 0))-1) * cv2.imread(str(DATA_DIR / f\"train/2/inklabels.png\"), 0))[0:4943, :]\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    img3_ir = abs(mms.fit_transform(cv2.imread(str(DATA_DIR / f\"train/3/ir.png\"), 0))-1) * cv2.imread(str(DATA_DIR / f\"train/3/inklabels.png\"), 0)\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    img4_ir = (abs(mms.fit_transform(cv2.imread(str(DATA_DIR / f\"train/2/ir.png\"), 0))-1) * cv2.imread(str(DATA_DIR / f\"train/2/inklabels.png\"), 0))[4943:9886, :]\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    img5_ir = (abs(mms.fit_transform(cv2.imread(str(DATA_DIR / f\"train/2/ir.png\"), 0))-1) * cv2.imread(str(DATA_DIR / f\"train/2/inklabels.png\"), 0))[9886:, :]\n",
    "    \n",
    "    img1_mask = cv2.imread(str(DATA_DIR / f\"train/1/mask.png\"), 0)\n",
    "    img2_mask = cv2.imread(str(DATA_DIR / f\"train/2/mask.png\"), 0)[0:4943, :]\n",
    "    img3_mask = cv2.imread(str(DATA_DIR / f\"train/3/mask.png\"), 0)\n",
    "    img4_mask = cv2.imread(str(DATA_DIR / f\"train/2/mask.png\"), 0)[4943:9886, :]\n",
    "    img5_mask = cv2.imread(str(DATA_DIR / f\"train/2/mask.png\"), 0)[9886:, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71ba5056",
   "metadata": {
    "papermill": {
     "duration": 0.015045,
     "end_time": "2023-04-29T11:01:05.824480",
     "exception": false,
     "start_time": "2023-04-29T11:01:05.809435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1aa3da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T11:01:05.857456Z",
     "iopub.status.busy": "2023-04-29T11:01:05.856447Z",
     "iopub.status.idle": "2023-04-29T11:01:05.866118Z",
     "shell.execute_reply": "2023-04-29T11:01:05.865153Z"
    },
    "papermill": {
     "duration": 0.028216,
     "end_time": "2023-04-29T11:01:05.868211",
     "exception": false,
     "start_time": "2023-04-29T11:01:05.839995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_augmentation():\n",
    "    train_transform = [\n",
    "        albu.Resize(height=Config.IMG_SIZE, width=Config.IMG_SIZE),\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.5),\n",
    "        albu.RandomBrightnessContrast(p=0.75),\n",
    "        albu.ShiftScaleRotate(p=0.75, scale_limit=0.2),\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.GaussNoise(var_limit=[20, 100]),\n",
    "                albu.GaussianBlur(),\n",
    "                albu.MotionBlur(),\n",
    "            ],\n",
    "            p=0.3,\n",
    "        ),\n",
    "        albu.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        albu.CoarseDropout(\n",
    "            max_holes=1,\n",
    "            max_width=int(Config.IMG_SIZE * 0.3),\n",
    "            max_height=int(Config.IMG_SIZE * 0.3),\n",
    "            mask_fill_value=0,\n",
    "            p=0.5,\n",
    "        ),\n",
    "        # albu.Cutout(max_h_size=int(size * 0.6),\n",
    "        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "        albu.Normalize(mean=[0] * Config.IN_CHANNELS, std=[1] * Config.IN_CHANNELS),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_test_augmentation():\n",
    "    train_transform = [\n",
    "        albu.Resize(height=Config.IMG_SIZE, width=Config.IMG_SIZE),\n",
    "        albu.Normalize(mean=[0] * Config.IN_CHANNELS, std=[1] * Config.IN_CHANNELS),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487bdc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T11:01:05.900613Z",
     "iopub.status.busy": "2023-04-29T11:01:05.900290Z",
     "iopub.status.idle": "2023-04-29T11:01:05.920288Z",
     "shell.execute_reply": "2023-04-29T11:01:05.919247Z"
    },
    "papermill": {
     "duration": 0.038776,
     "end_time": "2023-04-29T11:01:05.922392",
     "exception": false,
     "start_time": "2023-04-29T11:01:05.883616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CVDataSet(Dataset):\n",
    "    def __init__(self, imgs, transforms, labels=None, data_type=None, crop_size=256):\n",
    "        self.crop_size = crop_size\n",
    "        self.imgs = imgs\n",
    "        self.transforms = transforms\n",
    "        self.labels = labels\n",
    "        self.data_type = data_type\n",
    "\n",
    "        self.cell_counts = []\n",
    "        for img in self.imgs:\n",
    "            cell_count = math.ceil(img.shape[1] / self.crop_size) * math.ceil(\n",
    "                img.shape[2] / self.crop_size\n",
    "            )\n",
    "            self.cell_counts.append(cell_count)\n",
    "\n",
    "    def __len__(self):\n",
    "        data_count = 0\n",
    "        if self.data_type == \"train\":\n",
    "\n",
    "            self.cell_id_maps = {}\n",
    "\n",
    "            counter = 0\n",
    "            for img_num, img in enumerate(self.imgs):\n",
    "\n",
    "                cell_count = math.ceil(img.shape[1] / self.crop_size) * math.ceil(\n",
    "                    img.shape[2] / self.crop_size\n",
    "                )\n",
    "                for cell_id in range(cell_count):\n",
    "                    h_num = cell_id // math.ceil(\n",
    "                        self.labels[img_num].shape[1] / self.crop_size\n",
    "                    )\n",
    "                    w_num = cell_id - (\n",
    "                        h_num\n",
    "                        * math.ceil(self.labels[img_num].shape[1] / self.crop_size)\n",
    "                    )\n",
    "\n",
    "                    cropped_img = self.labels[img_num][\n",
    "                        h_num * self.crop_size : h_num * self.crop_size\n",
    "                        + self.crop_size,\n",
    "                        w_num * self.crop_size : w_num * self.crop_size\n",
    "                        + self.crop_size,\n",
    "                    ]\n",
    "\n",
    "                    if cropped_img.sum() == 0:\n",
    "                        continue\n",
    "\n",
    "                    data_count += 1\n",
    "\n",
    "                    self.cell_id_maps[counter] = (img_num, cell_id)\n",
    "                    counter += 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            for img in self.imgs:\n",
    "                data_count += math.ceil(img.shape[1] / self.crop_size) * math.ceil(\n",
    "                    img.shape[2] / self.crop_size\n",
    "                )\n",
    "        return data_count\n",
    "\n",
    "    def calc_img_num(self, idx):\n",
    "        cum_cell_count = 0\n",
    "        for i, cell_count in enumerate(self.cell_counts):\n",
    "            cum_cell_count += cell_count\n",
    "            if idx + 1 <= cum_cell_count:\n",
    "                return i, idx - (cum_cell_count - cell_count)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        shift_size = 0\n",
    "        if self.data_type == \"train\":\n",
    "            img_num, cell_id = self.cell_id_maps[idx]\n",
    "            if random.random() > 0.6:\n",
    "                shift_size = int(\n",
    "                    random.uniform(-(self.crop_size // 8), self.crop_size // 8)\n",
    "                )\n",
    "        else:\n",
    "            img_num, cell_id = self.calc_img_num(idx)\n",
    "\n",
    "        target_img = self.imgs[img_num]\n",
    "        if self.data_type != \"test\":\n",
    "            target_label = self.labels[img_num]\n",
    "\n",
    "        # print(target_label.shape)\n",
    "        target_img = np.moveaxis(target_img, 0, 2)\n",
    "        # target_label = np.moveaxis(target_label, 0, 2)\n",
    "        \n",
    "        h_num = cell_id // math.ceil(target_img.shape[1] / self.crop_size)\n",
    "        w_num = cell_id - (h_num * math.ceil(target_img.shape[1] / self.crop_size))\n",
    "\n",
    "        #\n",
    "        cropped_img = target_img[\n",
    "            max(h_num * self.crop_size + shift_size, 0) : h_num * self.crop_size\n",
    "            + self.crop_size\n",
    "            + shift_size,\n",
    "            max(w_num * self.crop_size + shift_size, 0) : w_num * self.crop_size\n",
    "            + self.crop_size\n",
    "            + shift_size,\n",
    "        ]\n",
    "\n",
    "        if self.data_type in [\"train\", \"valid\"]:\n",
    "            cropped_label = target_label[\n",
    "                max(h_num * self.crop_size + shift_size, 0) : h_num * self.crop_size\n",
    "                + self.crop_size\n",
    "                + shift_size,\n",
    "                max(w_num * self.crop_size + shift_size, 0) : w_num * self.crop_size\n",
    "                + self.crop_size\n",
    "                + shift_size,\n",
    "            ]\n",
    "            \"\"\"print('&&&')\n",
    "            print(cell_id)\n",
    "            print(h_num)\n",
    "            print(w_num)\n",
    "            print(target_img.shape)\n",
    "            print(cropped_img.shape)\n",
    "            print('%%%')\"\"\"\n",
    "            \n",
    "            #! ADD CLASS\n",
    "            target_class = (np.sum(cropped_label) > 0).astype(np.int32)\n",
    "            target_class = torch.tensor(target_class, dtype=torch.float32)\n",
    "    \n",
    "            #print(11111)\n",
    "            \n",
    "            #try:\n",
    "            augmented = self.transforms(image=cropped_img, mask=cropped_label)\n",
    "            img = augmented[\"image\"]\n",
    "            img = np.moveaxis(img, 2, 0)\n",
    "            mask = augmented[\"mask\"]\n",
    "            \n",
    "            \"\"\"except:\n",
    "                print(img_num)\n",
    "                print(h_num)\n",
    "                print(w_num)\n",
    "                print(shift_size)\n",
    "                print(cropped_img)\n",
    "                print(cropped_label)\"\"\"\n",
    "        else:\n",
    "            augmented = self.transforms(image=cropped_img)\n",
    "            img = augmented[\"image\"]\n",
    "            img = np.moveaxis(img, 2, 0)\n",
    "            mask = -1\n",
    "            target_class = -1\n",
    "            \n",
    "        return img, mask / 255, target_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c7d1b62",
   "metadata": {
    "papermill": {
     "duration": 0.014933,
     "end_time": "2023-04-29T11:01:05.952443",
     "exception": false,
     "start_time": "2023-04-29T11:01:05.937510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3b56f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T11:01:05.985186Z",
     "iopub.status.busy": "2023-04-29T11:01:05.984777Z",
     "iopub.status.idle": "2023-04-29T11:01:06.000229Z",
     "shell.execute_reply": "2023-04-29T11:01:05.999248Z"
    },
    "papermill": {
     "duration": 0.034599,
     "end_time": "2023-04-29T11:01:06.002408",
     "exception": false,
     "start_time": "2023-04-29T11:01:05.967809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "        self.defaults.update(self.base_optimizer.defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (\n",
    "                    (torch.pow(p, 2) if group[\"adaptive\"] else 1.0)\n",
    "                    * p.grad\n",
    "                    * scale.to(p)\n",
    "                )\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert (\n",
    "            closure is not None\n",
    "        ), \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(\n",
    "            closure\n",
    "        )  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][\n",
    "            0\n",
    "        ].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "            torch.stack(\n",
    "                [\n",
    "                    ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad)\n",
    "                    .norm(p=2)\n",
    "                    .to(shared_device)\n",
    "                    for group in self.param_groups\n",
    "                    for p in group[\"params\"]\n",
    "                    if p.grad is not None\n",
    "                ]\n",
    "            ),\n",
    "            p=2,\n",
    "        )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f02744e3",
   "metadata": {
    "papermill": {
     "duration": 0.014922,
     "end_time": "2023-04-29T11:01:06.032579",
     "exception": false,
     "start_time": "2023-04-29T11:01:06.017657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3464a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T11:01:06.064679Z",
     "iopub.status.busy": "2023-04-29T11:01:06.064334Z",
     "iopub.status.idle": "2023-04-29T11:01:06.088058Z",
     "shell.execute_reply": "2023-04-29T11:01:06.086897Z"
    },
    "papermill": {
     "duration": 0.042782,
     "end_time": "2023-04-29T11:01:06.090406",
     "exception": false,
     "start_time": "2023-04-29T11:01:06.047624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from timm import create_model\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone=Config.BACK_BONE,\n",
    "        backbone_kwargs=None,\n",
    "        backbone_indices=None,\n",
    "        decoder_use_batchnorm=True,\n",
    "        decoder_channels=(256, 128, 64, 32, 16),\n",
    "        in_chans=Config.IN_CHANNELS,\n",
    "        num_classes=1,\n",
    "        center=False,\n",
    "        norm_layer=nn.BatchNorm2d,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        backbone_kwargs = backbone_kwargs or {}\n",
    "        # NOTE some models need different backbone indices specified based on the alignment of features\n",
    "        # and some models won't have a full enough range of feature strides to work properly.\n",
    "        encoder = create_model(\n",
    "            backbone,\n",
    "            features_only=True,\n",
    "            out_indices=backbone_indices,\n",
    "            in_chans=in_chans,\n",
    "            pretrained=is_train,\n",
    "            **backbone_kwargs\n",
    "        )\n",
    "        encoder_channels = encoder.feature_info.channels()[::-1]\n",
    "        self.encoder = encoder\n",
    "\n",
    "        if not decoder_use_batchnorm:\n",
    "            norm_layer = None\n",
    "        self.decoder = UnetDecoder(\n",
    "            encoder_channels=encoder_channels,\n",
    "            decoder_channels=decoder_channels,\n",
    "            final_channels=num_classes,\n",
    "            norm_layer=norm_layer,\n",
    "            center=center,\n",
    "        )\n",
    "        \n",
    "        self.GAP = nn.AdaptiveAvgPool2d(output_size=(1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(encoder_channels[-1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.encoder(x)\n",
    "        # output class\n",
    "        emb = self.GAP(x[0])\n",
    "        output_class = self.classifier(torch.squeeze(emb))\n",
    "        x.reverse()  # torchscript doesn't work with [::-1]\n",
    "        x = self.decoder(x)\n",
    "        return x, output_class\n",
    "\n",
    "\n",
    "class Conv2dBnAct(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        padding=0,\n",
    "        stride=1,\n",
    "        act_layer=nn.ReLU,\n",
    "        norm_layer=nn.BatchNorm2d,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn = norm_layer(out_channels)\n",
    "        self.act = act_layer(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        scale_factor=2.0,\n",
    "        act_layer=nn.ReLU,\n",
    "        norm_layer=nn.BatchNorm2d,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        conv_args = dict(kernel_size=3, padding=1, act_layer=act_layer)\n",
    "        self.scale_factor = scale_factor\n",
    "        if norm_layer is None:\n",
    "            self.conv1 = Conv2dBnAct(in_channels, out_channels, **conv_args)\n",
    "            self.conv2 = Conv2dBnAct(out_channels, out_channels, **conv_args)\n",
    "        else:\n",
    "            self.conv1 = Conv2dBnAct(\n",
    "                in_channels, out_channels, norm_layer=norm_layer, **conv_args\n",
    "            )\n",
    "            self.conv2 = Conv2dBnAct(\n",
    "                out_channels, out_channels, norm_layer=norm_layer, **conv_args\n",
    "            )\n",
    "\n",
    "    def forward(self, x, skip: Optional[torch.Tensor] = None):\n",
    "        if self.scale_factor != 1.0:\n",
    "            x = F.interpolate(x, scale_factor=self.scale_factor, mode=\"nearest\")\n",
    "        if skip is not None:\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UnetDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_channels,\n",
    "        decoder_channels=(256, 128, 64, 32, 16),\n",
    "        final_channels=1,\n",
    "        norm_layer=nn.BatchNorm2d,\n",
    "        center=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if center:\n",
    "            channels = encoder_channels[0]\n",
    "            self.center = DecoderBlock(\n",
    "                channels, channels, scale_factor=1.0, norm_layer=norm_layer\n",
    "            )\n",
    "        else:\n",
    "            self.center = nn.Identity()\n",
    "\n",
    "        in_channels = [\n",
    "            in_chs + skip_chs\n",
    "            for in_chs, skip_chs in zip(\n",
    "                [encoder_channels[0]] + list(decoder_channels[:-1]),\n",
    "                list(encoder_channels[1:]) + [0],\n",
    "            )\n",
    "        ]\n",
    "        out_channels = decoder_channels\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for in_chs, out_chs in zip(in_channels, out_channels):\n",
    "            self.blocks.append(DecoderBlock(in_chs, out_chs, norm_layer=norm_layer))\n",
    "        self.final_conv = nn.Conv2d(\n",
    "            out_channels[-1], final_channels, kernel_size=(1, 1)\n",
    "        )\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x: List[torch.Tensor]):\n",
    "        encoder_head = x[0]\n",
    "        skips = x[1:]\n",
    "        x = self.center(encoder_head)\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            skip = skips[i] if i < len(skips) else None\n",
    "            x = b(x, skip)\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9b6273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T11:01:06.122466Z",
     "iopub.status.busy": "2023-04-29T11:01:06.121531Z",
     "iopub.status.idle": "2023-04-29T11:01:06.130745Z",
     "shell.execute_reply": "2023-04-29T11:01:06.129823Z"
    },
    "papermill": {
     "duration": 0.027593,
     "end_time": "2023-04-29T11:01:06.132862",
     "exception": false,
     "start_time": "2023-04-29T11:01:06.105269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, fold=\"\"):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "#             logger.info(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "            )\n",
    "#             logger.info(\n",
    "#                 f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "#             )\n",
    "        torch.save(model.state_dict(), OUTPUT_DIR / f\"{EXP_NAME}_{fold}.pt\")\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edc25614",
   "metadata": {
    "papermill": {
     "duration": 0.014945,
     "end_time": "2023-04-29T11:01:06.163269",
     "exception": false,
     "start_time": "2023-04-29T11:01:06.148324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d50b07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T11:01:06.195118Z",
     "iopub.status.busy": "2023-04-29T11:01:06.194710Z",
     "iopub.status.idle": "2023-04-29T11:01:09.036587Z",
     "shell.execute_reply": "2023-04-29T11:01:09.035514Z"
    },
    "papermill": {
     "duration": 2.860805,
     "end_time": "2023-04-29T11:01:09.039319",
     "exception": false,
     "start_time": "2023-04-29T11:01:06.178514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BCE_Mask = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([0.3]).cuda())\n",
    "# BCE_Class = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([0.3]).cuda())\n",
    "BCE_Mask = torch.nn.BCEWithLogitsLoss()\n",
    "BCE_Class = torch.nn.BCEWithLogitsLoss()\n",
    "def criterion(preds_class, targets_class, preds_mask, targets_mask):\n",
    "    return 0.1*BCE_Class(preds_class, targets_class) + 0.9*BCE_Mask(preds_mask, targets_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c159df2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T11:01:09.071244Z",
     "iopub.status.busy": "2023-04-29T11:01:09.070889Z",
     "iopub.status.idle": "2023-04-29T11:01:09.077457Z",
     "shell.execute_reply": "2023-04-29T11:01:09.076398Z"
    },
    "papermill": {
     "duration": 0.025906,
     "end_time": "2023-04-29T11:01:09.080643",
     "exception": false,
     "start_time": "2023-04-29T11:01:09.054737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fdac190",
   "metadata": {
    "papermill": {
     "duration": 0.015485,
     "end_time": "2023-04-29T11:01:09.111418",
     "exception": false,
     "start_time": "2023-04-29T11:01:09.095933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# set train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce65514",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T11:01:09.143900Z",
     "iopub.status.busy": "2023-04-29T11:01:09.143531Z",
     "iopub.status.idle": "2023-04-29T11:01:09.162259Z",
     "shell.execute_reply": "2023-04-29T11:01:09.161165Z"
    },
    "papermill": {
     "duration": 0.037791,
     "end_time": "2023-04-29T11:01:09.164481",
     "exception": false,
     "start_time": "2023-04-29T11:01:09.126690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_train:\n",
    "    data_set = []\n",
    "    data_set.append(\n",
    "        {\n",
    "            \"train_img\": [\n",
    "                img1,\n",
    "                img2,\n",
    "                img3,\n",
    "                img4,\n",
    "                img1_1,\n",
    "                img2_1,\n",
    "                img3_1,\n",
    "                img4_1,\n",
    "                img1_2,\n",
    "                img2_2,\n",
    "                img3_2,\n",
    "                img4_2,\n",
    "            ],\n",
    "            \"train_label\": [\n",
    "                img1_label,\n",
    "                img2_label,\n",
    "                img3_label,\n",
    "                img4_label,\n",
    "                img1_label,\n",
    "                img2_label,\n",
    "                img3_label,\n",
    "                img4_label,\n",
    "                img1_label,\n",
    "                img2_label,\n",
    "                img3_label,\n",
    "                img4_label,\n",
    "            ],\n",
    "            \"train_ir\": [\n",
    "                img1_ir,\n",
    "                img2_ir,\n",
    "                img3_ir,\n",
    "                img4_ir,\n",
    "                img1_ir,\n",
    "                img2_ir,\n",
    "                img3_ir,\n",
    "                img4_ir,\n",
    "                img1_ir,\n",
    "                img2_ir,\n",
    "                img3_ir,\n",
    "                img4_ir,\n",
    "            ],\n",
    "            \"valid_img\": [img5, img5_1, img5_2],\n",
    "            \"valid_label\": [img5_label],\n",
    "            \"valid_mask\": [img5_mask],\n",
    "            \"valid_img_num\": 1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    data_set.append(\n",
    "        {\n",
    "            \"train_img\": [\n",
    "                img1,\n",
    "                img2,\n",
    "                img3,\n",
    "                img5,\n",
    "                img1_1,\n",
    "                img2_1,\n",
    "                img3_1,\n",
    "                img5_1,\n",
    "                img1_2,\n",
    "                img2_2,\n",
    "                img3_2,\n",
    "                img5_2,\n",
    "            ],\n",
    "            \"train_label\": [\n",
    "                img1_label,\n",
    "                img2_label,\n",
    "                img3_label,\n",
    "                img5_label,\n",
    "                img1_label,\n",
    "                img2_label,\n",
    "                img3_label,\n",
    "                img5_label,\n",
    "                img1_label,\n",
    "                img2_label,\n",
    "                img3_label,\n",
    "                img5_label,\n",
    "            ],\n",
    "            \"train_ir\": [\n",
    "                img1_ir,\n",
    "                img2_ir,\n",
    "                img3_ir,\n",
    "                img5_ir,\n",
    "                img1_ir,\n",
    "                img2_ir,\n",
    "                img3_ir,\n",
    "                img5_ir,\n",
    "                img1_ir,\n",
    "                img2_ir,\n",
    "                img3_ir,\n",
    "                img5_ir,\n",
    "            ],\n",
    "            \"valid_img\": [img4, img4_1, img4_2],\n",
    "            \"valid_label\": [img4_label],\n",
    "            \"valid_mask\": [img4_mask],\n",
    "            \"valid_img_num\": 2,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    data_set.append(\n",
    "        {\n",
    "            \"train_img\": [\n",
    "                img1,\n",
    "                img2,\n",
    "                img4,\n",
    "                img5,\n",
    "                img1_1,\n",
    "                img2_1,\n",
    "                img4_1,\n",
    "                img5_1,\n",
    "                img1_2,\n",
    "                img2_2,\n",
    "                img4_2,\n",
    "                img5_2,\n",
    "            ],\n",
    "            \"train_label\": [\n",
    "                img1_label,\n",
    "                img2_label,\n",
    "                img4_label,\n",
    "                img5_label,\n",
    "                img1_label,\n",
    "                img2_label,\n",
    "                img4_label,\n",
    "                img5_label,\n",
    "                img1_label,\n",
    "                img2_label,\n",
    "                img4_label,\n",
    "                img5_label,\n",
    "            ],\n",
    "            \"train_ir\": [\n",
    "                img1_ir,\n",
    "                img2_ir,\n",
    "                img4_ir,\n",
    "                img5_ir,\n",
    "                img1_ir,\n",
    "                img2_ir,\n",
    "                img4_ir,\n",
    "                img5_ir,\n",
    "                img1_ir,\n",
    "                img2_ir,\n",
    "                img4_ir,\n",
    "                img5_ir,\n",
    "            ],\n",
    "            \"valid_img\": [img3, img3_1, img3_2],\n",
    "            \"valid_label\": [img3_label],\n",
    "            \"valid_mask\": [img3_mask],\n",
    "            \"valid_img_num\": 3,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    \n",
    "    data_set.append(\n",
    "        {\n",
    "            \"train_img\": [\n",
    "                img1,\n",
    "                img3,\n",
    "                img4,\n",
    "                img5,\n",
    "                img1_1,\n",
    "                img3_1,\n",
    "                img4_1,\n",
    "                img5_1,\n",
    "                img1_2,\n",
    "                img3_2,\n",
    "                img4_2,\n",
    "                img5_2,\n",
    "            ],\n",
    "            \"train_label\": [\n",
    "                img1_label,\n",
    "                img3_label,\n",
    "                img4_label,\n",
    "                img5_label,\n",
    "                img1_label,\n",
    "                img3_label,\n",
    "                img4_label,\n",
    "                img5_label,\n",
    "                img1_label,\n",
    "                img3_label,\n",
    "                img4_label,\n",
    "                img5_label,\n",
    "            ],\n",
    "            \"train_ir\": [\n",
    "                img1_ir,\n",
    "                img3_ir,\n",
    "                img4_ir,\n",
    "                img5_ir,\n",
    "                img1_ir,\n",
    "                img3_ir,\n",
    "                img4_ir,\n",
    "                img5_ir,\n",
    "                img1_ir,\n",
    "                img3_ir,\n",
    "                img4_ir,\n",
    "                img5_ir,\n",
    "            ],\n",
    "            \"valid_img\": [img2, img2_1, img2_2],\n",
    "            \"valid_label\": [img2_label],\n",
    "            \"valid_mask\": [img2_mask],\n",
    "            \"valid_img_num\": 4,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    \n",
    "    data_set.append(\n",
    "        {\n",
    "            \"train_img\": [\n",
    "                img2,\n",
    "                img3,\n",
    "                img4,\n",
    "                img5,\n",
    "                img2_1,\n",
    "                img3_1,\n",
    "                img4_1,\n",
    "                img5_1,\n",
    "                img2_2,\n",
    "                img3_2,\n",
    "                img4_2,\n",
    "                img5_2,\n",
    "            ],\n",
    "            \"train_label\": [\n",
    "                img2_label,\n",
    "                img3_label,\n",
    "                img4_label,\n",
    "                img5_label,\n",
    "                img2_label,\n",
    "                img3_label,\n",
    "                img4_label,\n",
    "                img5_label,\n",
    "                img2_label,\n",
    "                img3_label,\n",
    "                img4_label,\n",
    "                img5_label,\n",
    "            ],\n",
    "            \"train_ir\": [\n",
    "                img2_ir,\n",
    "                img3_ir,\n",
    "                img4_ir,\n",
    "                img5_ir,\n",
    "                img2_ir,\n",
    "                img3_ir,\n",
    "                img4_ir,\n",
    "                img5_ir,\n",
    "                img2_ir,\n",
    "                img3_ir,\n",
    "                img4_ir,\n",
    "                img5_ir,\n",
    "            ],\n",
    "            \"valid_img\": [img1, img1_1, img1_2],\n",
    "            \"valid_label\": [img1_label],\n",
    "            \"valid_mask\": [img1_mask],\n",
    "            \"valid_img_num\": 5,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6509c1f4",
   "metadata": {},
   "source": [
    "# check dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# valid_dataset = CVDataSet(\n",
    "#     [\n",
    "#         data_set[0][\"valid_img\"][0][\n",
    "#             :,\n",
    "#             (Config.IMG_SIZE // Config.PREDICT_STRIDE) * 0 :,\n",
    "#             (Config.IMG_SIZE // Config.PREDICT_STRIDE) * 0 :,\n",
    "#         ]\n",
    "#     ],\n",
    "#     get_test_augmentation(),\n",
    "#     labels=[\n",
    "#         data_set[0][\"valid_label\"][0][\n",
    "#             (Config.IMG_SIZE // Config.PREDICT_STRIDE) * 0 :,\n",
    "#             (Config.IMG_SIZE // Config.PREDICT_STRIDE) * 0 :,\n",
    "#         ]\n",
    "#     ],\n",
    "#     data_type=\"valid\",\n",
    "#     crop_size=Config.IMG_SIZE,\n",
    "# )\n",
    "\n",
    "# validloader = DataLoader(\n",
    "#     valid_dataset,\n",
    "#     batch_size=1,\n",
    "#     pin_memory=True,\n",
    "#     num_workers=0,\n",
    "# )\n",
    "# start_img_idx = 10\n",
    "# for i, (img, target_mask, target_class) in tqdm(enumerate(validloader), total=n_iter_val, smoothing=0):\n",
    "#     if i < start_img_idx:\n",
    "#         pass\n",
    "#     elif i > start_img_idx+10:\n",
    "#         break\n",
    "#     print(f\"idx={i}\")\n",
    "#     print(img.shape)\n",
    "#     print(target_mask.shape)\n",
    "#     print(target_class)\n",
    "#     img0 = img[0].numpy().transpose(1, 2, 0)\n",
    "#     target_mask0 = target_mask[0].numpy().transpose(0,1)\n",
    "#     target_class = target_class[0].numpy()\n",
    "#     plt.figure()\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(img0)\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.imshow(target_mask0)\n",
    "#     plt.title(f\"target_class={target_class}\")\n",
    "#     plt.show()\n",
    "# raise Exception(\"STOP\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4272d803",
   "metadata": {
    "papermill": {
     "duration": 0.015295,
     "end_time": "2023-04-29T11:01:09.195379",
     "exception": false,
     "start_time": "2023-04-29T11:01:09.180084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95ea08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T11:01:09.227945Z",
     "iopub.status.busy": "2023-04-29T11:01:09.227588Z",
     "iopub.status.idle": "2023-04-29T11:01:31.986863Z",
     "shell.execute_reply": "2023-04-29T11:01:31.985619Z"
    },
    "papermill": {
     "duration": 22.778943,
     "end_time": "2023-04-29T11:01:31.989502",
     "exception": false,
     "start_time": "2023-04-29T11:01:09.210559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if is_train:\n",
    "#     for fold in range(0, 5):\n",
    "#         print(f\"====== {fold} ======\")\n",
    "\n",
    "#         net = Unet()\n",
    "#         net.to(device)\n",
    "\n",
    "#         base_optimizer = optim.AdamW\n",
    "#         optimizer = SAM(\n",
    "#             net.parameters(), base_optimizer, lr=Config.LR, weight_decay=1.0e-02\n",
    "#         )\n",
    "\n",
    "#         train_dataset = CVDataSet(\n",
    "#             data_set[fold][\"train_img\"],\n",
    "#             get_augmentation(),\n",
    "#             labels=data_set[fold][\"train_label\"],\n",
    "#             data_type=\"train\",\n",
    "#             crop_size=Config.IMG_SIZE,\n",
    "#         )\n",
    "#         trainloader = DataLoader(\n",
    "#             train_dataset,\n",
    "#             batch_size=Config.BATCH_SIZE,\n",
    "#             pin_memory=True,\n",
    "#             shuffle=True,\n",
    "#             drop_last=True,\n",
    "#             num_workers=Config.NUM_WORKERS,\n",
    "#         )\n",
    "\n",
    "#         train_dataset_ir = CVDataSet(\n",
    "#             data_set[fold][\"train_img\"],\n",
    "#             get_augmentation(),\n",
    "#             labels=data_set[fold][\"train_ir\"],\n",
    "#             data_type=\"train\",\n",
    "#             crop_size=Config.IMG_SIZE,\n",
    "#         )\n",
    "#         trainloader_ir = DataLoader(\n",
    "#             train_dataset_ir,\n",
    "#             batch_size=Config.BATCH_SIZE,\n",
    "#             pin_memory=True,\n",
    "#             shuffle=True,\n",
    "#             drop_last=True,\n",
    "#             num_workers=Config.NUM_WORKERS,\n",
    "#         )\n",
    "\n",
    "        \n",
    "#         valid_dataloaders = []\n",
    "\n",
    "#         for j in range(Config.PREDICT_STRIDE):\n",
    "\n",
    "#             valid_dataset = CVDataSet(\n",
    "#                 [\n",
    "#                     data_set[fold][\"valid_img\"][0][\n",
    "#                         :,\n",
    "#                         (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                         (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                     ]\n",
    "#                 ],\n",
    "#                 get_test_augmentation(),\n",
    "#                 labels=[\n",
    "#                     data_set[fold][\"valid_label\"][0][\n",
    "#                         (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                         (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                     ]\n",
    "#                 ],\n",
    "#                 data_type=\"valid\",\n",
    "#                 crop_size=Config.IMG_SIZE,\n",
    "#             )\n",
    "\n",
    "#             validloader = DataLoader(\n",
    "#                 valid_dataset,\n",
    "#                 batch_size=Config.BATCH_SIZE,\n",
    "#                 pin_memory=True,\n",
    "#                 num_workers=Config.NUM_WORKERS,\n",
    "#             )\n",
    "#             valid_dataloaders.append(validloader)\n",
    "\n",
    "#         early_stopping = EarlyStopping(\n",
    "#             patience=Config.PATIENCE, verbose=True, fold=fold\n",
    "#         )\n",
    "\n",
    "#         scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "#             optimizer,\n",
    "#             epochs=Config.EPOCH,\n",
    "#             steps_per_epoch=len(trainloader),\n",
    "#             max_lr=Config.MAX_LR,\n",
    "#             pct_start=0.1,\n",
    "#             anneal_strategy=\"cos\",\n",
    "#             div_factor=1.0e2,\n",
    "#             final_div_factor=5,\n",
    "#         )\n",
    "\n",
    "#         val_metrics = []\n",
    "#         learning_rates = []\n",
    "\n",
    "#         for epoch in range(Config.EPOCH):\n",
    "\n",
    "#             running_loss = 0.0\n",
    "#             train_rmse_list = []\n",
    "            \n",
    "#             if epoch < 20:\n",
    "#                 loader = trainloader_ir\n",
    "#             else:\n",
    "#                 loader = trainloader\n",
    "        \n",
    "#             n_iter = len(loader)\n",
    "#             with tqdm(enumerate(loader), total=n_iter) as pbar:\n",
    "#                 #! ADD CLASS\n",
    "#                 for i, (img, target_mask, target_class) in pbar:\n",
    "\n",
    "#                     net.train()\n",
    "#                     #! ADD CLASS                    \n",
    "#                     img, target_mask, target_class = img.to(device).float(), target_mask.to(device).float(), target_class.to(device).float().view(-1,1)\n",
    "#                     outputs_mask, outputs_class = net(img)\n",
    "#                     loss = criterion(outputs_class, target_class, outputs_mask.squeeze(), target_mask)\n",
    "                    \n",
    "#                     loss.backward()  # Backward pass\n",
    "#                     optimizer.first_step(zero_grad=True)\n",
    "\n",
    "#                     outputs_mask, outputs_class = net(img)\n",
    "#                     criterion(outputs_class, target_class, outputs_mask.squeeze(), target_mask).backward()\n",
    "\n",
    "#                     optimizer.second_step(zero_grad=True)\n",
    "#                     net.zero_grad()\n",
    "\n",
    "#                     # print statistics\n",
    "#                     running_loss += loss.item()\n",
    "\n",
    "#                     outputs_np = outputs_mask.to(\"cpu\").detach().numpy().copy()\n",
    "\n",
    "#                     pbar.set_postfix(\n",
    "#                         OrderedDict(\n",
    "#                             epoch=\"{:>10}\".format(epoch),\n",
    "#                             loss=\"{:.4f}\".format(loss.item()),\n",
    "#                         )\n",
    "#                     )\n",
    "#                     scheduler.step()\n",
    "\n",
    "#             pred_tile_imgs = []\n",
    "#             for j, validloader in enumerate(valid_dataloaders):\n",
    "\n",
    "#                 ## shift test\n",
    "#                 val_preds = []\n",
    "#                 val_class = []\n",
    "#                 valid_targets = []\n",
    "                \n",
    "#                 n_iter_val = len(validloader)\n",
    "#                 #! ADD CLASS\n",
    "#                 for i, (img, target_mask, target_class) in tqdm(\n",
    "#                     enumerate(validloader), total=n_iter_val, smoothing=0\n",
    "#                 ):\n",
    "#                     net.eval()\n",
    "\n",
    "#                     with torch.no_grad():\n",
    "#                         #! ADD CLASS\n",
    "#                         img, target_mask, target_class = (\n",
    "#                                         img.to(device).float(),\n",
    "#                                         target_mask.to(device).float(),\n",
    "#                                         target_class.to(device).float().view(-1,1),\n",
    "#                                     )\n",
    "#                         outputs_mask, outputs_class  = net(img)\n",
    "#                         outputs_mask = outputs_mask.sigmoid()\n",
    "                        \n",
    "#                         outputs_np = outputs_mask.to(\"cpu\").detach().numpy().copy()\n",
    "#                         outputs_class = outputs_class.detach().cpu().numpy().ravel().tolist()\n",
    "                        \n",
    "#                         val_preds.append(outputs_np)\n",
    "#                         val_class.append(outputs_class)\n",
    "#                         valid_targets.append(target_mask.to(\"cpu\").detach().numpy().copy())\n",
    "\n",
    "#                 ## 端を切る\n",
    "#                 w_count = math.ceil(\n",
    "#                     data_set[fold][\"valid_label\"][0][\n",
    "#                         (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                         (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                     ].shape[1]\n",
    "#                     / Config.IMG_SIZE\n",
    "#                 )\n",
    "#                 h_count = math.ceil(\n",
    "#                     data_set[fold][\"valid_label\"][0][\n",
    "#                         (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                         (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                     ].shape[0]\n",
    "#                     / Config.IMG_SIZE\n",
    "#                 )\n",
    "\n",
    "#                 tile_arry = []\n",
    "#                 stack_pred = np.vstack(val_preds).reshape(\n",
    "#                     -1, Config.IMG_SIZE, Config.IMG_SIZE\n",
    "#                 )\n",
    "#                 for h_i in range(h_count):\n",
    "#                     tile_arry.append(stack_pred[h_i * w_count : (h_i + 1) * w_count])\n",
    "\n",
    "#                 _pred_tile_img = concat_tile(tile_arry)\n",
    "#                 _pred_tile_img = np.where(\n",
    "#                     data_set[fold][\"valid_mask\"][0][\n",
    "#                         (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                         (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                     ]\n",
    "#                     > 1,\n",
    "#                     _pred_tile_img[\n",
    "#                         : data_set[fold][\"valid_label\"][0][\n",
    "#                             (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                             (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                         ].shape[0],\n",
    "#                         : data_set[fold][\"valid_label\"][0][\n",
    "#                             (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                             (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                         ].shape[1],\n",
    "#                     ],\n",
    "#                     0,\n",
    "#                 )\n",
    "\n",
    "#                 shift_pred_tile_img = np.zeros(\n",
    "#                     (\n",
    "#                         data_set[fold][\"valid_img\"][0].shape[1],\n",
    "#                         data_set[fold][\"valid_img\"][0].shape[2],\n",
    "#                     )\n",
    "#                 )\n",
    "#                 shift_pred_tile_img[\n",
    "#                     (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                     (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "#                 ] = _pred_tile_img\n",
    "\n",
    "#                 # plt.imshow(shift_pred_tile_img)\n",
    "#                 # plt.show()\n",
    "\n",
    "#                 pred_tile_imgs.append(shift_pred_tile_img)\n",
    "\n",
    "#             pred_tile_img = np.sum(pred_tile_imgs, axis=0) / (Config.PREDICT_STRIDE)\n",
    "\n",
    "#             auc = roc_auc_score(\n",
    "#                 data_set[fold][\"valid_label\"][0].reshape(-1),\n",
    "#                 pred_tile_img.reshape(-1),\n",
    "#             )\n",
    "\n",
    "# #             logger.info(\"auc:{:.4f}\".format(auc))\n",
    "#             print(\"auc:{:.4f}\".format(auc))\n",
    "\n",
    "#             lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "#             val_metrics.append(auc)\n",
    "#             learning_rates.append(lr)\n",
    "\n",
    "#             early_stopping(-auc, net)\n",
    "\n",
    "#             if early_stopping.early_stop:\n",
    "#                 print(\"Early stopping\")\n",
    "# #                 logger.info(\"Early stopping\")\n",
    "#                 break\n",
    "\n",
    "#         fig = plt.figure()\n",
    "#         ax1 = fig.add_subplot(111)\n",
    "#         ax1.plot(learning_rates)\n",
    "#         ax2 = ax1.twinx()\n",
    "#         ax2.plot(val_metrics)\n",
    "#         plt.show()\n",
    "\n",
    "#         del (\n",
    "#             net,\n",
    "#             validloader,\n",
    "#             trainloader,\n",
    "#             train_dataset,\n",
    "#             valid_dataset,\n",
    "#             img,\n",
    "#             target_mask,\n",
    "#             target_class,\n",
    "#             outputs_mask,\n",
    "#             outputs_class,\n",
    "#         )\n",
    "#         torch.cuda.empty_cache()\n",
    "#         gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c53b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T11:01:32.040765Z",
     "iopub.status.busy": "2023-04-29T11:01:32.039299Z",
     "iopub.status.idle": "2023-04-29T11:01:32.067132Z",
     "shell.execute_reply": "2023-04-29T11:01:32.064386Z"
    },
    "papermill": {
     "duration": 0.055305,
     "end_time": "2023-04-29T11:01:32.068758",
     "exception": true,
     "start_time": "2023-04-29T11:01:32.013453",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(pred_tile_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87788d9f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.715045Z",
     "iopub.status.idle": "2023-04-29T10:45:34.715431Z",
     "shell.execute_reply": "2023-04-29T10:45:34.715273Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.715254Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.flip(data_set[fold][\"valid_label\"][0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5199366",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.719860Z",
     "iopub.status.idle": "2023-04-29T10:45:34.720668Z",
     "shell.execute_reply": "2023-04-29T10:45:34.720448Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.720420Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(data_set[fold][\"valid_label\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1492372",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.722674Z",
     "iopub.status.idle": "2023-04-29T10:45:34.723696Z",
     "shell.execute_reply": "2023-04-29T10:45:34.723365Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.723308Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.flip(data_set[fold][\"valid_img\"][0], 2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e1073b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400abc3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.725385Z",
     "iopub.status.idle": "2023-04-29T10:45:34.726285Z",
     "shell.execute_reply": "2023-04-29T10:45:34.726043Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.726016Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(data_set[fold][\"valid_img\"][0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0138cd6b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395d264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340ef2b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.728207Z",
     "iopub.status.idle": "2023-04-29T10:45:34.728899Z",
     "shell.execute_reply": "2023-04-29T10:45:34.728636Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.728610Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if is_train:\n",
    "    all_preds = []\n",
    "    all_masks = []\n",
    "    aucs = {}\n",
    "    for fold in range(0, 5):\n",
    "        # for fold in [0, 2]:\n",
    "        print(f\"====== {fold} ======\")\n",
    "\n",
    "        net = Unet()\n",
    "        net.load_state_dict(torch.load(OUTPUT_DIR/ f\"{EXP_NAME}_{fold}.pt\"))\n",
    "        net.to(device)\n",
    "\n",
    "        img_idx_nums = []\n",
    "        for img_idx_num in range(3):\n",
    "\n",
    "            valid_dataloaders = []\n",
    "\n",
    "            for j in range(Config.PREDICT_STRIDE):\n",
    "\n",
    "                valid_dataset = CVDataSet(\n",
    "                    [\n",
    "                        data_set[fold][\"valid_img\"][img_idx_num][\n",
    "                            :,\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        ]\n",
    "                    ],\n",
    "                    get_test_augmentation(),\n",
    "                    labels=[\n",
    "                        data_set[fold][\"valid_label\"][0][\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        ]\n",
    "                    ],\n",
    "                    data_type=\"valid\",\n",
    "                    crop_size=Config.IMG_SIZE,\n",
    "                )\n",
    "\n",
    "                validloader = DataLoader(\n",
    "                    valid_dataset,\n",
    "                    batch_size=Config.BATCH_SIZE,\n",
    "                    pin_memory=True,\n",
    "                    num_workers=Config.NUM_WORKERS,\n",
    "                )\n",
    "                valid_dataloaders.append(validloader)\n",
    "\n",
    "            h_flip_valid_dataloaders = []\n",
    "\n",
    "            for j in range(Config.PREDICT_STRIDE):\n",
    "\n",
    "                valid_dataset = CVDataSet(\n",
    "                    [\n",
    "                        np.flip(data_set[fold][\"valid_img\"][img_idx_num], 2)[\n",
    "                            :,\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        ]\n",
    "                    ],\n",
    "                    get_test_augmentation(),\n",
    "                    labels=[\n",
    "                        np.flip(data_set[fold][\"valid_label\"][0], 1)[\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        ]\n",
    "                    ],\n",
    "                    data_type=\"valid\",\n",
    "                    crop_size=Config.IMG_SIZE,\n",
    "                )\n",
    "\n",
    "                validloader = DataLoader(\n",
    "                    valid_dataset,\n",
    "                    batch_size=Config.BATCH_SIZE,\n",
    "                    pin_memory=True,\n",
    "                    num_workers=Config.NUM_WORKERS,\n",
    "                )\n",
    "                h_flip_valid_dataloaders.append(validloader)\n",
    "\n",
    "            fig, axes = plt.subplots(\n",
    "                2, math.ceil(Config.PREDICT_STRIDE / 2), figsize=(30, 15)\n",
    "            )\n",
    "            axes = axes.reshape(-1)\n",
    "            pred_tile_imgs = []\n",
    "\n",
    "            for j, validloader in enumerate(valid_dataloaders):\n",
    "                ## shift test\n",
    "                val_preds = []\n",
    "                val_class = []\n",
    "                valid_targets = []\n",
    "                valid_targets_class = []\n",
    "                n_iter_val = len(validloader)\n",
    "                for i, (img, target_mask, target_class) in tqdm(\n",
    "                    enumerate(validloader), total=n_iter_val, smoothing=0\n",
    "                    ):\n",
    "                    net.eval()\n",
    "                    with torch.no_grad():\n",
    "                        img, target_mask, target_class = (\n",
    "                            img.to(device).float(),\n",
    "                            target_mask.to(device).float(),\n",
    "                            target_class.to(device).float(),\n",
    "                        )\n",
    "                        outputs_mask, outputs_class = net(img)\n",
    "                        outputs_mask = outputs_mask.sigmoid()\n",
    "                        outputs_np = outputs_mask.to(\"cpu\").detach().numpy().copy()\n",
    "                        outputs_class = outputs_class.detach().cpu().numpy().ravel()\n",
    "                        \n",
    "                        val_preds.append(outputs_np)\n",
    "                        val_class.append(outputs_class)\n",
    "                        valid_targets.append(target_mask.to(\"cpu\").detach().numpy().copy())\n",
    "                        valid_targets_class.append(target_class.to(\"cpu\").detach().numpy().copy()) \n",
    "\n",
    "                ## 端を切る\n",
    "                w_count = math.ceil(\n",
    "                    data_set[fold][\"valid_label\"][0][\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ].shape[1]\n",
    "                    / Config.IMG_SIZE\n",
    "                )\n",
    "                h_count = math.ceil(\n",
    "                    data_set[fold][\"valid_label\"][0][\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ].shape[0]\n",
    "                    / Config.IMG_SIZE\n",
    "                )\n",
    "\n",
    "                tile_arry = []\n",
    "                stack_pred = np.vstack(val_preds).reshape(\n",
    "                    -1, Config.IMG_SIZE, Config.IMG_SIZE\n",
    "                )\n",
    "                for h_i in range(h_count):\n",
    "                    tile_arry.append(stack_pred[h_i * w_count : (h_i + 1) * w_count])\n",
    "\n",
    "                _pred_tile_img = concat_tile(tile_arry)\n",
    "                _pred_tile_img = np.where(\n",
    "                    data_set[fold][\"valid_mask\"][0][\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ]\n",
    "                    > 1,\n",
    "                    _pred_tile_img[\n",
    "                        : data_set[fold][\"valid_label\"][0][\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        ].shape[0],\n",
    "                        : data_set[fold][\"valid_label\"][0][\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        ].shape[1],\n",
    "                    ],\n",
    "                    0,\n",
    "                )\n",
    "\n",
    "                axes[j].imshow(_pred_tile_img)\n",
    "\n",
    "                shift_pred_tile_img = np.zeros(\n",
    "                    (\n",
    "                        data_set[fold][\"valid_img\"][0].shape[1],\n",
    "                        data_set[fold][\"valid_img\"][0].shape[2],\n",
    "                    )\n",
    "                )\n",
    "                shift_pred_tile_img[\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                ] = _pred_tile_img\n",
    "\n",
    "                pred_tile_imgs.append(shift_pred_tile_img)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            pred_tile_img_idx = np.sum(pred_tile_imgs, axis=0) / Config.PREDICT_STRIDE\n",
    "            img_idx_nums.append(pred_tile_img_idx)\n",
    "\n",
    "            # ここから HFLIP\n",
    "\n",
    "            fig, axes = plt.subplots(\n",
    "                2, math.ceil(Config.PREDICT_STRIDE / 2), figsize=(30, 15)\n",
    "            )\n",
    "            axes = axes.reshape(-1)\n",
    "            pred_tile_imgs = []\n",
    "\n",
    "            for j, validloader in enumerate(h_flip_valid_dataloaders):\n",
    "                val_preds = []\n",
    "                val_class = []\n",
    "                valid_targets = []\n",
    "                valid_targets_class = []\n",
    "                n_iter_val = len(validloader)\n",
    "                for i, (img, target_mask, target_class) in tqdm(enumerate(validloader), total=n_iter_val, smoothing=0):\n",
    "                    net.eval()\n",
    "                    with torch.no_grad():\n",
    "                        img, target_mask, target_class = (img.to(device).float(),\n",
    "                                                            target_mask.to(device).float(),\n",
    "                                                            target_class.to(device).float(),\n",
    "                                                        )\n",
    "                        outputs_mask, outputs_class = net(img)\n",
    "                        outputs_mask = outputs_mask.sigmoid()\n",
    "                        outputs_np = outputs_mask.to(\"cpu\").detach().numpy().copy()\n",
    "                        outputs_class = outputs_class.detach().cpu().numpy().ravel()\n",
    "                        \n",
    "                        val_preds.append(outputs_np)\n",
    "                        val_class.append(outputs_class)\n",
    "                        valid_targets.append(target_mask.to(\"cpu\").detach().numpy().copy())\n",
    "                        valid_targets_class.append(target_class.to(\"cpu\").detach().numpy().copy())\n",
    "\n",
    "                ## 端を切る\n",
    "                w_count = math.ceil(\n",
    "                    data_set[fold][\"valid_label\"][0][\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ].shape[1]\n",
    "                    / Config.IMG_SIZE\n",
    "                )\n",
    "                h_count = math.ceil(\n",
    "                    data_set[fold][\"valid_label\"][0][\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ].shape[0]\n",
    "                    / Config.IMG_SIZE\n",
    "                )\n",
    "\n",
    "                tile_arry = []\n",
    "                stack_pred = np.vstack(val_preds).reshape(\n",
    "                    -1, Config.IMG_SIZE, Config.IMG_SIZE\n",
    "                )\n",
    "                for h_i in range(h_count):\n",
    "                    tile_arry.append(stack_pred[h_i * w_count : (h_i + 1) * w_count])\n",
    "\n",
    "                _pred_tile_img = concat_tile(tile_arry)\n",
    "                _pred_tile_img = np.where(\n",
    "                    np.flip(data_set[fold][\"valid_mask\"][0], 1)[\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ]\n",
    "                    > 1,\n",
    "                    _pred_tile_img[\n",
    "                        : data_set[fold][\"valid_label\"][0][\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        ].shape[0],\n",
    "                        : data_set[fold][\"valid_label\"][0][\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                            (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        ].shape[1],\n",
    "                    ],\n",
    "                    0,\n",
    "                )\n",
    "\n",
    "                axes[j].imshow(_pred_tile_img)\n",
    "\n",
    "                shift_pred_tile_img = np.zeros(\n",
    "                    (\n",
    "                        data_set[fold][\"valid_img\"][0].shape[1],\n",
    "                        data_set[fold][\"valid_img\"][0].shape[2],\n",
    "                    )\n",
    "                )\n",
    "                shift_pred_tile_img[\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                ] = _pred_tile_img\n",
    "\n",
    "                pred_tile_imgs.append(shift_pred_tile_img)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            pred_tile_img_idx = np.sum(pred_tile_imgs, axis=0) / Config.PREDICT_STRIDE\n",
    "\n",
    "            # plt.imshow(pred_tile_img_idx)\n",
    "            # plt.show()\n",
    "\n",
    "            # plt.imshow(np.fliplr(pred_tile_img_idx))\n",
    "            # plt.show()\n",
    "\n",
    "            img_idx_nums.append(np.flip(pred_tile_img_idx, 1))\n",
    "\n",
    "        pred_tile_img = np.sum(img_idx_nums, axis=0) / 6  # うえにもある\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(pred_tile_img)\n",
    "        plt.show()\n",
    "\n",
    "        auc = roc_auc_score(\n",
    "            data_set[fold][\"valid_label\"][0].reshape(-1),\n",
    "            pred_tile_img.reshape(-1),\n",
    "        )\n",
    "\n",
    "        aucs[f\"auc{fold}\"] = auc\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(np.where(cv2.GaussianBlur(pred_tile_img, (65, 65), 32) > 0.3, 1, 0))\n",
    "        plt.show()\n",
    "\n",
    "        np.save(\n",
    "            str(OUTPUT_DIR / f'oof_img{data_set[fold][\"valid_img_num\"]}'),\n",
    "            cv2.GaussianBlur(pred_tile_img, (65, 65), 32),\n",
    "        )\n",
    "\n",
    "        all_masks.append(data_set[fold][\"valid_label\"][0].reshape(-1))\n",
    "        all_preds.append(cv2.GaussianBlur(pred_tile_img, (65, 65), 32).reshape(-1))\n",
    "\n",
    "        print(auc)\n",
    "\n",
    "        del net, validloader, valid_dataset, img, target_mask, target_class, outputs_mask, outputs_class\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea371b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4955ba3e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f5983",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.730543Z",
     "iopub.status.idle": "2023-04-29T10:45:34.731431Z",
     "shell.execute_reply": "2023-04-29T10:45:34.731190Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.731162Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_preds.append(cv2.GaussianBlur(pred_tile_img, (127, 127), 64).reshape(-1))\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from torchmetrics.classification import BinaryFBetaScore\n",
    "metric = BinaryFBetaScore(beta=0.5).to(\"cuda\")\n",
    "\n",
    "# score = fbeta_score(y_true, y_pred, beta=0.5)\n",
    "\n",
    "thr_scores = []\n",
    "\n",
    "if is_train:\n",
    "\n",
    "    for fold in range(5):\n",
    "\n",
    "        print(fold)\n",
    "\n",
    "        flat_preds = all_preds[fold].astype(np.float)\n",
    "        flat_masks = (all_masks[fold] / 255).astype(int)\n",
    "        flat_masks_torch = (\n",
    "            torch.from_numpy(flat_masks.astype(np.int)).clone().to(\"cuda\")\n",
    "        )\n",
    "\n",
    "        plt.hist(flat_preds, bins=50)\n",
    "        plt.show()\n",
    "\n",
    "        thr_list = []\n",
    "        for thr in tqdm(np.arange(0.1, 0.75, 0.025)):\n",
    "            _val_pred = np.where(flat_preds > thr, 1, 0).astype(np.int)\n",
    "            #score = fbeta_score(flat_masks, _val_pred, beta=0.5)\n",
    "            \n",
    "            _val_pred_torch = (\n",
    "                torch.from_numpy(_val_pred.astype(np.int)).clone().to(\"cuda\")\n",
    "            )\n",
    "            score = metric(_val_pred_torch, flat_masks_torch)\n",
    "            \n",
    "            # print(thr, score)\n",
    "            thr_list.append({\"thr\": thr, \"score\": score})\n",
    "\n",
    "            thr_scores.append({\"fold\": fold, \"thr\": thr, \"score\": score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ec418",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.732898Z",
     "iopub.status.idle": "2023-04-29T10:45:34.733783Z",
     "shell.execute_reply": "2023-04-29T10:45:34.733522Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.733496Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_train:\n",
    "    thr_scores_df = pd.DataFrame(thr_scores)\n",
    "    for fold, fold_df in thr_scores_df.groupby(\"fold\"):\n",
    "        plt.plot(fold_df[\"thr\"], fold_df[\"score\"], label=f\"fold {fold}\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"threshold\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.show()\n",
    "    best_thr_scores = (\n",
    "        thr_scores_df.sort_values(\"score\", ascending=False).groupby(\"fold\").first()\n",
    "    )\n",
    "    display(best_thr_scores)\n",
    "\n",
    "    print(best_thr_scores[\"thr\"].mean())\n",
    "\n",
    "    print(best_thr_scores[\"score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f4666",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.735332Z",
     "iopub.status.idle": "2023-04-29T10:45:34.736328Z",
     "shell.execute_reply": "2023-04-29T10:45:34.736094Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.736067Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "thr_scores_df.groupby(\"thr\")[\"score\"].mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063556e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.741026Z",
     "iopub.status.idle": "2023-04-29T10:45:34.741857Z",
     "shell.execute_reply": "2023-04-29T10:45:34.741442Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.741389Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_train:\n",
    "    \n",
    "    _best_thr_scores = best_thr_scores.copy()\n",
    "    _best_thr_scores[\"idx\"] = [f\"fbeta_score{i}\" for i in _best_thr_scores.index]\n",
    "    _best_thr_scores = _best_thr_scores.set_index(\"idx\")\n",
    "    print(_best_thr_scores[\"score\"].to_dict())\n",
    "    print(\"score_mean\", best_thr_scores[\"score\"].mean())\n",
    "\n",
    "    _best_thr_scores = best_thr_scores.copy()\n",
    "    _best_thr_scores[\"idx\"] = [f\"thr{i}\" for i in _best_thr_scores.index]\n",
    "    _best_thr_scores = _best_thr_scores.set_index(\"idx\")\n",
    "    print(_best_thr_scores[\"thr\"].to_dict())\n",
    "    print(\"thr_mean\", best_thr_scores[\"thr\"].mean())\n",
    "\n",
    "    print(aucs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb722e26",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ad8cf0e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e191fe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.744500Z",
     "iopub.status.idle": "2023-04-29T10:45:34.745063Z",
     "shell.execute_reply": "2023-04-29T10:45:34.744837Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.744802Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def predict(test_data_dir, thr=0.5):\n",
    "    \n",
    "    _im = cv2.imread(str(test_data_dir / f\"surface_volume/00.tif\"), 0)\n",
    "    \n",
    "    pred_tile_img = np.zeros((_im.shape[0], _im.shape[1]))\n",
    "\n",
    "\n",
    "    # mask\n",
    "    test_mask = cv2.imread(str(test_data_dir / \"mask.png\"), 0)\n",
    "\n",
    "    ## 推論\n",
    "    nets = []\n",
    "\n",
    "    for fold in range(0, 5):\n",
    "        net = Unet()\n",
    "        net.to(device)\n",
    "        net.load_state_dict(torch.load(OUTPUT_DIR / f\"{EXP_NAME}_{fold}.pt\"))\n",
    "        # net.load_state_dict(torch.load('/kaggle/input/ink-model/DESKTOP-M3SEAIN_exp0001_checkpoint_0.pt'))\n",
    "        nets.append(net)\n",
    "\n",
    "    for _idxs in [idxs, idxs2, idxs3]:\n",
    "        \n",
    "        test_img = []\n",
    "        for i in tqdm(_idxs):\n",
    "            test_img.append(\n",
    "                cv2.imread(str(test_data_dir / f\"surface_volume/{i:02}.tif\"), 0)\n",
    "            )\n",
    "\n",
    "        \n",
    "\n",
    "        test_img = np.stack(test_img)\n",
    "        print(test_img.shape)\n",
    "        \n",
    "\n",
    "        test_dataloaders = []\n",
    "\n",
    "        for j in range(Config.PREDICT_STRIDE):\n",
    "\n",
    "            test_dataset = CVDataSet(\n",
    "                [\n",
    "                    test_img[\n",
    "                        :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ]\n",
    "                ],\n",
    "                get_test_augmentation(),\n",
    "                data_type=\"test\",\n",
    "                crop_size=Config.IMG_SIZE,\n",
    "            )\n",
    "            testloader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=Config.BATCH_SIZE // 2,\n",
    "                pin_memory=True,\n",
    "                num_workers=Config.NUM_WORKERS,\n",
    "            )\n",
    "\n",
    "            test_dataloaders.append(testloader)\n",
    "\n",
    "        h_flip_test_dataloaders = []\n",
    "\n",
    "        for j in range(Config.PREDICT_STRIDE):\n",
    "\n",
    "            test_dataset = CVDataSet(\n",
    "                [\n",
    "                    np.flip(test_img, 2)[\n",
    "                        :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ]\n",
    "                ],\n",
    "                get_test_augmentation(),\n",
    "                data_type=\"test\",\n",
    "                crop_size=Config.IMG_SIZE,\n",
    "            )\n",
    "            testloader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=Config.BATCH_SIZE // 2,\n",
    "                pin_memory=True,\n",
    "                num_workers=Config.NUM_WORKERS,\n",
    "            )\n",
    "\n",
    "            h_flip_test_dataloaders.append(testloader)\n",
    "\n",
    "        pred_tile_imgs = np.zeros((test_img[0].shape[0], test_img[0].shape[1]))\n",
    "        for j, testloader in enumerate(test_dataloaders):\n",
    "\n",
    "            # shift\n",
    "            for epoch in range(1):\n",
    "\n",
    "                test_preds = []\n",
    "                n_iter_val = len(testloader)\n",
    "                for i, (img, target) in tqdm(enumerate(testloader), total=n_iter_val):\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        img, target = img.to(device).float(), target.to(device).float()\n",
    "\n",
    "                        outputs_all = np.zeros(\n",
    "                            (img.shape[0], img.shape[2], img.shape[3])\n",
    "                        )\n",
    "\n",
    "                        for net in nets:\n",
    "                            net.eval()\n",
    "                            outputs = net(img)\n",
    "                            outputs = outputs.sigmoid()\n",
    "                            outputs_np = (\n",
    "                                outputs.squeeze().to(\"cpu\").detach().numpy().copy()\n",
    "                            )\n",
    "                            # print(outputs_np.shape)\n",
    "                            # print(outputs_all.shape)\n",
    "                            outputs_all += outputs_np / len(nets)\n",
    "\n",
    "                        test_preds.append(outputs_all)\n",
    "\n",
    "            w_count = math.ceil(\n",
    "                test_img[0][\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                ].shape[1]\n",
    "                / Config.IMG_SIZE\n",
    "            )\n",
    "            h_count = math.ceil(\n",
    "                test_img[0][\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                ].shape[0]\n",
    "                / Config.IMG_SIZE\n",
    "            )\n",
    "\n",
    "            # w_count = math.ceil(test_img[0].shape[1] / Config.IMG_SIZE)\n",
    "            # h_count = math.ceil(test_img[0].shape[0] / Config.IMG_SIZE)\n",
    "\n",
    "            tile_arry = []\n",
    "            stack_pred = np.vstack(test_preds).reshape(\n",
    "                -1, Config.IMG_SIZE, Config.IMG_SIZE\n",
    "            )\n",
    "            for h_i in range(h_count):\n",
    "                tile_arry.append(stack_pred[h_i * w_count : (h_i + 1) * w_count])\n",
    "\n",
    "            _pred_tile_img = concat_tile(tile_arry)\n",
    "\n",
    "            _pred_tile_img = np.where(\n",
    "                test_mask[\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                ]\n",
    "                > 1,\n",
    "                _pred_tile_img[\n",
    "                    : test_img[0][\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ].shape[0],\n",
    "                    : test_img[0][\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ].shape[1],\n",
    "                ],\n",
    "                0,\n",
    "            )\n",
    "\n",
    "            shift_pred_tile_img = np.zeros((test_img[0].shape[0], test_img[0].shape[1]))\n",
    "            shift_pred_tile_img[\n",
    "                (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "            ] = _pred_tile_img\n",
    "\n",
    "            # plt.figure(figsize=(10, 10))\n",
    "            # plt.imshow(shift_pred_tile_img)\n",
    "            # plt.show()\n",
    "\n",
    "            pred_tile_imgs += shift_pred_tile_img / Config.PREDICT_STRIDE\n",
    "\n",
    "        pred_tile_img += pred_tile_imgs / 6\n",
    "\n",
    "        pred_tile_imgs = np.zeros((test_img[0].shape[0], test_img[0].shape[1]))\n",
    "        for j, testloader in enumerate(h_flip_test_dataloaders):\n",
    "\n",
    "            # shift\n",
    "            for epoch in range(1):\n",
    "\n",
    "                test_preds = []\n",
    "                n_iter_val = len(testloader)\n",
    "                for i, (img, target) in tqdm(enumerate(testloader), total=n_iter_val):\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        img, target = img.to(device).float(), target.to(device).float()\n",
    "\n",
    "                        outputs_all = np.zeros(\n",
    "                            (img.shape[0], img.shape[2], img.shape[3])\n",
    "                        )\n",
    "\n",
    "                        for net in nets:\n",
    "                            net.eval()\n",
    "                            outputs = net(img)\n",
    "                            outputs = outputs.sigmoid()\n",
    "                            outputs_np = (\n",
    "                                outputs.squeeze().to(\"cpu\").detach().numpy().copy()\n",
    "                            )\n",
    "                            # print(outputs_np.shape)\n",
    "                            # print(outputs_all.shape)\n",
    "                            outputs_all += outputs_np / len(nets)\n",
    "\n",
    "                        test_preds.append(outputs_all)\n",
    "\n",
    "            w_count = math.ceil(\n",
    "                test_img[0][\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                ].shape[1]\n",
    "                / Config.IMG_SIZE\n",
    "            )\n",
    "            h_count = math.ceil(\n",
    "                test_img[0][\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                ].shape[0]\n",
    "                / Config.IMG_SIZE\n",
    "            )\n",
    "\n",
    "            # w_count = math.ceil(test_img[0].shape[1] / Config.IMG_SIZE)\n",
    "            # h_count = math.ceil(test_img[0].shape[0] / Config.IMG_SIZE)\n",
    "\n",
    "            tile_arry = []\n",
    "            stack_pred = np.vstack(test_preds).reshape(\n",
    "                -1, Config.IMG_SIZE, Config.IMG_SIZE\n",
    "            )\n",
    "            for h_i in range(h_count):\n",
    "                tile_arry.append(stack_pred[h_i * w_count : (h_i + 1) * w_count])\n",
    "\n",
    "            _pred_tile_img = concat_tile(tile_arry)\n",
    "\n",
    "            _pred_tile_img = np.where(\n",
    "                np.flip(test_mask, 1)[\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                ]\n",
    "                > 1,\n",
    "                _pred_tile_img[\n",
    "                    : test_img[0][\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ].shape[0],\n",
    "                    : test_img[0][\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                        (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                    ].shape[1],\n",
    "                ],\n",
    "                0,\n",
    "            )\n",
    "\n",
    "            shift_pred_tile_img = np.zeros((test_img[0].shape[0], test_img[0].shape[1]))\n",
    "            shift_pred_tile_img[\n",
    "                (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "                (Config.IMG_SIZE // Config.PREDICT_STRIDE) * j :,\n",
    "            ] = _pred_tile_img\n",
    "\n",
    "            # plt.figure(figsize=(10, 10))\n",
    "            # plt.imshow(shift_pred_tile_img)\n",
    "            # plt.show()\n",
    "\n",
    "            pred_tile_imgs += np.flip(shift_pred_tile_img, 1) / Config.PREDICT_STRIDE\n",
    "\n",
    "        pred_tile_img += pred_tile_imgs / 6\n",
    "\n",
    "        del pred_tile_imgs, shift_pred_tile_img\n",
    "\n",
    "    pred_tile_img = cv2.GaussianBlur(\n",
    "        pred_tile_img, (65, 65), 32\n",
    "    )  # cv2.GaussianBlur(pred_tile_img, (191, 191), 64)\n",
    "\n",
    "    return pred_tile_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac77cb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d33c8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.746894Z",
     "iopub.status.idle": "2023-04-29T10:45:34.747394Z",
     "shell.execute_reply": "2023-04-29T10:45:34.747160Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.747133Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_root_dir = DATA_DIR / \"test/*\"\n",
    "\n",
    "pred_list = []\n",
    "for f in glob.glob(str(test_root_dir)):\n",
    "    print(f)\n",
    "    pred_tile_img = predict(Path(f))\n",
    "\n",
    "    if is_train:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(pred_tile_img)\n",
    "    plt.show()\n",
    "\n",
    "    if is_train:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(np.where(pred_tile_img > 0.475, 1, 0))\n",
    "    plt.show()\n",
    "\n",
    "    starts_ix, lengths = rle(pred_tile_img.reshape(-1), 0.475)\n",
    "    inklabels_rle = \" \".join(map(str, sum(zip(starts_ix, lengths), ())))\n",
    "    inklabels_rle\n",
    "\n",
    "    pred_list.append({\"Id\": str(f).split(\"/\")[-1], \"Predicted\": inklabels_rle})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9960b80",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b76d6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.749697Z",
     "iopub.status.idle": "2023-04-29T10:45:34.751291Z",
     "shell.execute_reply": "2023-04-29T10:45:34.751051Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.751023Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_list).to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d2cbc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T10:45:34.752640Z",
     "iopub.status.idle": "2023-04-29T10:45:34.753518Z",
     "shell.execute_reply": "2023-04-29T10:45:34.753274Z",
     "shell.execute_reply.started": "2023-04-29T10:45:34.753247Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc3c52",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 176.32582,
   "end_time": "2023-04-29T11:01:35.035114",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-29T10:58:38.709294",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
