{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# ex023\n","bug fix masked_img   \n","5-fold  \n","img size 512\n","output shape is half of input shape  \n","channel shuffle  \n","ComboLoss"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:41.388632Z","iopub.status.busy":"2023-04-11T00:41:41.388166Z","iopub.status.idle":"2023-04-11T00:41:43.938183Z","shell.execute_reply":"2023-04-11T00:41:43.937024Z","shell.execute_reply.started":"2023-04-11T00:41:41.388578Z"},"trusted":true},"outputs":[],"source":["import gc\n","import os\n","import random\n","import time\n","import math\n","\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# model\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import timm\n","from torchvision.models.feature_extraction import create_feature_extractor\n","import torchvision.transforms.functional as TF\n","\n","# data loader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from torch.utils.data import DataLoader, Dataset\n","\n","# training\n","from torch.optim import SGD, Adam, AdamW\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau, ExponentialLR\n","\n","# metric\n","from sklearn.metrics import fbeta_score, roc_auc_score\n","\n","import wandb\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["# config"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:43.940925Z","iopub.status.busy":"2023-04-11T00:41:43.940483Z","iopub.status.idle":"2023-04-11T00:41:43.958735Z","shell.execute_reply":"2023-04-11T00:41:43.957018Z","shell.execute_reply.started":"2023-04-11T00:41:43.94088Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4\n","[[26, 29, 32, 35], [27, 30, 33, 36], [25, 28, 31, 34]]\n","SLIDE_POS_LIST = [[0, 0], [256, 0], [0, 256], [256, 256]]\n"]}],"source":["BASE_DIR = \"/working/\"\n","INPUT_DIR = os.path.join(BASE_DIR, \"input\", \"vesuvius-challenge-ink-detection\")\n","TRAIN_DIR = os.path.join(INPUT_DIR, \"train\")\n","TEST_DIR = os.path.join(INPUT_DIR, \"test\")\n","# IMG_SIZE = [256, 256]\n","# IMG_SIZE = [128, 128]\n","IMG_SIZE = [512, 512]\n","SURFACE_LIST = [\n","                list(range(26, 36, 3)),\n","                list(range(27, 37, 3)),                \n","                list(range(25, 35, 3)),\n","                ]\n","print(len(SURFACE_LIST[0]))\n","print(SURFACE_LIST)\n","\n","SURFACE_NUM = len(SURFACE_LIST[0])\n","# print(\"Start surface idx =\",START_SURFACE)\n","\n","# SLIDE_POS_LIST = [[idx*(IMG_SIZE[0]//6), idx*(IMG_SIZE[1]//6)] for idx in range(0, 3)]\n","SLIDE_POS_LIST = [[0,0], [IMG_SIZE[0]//2, 0], [0, IMG_SIZE[1]//2], [IMG_SIZE[0]//2, IMG_SIZE[1]//2]]\n","print(\"SLIDE_POS_LIST =\", SLIDE_POS_LIST)\n","CFG = {\n","    \"DEBUG\" : False,\n","    # exp setting\n","    \"EXP_CATEGORY\" : \"5fold\",\n","    \"EXP_NAME\" : \"exp023\",\n","    \"folds\" : [0, 1, 2, 3, 4],\n","\n","    # model\n","    # \"model_name\" : \"tf_efficientnet_b0\",\n","    \"model_name\" : \"tf_efficientnet_b6\",\n","    \"inp_channels\" : SURFACE_NUM,\n","    \"out_channels\" : 1,\n","    \"pretrained\" : True,\n","    \"out_indices\" : [0,1,2,3,4],\n"," \n","    # data   \n","    \"img_size\": IMG_SIZE,\n","    # \"batch_size\": 32,\n","    # \"batch_size\": 16,#batch normの関係か？16の方が64より安定してそう？？\n","    \"batch_size\": 8,\n","    \"INPUT_DIR\": INPUT_DIR,\n","    \"TRAIN_DIR\": TRAIN_DIR,\n","    \"TEST_DIR\": TEST_DIR,\n","    \"surface_num\": SURFACE_NUM,\n","    \"surface_list\": list(SURFACE_LIST),\n","    \"slide_pos_list\": SLIDE_POS_LIST,\n","    \"RANDOM_SLIDE\": True,\n","#     \"surface_start_idx\": START_SURFACE,\n","    # \"TRAIN_DIR_LIST\": [[\"1\", \"2\"], [\"1\", \"3\"], [\"2\", \"3\"]],\n","    \"TRAIN_DIR_LIST\": [[\"1\", \"2_0\", \"2_1\", \"2_2\"], \n","                       [\"1\", \"2_0\", \"2_1\", \"3\"],\n","                       [\"1\", \"2_0\",  \"2_2\", \"3\"],\n","                       [\"1\", \"2_1\", \"2_2\", \"3\"],\n","                       [\"2_0\", \"2_1\", \"2_2\", \"3\"],\n","                       ],\n","#     \"TRAIN_IDX_LIST\" : [\"1\"],\n","    # \"VALID_DIR_LIST\": [[\"3\"],[\"2\"],[\"1\"]],\n","    \"VALID_DIR_LIST\": [[\"3\"], [\"2_2\"], [\"2_1\"], [\"2_0\"],[\"1\"]],\n","    \"TEST_DIR_LIST\": [\"a\", \"b\"],\n","\n","    # learning\n","    \"n_epoch\" : 20,\n","    \"lr\" : 1e-3,\n","    \"T_max\" : 5,\n","    \"min_lr\" : 1e-8,\n","    \"weight_decay\" : 1e-6,\n","\n","    # etc\n","    \"print_freq\" : 1000,\n","    \"random_seed\" : 21,\n","    \"num_workers\": 2,\n","}\n","\n","\n","if CFG[\"model_name\"]==\"tf_efficientnet_b0\":\n","    CFG[\"channel_nums\"] = [320, 112, 40, 24, 16]\n","elif CFG[\"model_name\"]==\"tf_efficientnet_b4\":\n","    CFG[\"channel_nums\"] = [448, 160, 56, 32, 24]\n","elif CFG[\"model_name\"]==\"tf_efficientnet_b6\":\n","    CFG[\"channel_nums\"] = [576, 200, 72, 40, 32]\n","\n","\n","if CFG[\"DEBUG\"]:\n","    CFG[\"n_epoch\"] = 1\n","    CFG[\"EXP_NAME\"] = \"DEBUG\"\n","    \n","\n","CFG[\"OUTPUT_DIR\"] = os.path.join(BASE_DIR, \"output\", CFG[\"EXP_NAME\"])"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["if not CFG[\"DEBUG\"]:\n","    os.makedirs(CFG[\"OUTPUT_DIR\"])\n","    os.makedirs(os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\"))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-04-21 12:59:11.608810: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-21 12:59:11.701217: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-04-21 12:59:12.286383: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n","2023-04-21 12:59:12.286475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.7/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n","2023-04-21 12:59:12.286483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["if not CFG[\"DEBUG\"]:\n","    WANDB_CONFIG = {'competition': 'vcid', '_wandb_kernel': 'taro'}\n","    os.environ[\"WANDB_SILENT\"] = \"true\"\n","    wandb.init(project=WANDB_CONFIG[\"competition\"], config=CFG, group=CFG[\"EXP_CATEGORY\"], name=CFG[\"EXP_NAME\"], reinit=True)"]},{"cell_type":"markdown","metadata":{},"source":["# utils"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def logging_metrics_epoch(CFG, fold, epoch, slice_idx,train_loss_avg, valid_loss_avg, score, threshold, auc_score):\n","    wandb.log({f\"train/fold{fold}\": train_loss_avg,\n","                f\"valid/fold{fold}\": valid_loss_avg,\n","                f\"score/fold{fold}\":score,\n","                f\"score threshold/fold{fold}\":threshold,\n","                f\"auc/fold{fold}\":auc_score,\n","                f\"epoch/fold{fold}\":epoch+slice_idx*CFG[\"n_epoch\"],\n","                })\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:43.962726Z","iopub.status.busy":"2023-04-11T00:41:43.962423Z","iopub.status.idle":"2023-04-11T00:41:43.996799Z","shell.execute_reply":"2023-04-11T00:41:43.995583Z","shell.execute_reply.started":"2023-04-11T00:41:43.962698Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["def seed_everything(seed=CFG[\"random_seed\"]):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic =True\n","    torch.backends.cudnn.benchmark = False\n","seed_everything()\n","\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.000826Z","iopub.status.busy":"2023-04-11T00:41:44.000079Z","iopub.status.idle":"2023-04-11T00:41:44.010016Z","shell.execute_reply":"2023-04-11T00:41:44.009127Z","shell.execute_reply.started":"2023-04-11T00:41:44.000749Z"},"trusted":true},"outputs":[],"source":["def asMinutes(s):\n","    \"\"\"Convert Seconds to Minutes.\"\"\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    \"\"\"Accessing and Converting Time Data.\"\"\"\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"markdown","metadata":{},"source":["# metric"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.012555Z","iopub.status.busy":"2023-04-11T00:41:44.011593Z","iopub.status.idle":"2023-04-11T00:41:44.023483Z","shell.execute_reply":"2023-04-11T00:41:44.022677Z","shell.execute_reply.started":"2023-04-11T00:41:44.012515Z"},"trusted":true},"outputs":[],"source":["def fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n","    y_true_count = targets.sum()\n","    ctp = preds[targets==1].sum()\n","    cfp = preds[targets==0].sum()\n","    beta_squared = beta * beta\n","\n","    c_precision = ctp / (ctp + cfp + smooth)\n","    c_recall = ctp / (y_true_count + smooth)\n","    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n","\n","    return dice\n","\n","def calc_fbeta_auc(mask, mask_pred):\n","    mask = mask.astype(int).flatten()\n","    mask_pred = mask_pred.flatten()\n","\n","    best_th = 0\n","    best_dice = 0\n","    dice_list = [] \n","    # for th in np.array(range(10, 50+1, 5)) / 100:\n","    for th in np.array(range(10, 100+1, 5)) / 100:\n","        # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n","        dice = fbeta_numpy(mask, (mask_pred >= th).astype(int), beta=0.5)\n","        dice_list.append(dice)\n","        # print(f'\\t th: {th}, fbeta: {dice}')\n","        if dice > best_dice:\n","            best_dice = dice\n","            best_th = th\n","    \n","    auc = roc_auc_score(mask, mask_pred)\n","    # Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n","    return best_dice, best_th, auc, dice_list\n","\n","\n","def calc_cv(mask_gt, mask_pred):\n","    best_dice, best_th, auc, dice_list = calc_fbeta_auc(mask_gt, mask_pred)\n","\n","    return best_dice, best_th, auc, dice_list"]},{"cell_type":"markdown","metadata":{},"source":["# model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.026051Z","iopub.status.busy":"2023-04-11T00:41:44.025452Z","iopub.status.idle":"2023-04-11T00:41:44.044558Z","shell.execute_reply":"2023-04-11T00:41:44.043338Z","shell.execute_reply.started":"2023-04-11T00:41:44.026009Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, CFG):\n","        super().__init__()\n","        self.encoder = timm.create_model(CFG[\"model_name\"], in_chans=CFG[\"inp_channels\"], features_only=True, out_indices=CFG[\"out_indices\"], pretrained=CFG[\"pretrained\"])\n","    def forward(self, img):\n","        skip_connection_list = self.encoder(img)\n","        return skip_connection_list\n","\n","class UpConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","        self.bn1 = nn.BatchNorm2d(in_channels)\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 2, padding=\"same\")\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","    def forward(self, x):\n","        x = self.up(x)\n","        x = self.bn1(x)\n","        x = self.conv(x)\n","        x = self.bn2(x)\n","        return x\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.UpConv_0 = UpConv(CFG[\"channel_nums\"][0], CFG[\"channel_nums\"][1])\n","        self.UpConv_1 = UpConv(CFG[\"channel_nums\"][1]*2, CFG[\"channel_nums\"][2])\n","        self.UpConv_2 = UpConv(CFG[\"channel_nums\"][2]*2, CFG[\"channel_nums\"][3])\n","        self.UpConv_3 = UpConv(CFG[\"channel_nums\"][3]*2, CFG[\"channel_nums\"][4])\n","        # self.UpConv_4 = UpConv(CFG[\"channel_nums\"][4]*2, CFG[\"channel_nums\"][4])\n","    \n","    def forward(self, skip_connection_list):\n","        emb = self.UpConv_0(skip_connection_list[4]) # emb.shape = (None, 160, 14, 14)\n","        emb_cat = torch.cat([skip_connection_list[3], emb], dim = 1)\n","        \n","        emb = self.UpConv_1(emb_cat)\n","        emb_cat = torch.cat([skip_connection_list[2], emb], dim = 1)\n","        \n","        emb = self.UpConv_2(emb_cat)\n","        emb_cat = torch.cat([skip_connection_list[1], emb], dim = 1)\n","        \n","        emb = self.UpConv_3(emb_cat)\n","        emb_cat = torch.cat([skip_connection_list[0], emb], dim = 1)\n","\n","        # emb_cat = self.UpConv_4(emb_cat)\n","        \n","        return emb_cat\n","\n","class SegModel(nn.Module):\n","    def __init__(self, CFG):\n","        super().__init__()\n","        self.encoder = Encoder(CFG)\n","        self.decoder = Decoder()\n","        self.head = nn.Sequential(\n","            nn.Conv2d(CFG[\"channel_nums\"][-1]*2, CFG[\"out_channels\"], kernel_size=1, stride=1, padding=0),\n","            nn.Sigmoid()\n","        )\n","    def forward(self, img):\n","        skip_connection_list = self.encoder(img)\n","        emb = self.decoder(skip_connection_list)\n","        output = self.head(emb)\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.05649Z","iopub.status.busy":"2023-04-11T00:41:44.056177Z","iopub.status.idle":"2023-04-11T00:41:44.063611Z","shell.execute_reply":"2023-04-11T00:41:44.062381Z","shell.execute_reply.started":"2023-04-11T00:41:44.05646Z"},"trusted":true},"outputs":[],"source":["train_transforms = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.VerticalFlip(p=0.5),\n","    A.RandomRotate90(p=0.5),\n","    A.RandomCrop(int(CFG[\"img_size\"][0]*0.8), int(CFG[\"img_size\"][1]*0.8), p=0.3),\n","    A.Blur(blur_limit=3, p=0.3),\n","    A.Resize(CFG[\"img_size\"][0], CFG[\"img_size\"][1]),\n","    ToTensorV2(),\n","])\n","\n","valid_transforms = A.Compose([\n","    ToTensorV2(),\n","])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["class VCID_Dataset(Dataset):\n","    def __init__(self, CFG, data_dir_list, surface_list, surface_volumes=None, slide_pos=[0,0], mode=\"train\", transform=None):\n","        # get config\n","        self.mode = mode\n","        self.RANDOM_SLIDE = CFG[\"RANDOM_SLIDE\"]\n","        self.img_size = CFG[\"img_size\"]\n","        if self.mode==\"train\":  self.DATADIR = CFG[\"TRAIN_DIR\"]\n","        elif self.mode==\"valid\":    self.DATADIR = CFG[\"TRAIN_DIR\"]\n","        elif self.mode == \"test\":   self.DATADIR = CFG[\"TEST_DIR\"]\n","        self.data_dir_list = data_dir_list\n","        self.surface_list = surface_list\n","        self.slide_pos = slide_pos\n","        self.transform = transform\n","        \n","        # get imgs\n","        # print(\"initializing dataset...\")\n","        self.imgs = []\n","        for data_dir in self.data_dir_list:\n","            img_path = os.path.join(self.DATADIR, data_dir, \"mask.png\")\n","            # print(img_path)\n","            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","            img = img.reshape(img.shape[0], img.shape[1], 1) # (h, w, channel=1)\n","            assert img is not None, \"img is None. data path is wrong\"\n","            self.imgs.append(img)  \n","        \n","        # get and split surface\n","        if surface_volumes is None:\n","            self.surface_vols = self.read_surfacevols()\n","        else:\n","            # print(\"using loaded surface_vols\")\n","            self.surface_vols = surface_volumes\n","       \n","        # split grid\n","        self.get_all_grid()\n","        self.fileter_grid()\n","        self.get_flatten_grid()\n","        # print(\"split grid done.\") \n","       \n","        # get label imgs\n","        if self.mode == \"train\" or self.mode == \"valid\":\n","            self.labels = []\n","            for data_dir in self.data_dir_list:\n","                label_path = os.path.join(self.DATADIR, data_dir, \"inklabels.png\")\n","                assert os.path.exists(label_path), f\"{label_path} is not exist.\"\n","                # read label\n","                label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n","                label = label.reshape(label.shape[0], label.shape[1], 1) # (h, w, channel=1)\n","                self.labels.append(label)# 画像サイズがそれぞれ違うので単純にconcatできずlist化しているs\n","        # print(\"initializing dataset done.\")\n","\n","    def get_surface_volumes(self):\n","        return self.surface_vols\n","\n","    def read_surfacevols(self):\n","        \"\"\" read surface volume by data_dir_list and surface_list \n","            Returns:surface_vuls (list): surface volume list [array(h,w,channel=surface_num), array(), ...]\n","        \"\"\"\n","        surface_vols = []\n","        # print(\"reading surface volume...\")\n","        for data_dir in self.data_dir_list:\n","            surface_vol_ = None\n","            for read_idx, surface_idx in enumerate(self.surface_list):\n","                # print(\"\\r\", f\"reading idx : {read_idx+1}/{len(self.surface_list)}\", end=\"\")\n","                surface_path = os.path.join(self.DATADIR, data_dir, \"surface_volume\", f\"{surface_idx:02}.tif\")\n","                surface_vol = cv2.imread(surface_path, cv2.IMREAD_GRAYSCALE)\n","                surface_vol = surface_vol.reshape(surface_vol.shape[0], surface_vol.shape[1], 1) # (h, w, channel=1)\n","                if surface_vol_ is None:\n","                    surface_vol_ = surface_vol\n","                else:\n","                    surface_vol_ = np.concatenate([surface_vol_, surface_vol], axis=2) # (h, w, channel=surface_num)\n","            surface_vols.append(surface_vol_)\n","            # print(f\"  => read surface volume done. [{data_dir}]\")\n","        return surface_vols\n","\n","\n","    def get_grid_img(self, img, grid_idx):\n","        \"\"\" crop grid img from original img\"\"\"\n","        img_grid = img[(grid_idx[0]*self.img_size[0]) + self.slide_pos[0] : ((grid_idx[0]+1)*self.img_size[0]) + self.slide_pos[0],\n","                        (grid_idx[1]*self.img_size[1]) + self.slide_pos[1] : ((grid_idx[1]+1)*self.img_size[1]) + self.slide_pos[1]]\n","        return img_grid\n","    \n","    def get_grid_img_and_mask(self, img, mask, grid_idx):\n","        \"\"\" crop grid img from original img\"\"\"\n","        if self.RANDOM_SLIDE and self.mode==\"train\" and random.random() < 0.5:\n","            if (grid_idx[0]!=0 and grid_idx[1]!=0) and (grid_idx[0]!=img.shape[0]//self.img_size[0] and grid_idx[1]!=img.shape[1]//self.img_size[1]):\n","                rand_pos = [np.random.randint(0, self.img_size[0]//4) - self.img_size[0]//4, np.random.randint(0, self.img_size[1]//4)-self.img_size[1]//4]\n","            else:\n","                rand_pos = [0, 0]\n","        else:\n","            rand_pos = [0, 0]\n","        img_grid = img[(grid_idx[0]*self.img_size[0]) + self.slide_pos[0] + rand_pos[0] : ((grid_idx[0]+1)*self.img_size[0]) + self.slide_pos[0] + rand_pos[0],\n","                        (grid_idx[1]*self.img_size[1]) + self.slide_pos[1] + rand_pos[1] : ((grid_idx[1]+1)*self.img_size[1]) + self.slide_pos[1] + rand_pos[1]]\n","        mask_grid = mask[(grid_idx[0]*self.img_size[0]) + self.slide_pos[0] + rand_pos[0] : ((grid_idx[0]+1)*self.img_size[0]) + self.slide_pos[0] + rand_pos[0],\n","                         (grid_idx[1]*self.img_size[1]) + self.slide_pos[1] + rand_pos[1] : ((grid_idx[1]+1)*self.img_size[1]) + self.slide_pos[1] + rand_pos[1]]\n","        return img_grid/255., mask_grid/255.\n","    \n","    def get_masked_img(self, img, mask):\n","        \"\"\" multiply mask to surface_volumes \"\"\"\n","        masked_img = None\n","        for channel in range(img.shape[2]):\n","            img_channel = img[:,:,channel].reshape(img.shape[0], img.shape[1],1)\n","            masked = img_channel*mask\n","            if masked_img is None:\n","                masked_img = masked.reshape(masked.shape[0], masked.shape[1], 1)\n","            else:\n","                masked = masked.reshape(masked.shape[0], masked.shape[1], 1)\n","                masked_img = np.concatenate([masked_img, masked], axis=2)\n","        return masked_img\n","    \n","    \n","    def get_all_grid(self):\n","        \"\"\" get all grid indices by img size and grid size\n","        \"\"\"\n","        self.grid_indices = []\n","        for img in self.imgs:\n","            self.x_grid_size = (img.shape[0] - self.slide_pos[0]) // self.img_size[0]\n","            self.y_grid_size = (img.shape[1] - self.slide_pos[1]) // self.img_size[1]\n","            grid_img = []\n","            for i in range(self.x_grid_size):\n","                for j in range(self.y_grid_size):\n","                    grid_img.append([i, j])\n","            self.grid_indices.append(grid_img)\n","        return self.grid_indices\n","          \n","    def fileter_grid(self):\n","        \"\"\" get grid indices which mask is not 0 by all grid indices\"\"\"\n","        grid_indices_all = []\n","        for img, grid_indices in zip(self.imgs, self.grid_indices):\n","            grid_indices_copy = grid_indices.copy()\n","            for grid_idx in grid_indices:\n","                img_grid = self.get_grid_img(img, grid_idx)\n","                if img_grid.sum() == 0:\n","                    grid_indices_copy.remove(grid_idx)\n","            grid_indices_all.append(grid_indices_copy)\n","        self.grid_indices = grid_indices_all\n","        return self.grid_indices\n","\n","    def get_flatten_grid(self):\n","        \"\"\" get flatten index list by grid indices\n","            Returns:flatten_grid (list): flatten index list [[img_idx, grid_idx], [img_idx, grid_idx], ...]\n","        \"\"\"\n","        flatten_grid = []\n","        for img_idx, grid_indices in enumerate(self.grid_indices):\n","            for grid_idx in grid_indices:\n","                grid_imgidx_list = [img_idx]\n","                grid_imgidx_list.extend(grid_idx)\n","                flatten_grid.append(grid_imgidx_list)\n","        self.flatten_grid = flatten_grid\n","        return self.flatten_grid\n","    \n","    def channel_shuffle(self, img):\n","        img = img.transpose(2, 0, 1)\n","        np.random.shuffle(img)\n","        return img.transpose(1, 2, 0)\n","\n","    def __len__(self):\n","        return len(self.flatten_grid)\n","\n","    def __getitem__(self, idx):\n","        # get indices\n","        img_grid_idx = self.flatten_grid[idx]\n","        img_idx = img_grid_idx[0]\n","        grid_idx = img_grid_idx[1:]\n","        # get img & surface_vol\n","        mask = self.imgs[img_idx]\n","        surface_vol = self.surface_vols[img_idx]\n","        # mask = self.get_grid_img(mask, grid_idx)/255.\n","        # surface_vol = self.get_grid_img(surface_vol, grid_idx)/255.\n","        mask, surface_vol = self.get_grid_img_and_mask(mask, surface_vol, grid_idx)\n","        # multiple small mask \n","        assert surface_vol.shape[0]==mask.shape[0] and surface_vol.shape[1]==mask.shape[1] , \"surface_vol_list shape is not same as img shape\"\n","        img = surface_vol\n","        # transform\n","        if self.mode == \"test\":\n","            if self.transform:\n","                img = self.transform(image=img)[\"image\"]\n","            else:\n","                img = img.transpose(2, 0, 1)\n","                img = torch.tensor(img, dtype=torch.float32)\n","            return img, grid_idx\n","        elif self.mode == \"train\" or self.mode==\"valid\":\n","            # get label(segmentation mask)\n","            label = self.labels[img_idx]\n","            label = self.get_grid_img(label, grid_idx)\n","            if self.mode == \"train\":\n","                img = self.channel_shuffle(img)\n","            if self.transform:\n","                transformed = self.transform(image=img, mask=label)\n","                img = transformed[\"image\"]\n","                label = transformed[\"mask\"]\n","                label = label.permute(2, 0, 1)/255. # (channel, h, w)\n","                # label = TF.resize(img=label, size=(self.img_size[0]//2, self.img_size[1]//2))\n","            else:\n","                img = img.transpose(2, 0, 1) # (channel, h, w)\n","                label = label.transpose(2, 0, 1)/255. # (channel, h, w){}\n","                img = torch.tensor(img, dtype=torch.float32)\n","                label = torch.tensor(label, dtype=torch.float32)\n","                # label = TF.resize(img=label, size=(self.img_size[0]//2, self.img_size[1]//2))\n","            return img, label, grid_idx\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.115468Z","iopub.status.busy":"2023-04-11T00:41:44.115176Z","iopub.status.idle":"2023-04-11T00:41:44.124975Z","shell.execute_reply":"2023-04-11T00:41:44.123696Z","shell.execute_reply.started":"2023-04-11T00:41:44.115434Z"},"trusted":true},"outputs":[],"source":["# valid_dirs = CFG[\"VALID_DIR_LIST\"][0]\n","# surface_list = SURFACE_LIST[0]\n","# print(\"dataset\")\n","# dataset_notrans = VCID_Dataset(CFG, valid_dirs, surface_list, mode=\"train\")\n","# surface_volumes = dataset_notrans.surface_vols\n","# print(\"dataloader\")\n","# dataloader_notrans = DataLoader(dataset_notrans, 4, shuffle=False, num_workers=0)\n","\n","# imshow_batch = 10\n","\n","# for batch_idx, (imgs, labels, grid_idx) in enumerate(dataloader_notrans):\n","#     img = imgs[0].permute(1, 2, 0)\n","#     if batch_idx < 2:\n","#         plt.figure(figsize=(20,5))\n","#         for channel in range(img.shape[2]):\n","#             plt.subplot(1, img.shape[2], channel+1)\n","#             plt.imshow(img[:,:,channel], cmap=\"gray\")\n","#         plt.show()\n","#         [print(np.max(img[:,:,idx].numpy())) for idx in range(img.shape[2])]\n","        \n","#     if batch_idx >= imshow_batch:\n","#         break    \n","\n","# img_hist, img_bins = np.histogram(np.array(img[:,:,0]).flatten())\n","# plt.figure()\n","# plt.plot(img_hist)\n","# plt.show()\n","# print(img[:,:,0])\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# valid_dirs = CFG[\"VALID_DIR_LIST\"][0]\n","# surface_list = SURFACE_LIST[0]\n","# print(\"dataset\")\n","# dataset_notrans = VCID_Dataset(CFG, valid_dirs, surface_list, mode=\"train\")\n","# surface_volumes = dataset_notrans.surface_vols\n","# print(\"dataloader\")\n","# dataloader_notrans = DataLoader(dataset_notrans, 4, shuffle=False, num_workers=0)\n","\n","# imshow_batch = 10\n","\n","# for batch_idx, (imgs, labels, grid_idx) in enumerate(dataloader_notrans):\n","#     img = imgs[0].permute(1, 2, 0)\n","#     if batch_idx < 2:\n","#         plt.figure(figsize=(20,5))\n","#         for channel in range(img.shape[2]):\n","#             plt.subplot(1, img.shape[2], channel+1)\n","#             plt.imshow(img[:,:,channel], cmap=\"gray\")\n","#         plt.show()\n","#         [print(np.max(img[:,:,idx].numpy())) for idx in range(img.shape[2])]\n","#     if batch_idx >= imshow_batch:\n","#         break    \n","\n","# img_hist, img_bins = np.histogram(np.array(img[:,:,0]).flatten())\n","# plt.figure()\n","# plt.plot(img_hist)\n","# plt.show()\n","# print(img[:,:,0])\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# print(\"dataset\")\n","# dataset_notrans = VCID_Dataset(CFG, valid_dirs, surface_list, surface_volumes, slide_pos=[0,50],mode=\"train\")\n","# print(\"dataloader\")\n","# dataloader_notrans = DataLoader(dataset_notrans, 4, shuffle=False, num_workers=0)\n","\n","# imshow_batch = 10\n","\n","# for batch_idx, (imgs, labels, grid_idx) in enumerate(dataloader_notrans):\n","#     img = imgs[0].permute(1, 2, 0)\n","#     if batch_idx == 1:\n","#         plt.figure(figsize=(20,5))\n","#         for channel in range(img.shape[2]):\n","#             plt.subplot(1, img.shape[2], channel+1)\n","#             plt.imshow(img[:,:,channel], cmap=\"gray\")\n","#         plt.show()\n","#         [print(np.max(img[:,:,idx].numpy())) for idx in range(img.shape[2])]\n","#     if batch_idx >= imshow_batch:\n","#         break    \n","\n","# img_hist, img_bins = np.histogram(np.array(img[:,:,0]).flatten())\n","# plt.figure()\n","# plt.plot(img_hist)\n","# plt.show()\n","# print(img[:,:,0])\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.139137Z","iopub.status.busy":"2023-04-11T00:41:44.138643Z","iopub.status.idle":"2023-04-11T00:41:44.149059Z","shell.execute_reply":"2023-04-11T00:41:44.147985Z","shell.execute_reply.started":"2023-04-11T00:41:44.139095Z"},"trusted":true},"outputs":[],"source":["# valid_dirs = CFG[\"VALID_DIR_LIST\"][0]\n","# surface_list = SURFACE_LIST[0]\n","# print(\"dataset\")\n","# dataset_notrans = VCID_Dataset(CFG, valid_dirs, surface_list, mode=\"train\", transform=train_transforms)\n","# print(\"dataloader\")\n","# dataloader_notrans = DataLoader(dataset_notrans, 4, shuffle=False, num_workers=0)\n","\n","\n","# imshow_batch = 10\n","\n","# for batch_idx, (imgs, labels, grid_idx) in enumerate(dataloader_notrans):\n","#     img = imgs[0].permute(1, 2, 0)\n","#     if batch_idx == 0:\n","#         plt.figure(figsize=(20,5))\n","#         for channel in range(img.shape[2]):\n","#             plt.subplot(1, img.shape[2], channel+1)\n","#             plt.imshow(img[:,:,channel], cmap=\"gray\")\n","#         plt.show()\n","#         [print(np.max(img[:,:,idx].numpy())) for idx in range(img.shape[2])]\n","#     if batch_idx >= imshow_batch:\n","#         break    \n","\n","# img_hist, img_bins = np.histogram(np.array(img[:,:,0]).flatten())\n","# plt.figure()\n","# plt.plot(img_hist)\n","# plt.show()\n","# print(img[:,:,0])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Loss"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["#PyTorch\n","ALPHA = 0.3 # < 0.5 penalises FP more, > 0.5 penalises FN more\n","CE_RATIO = 0.95 #weighted contribution of modified CE loss compared to Dice loss\n","\n","class ComboLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(ComboLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1, alpha=ALPHA, eps=1e-9):\n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","        \n","        #True Positives, False Positives & False Negatives\n","        intersection = (inputs * targets).sum()    \n","        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n","        \n","        inputs = torch.clamp(inputs, eps, 1.0 - eps)       \n","        out = - (ALPHA * ((targets * torch.log(inputs)) + ((1 - ALPHA) * (1.0 - targets) * torch.log(1.0 - inputs))))\n","        weighted_ce = out.mean(-1)\n","        if dice is None:\n","            combo = weighted_ce\n","        else:\n","            combo = (CE_RATIO * weighted_ce) - ((1 - CE_RATIO) * dice)\n","        \n","        return combo"]},{"cell_type":"markdown","metadata":{},"source":["# train valid fn"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.151325Z","iopub.status.busy":"2023-04-11T00:41:44.150944Z","iopub.status.idle":"2023-04-11T00:41:44.163092Z","shell.execute_reply":"2023-04-11T00:41:44.161981Z","shell.execute_reply.started":"2023-04-11T00:41:44.151287Z"},"trusted":true},"outputs":[],"source":["def train_fn(train_loader, model, criterion, epoch ,optimizer, scheduler):\n","    model.train()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets, _) in enumerate(train_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float()     \n","        preds = model(images)\n","        preds = TF.resize(img=preds, size=(CFG[\"img_size\"][0], CFG[\"img_size\"][1]))\n","        # preds = torch.sigmoid(preds)\n","        loss = criterion(preds, targets)\n","        \n","        losses.update(loss.item(), CFG[\"batch_size\"]) \n","        targets = targets.detach().cpu().numpy().ravel().tolist()\n","        preds = preds.detach().cpu().numpy().ravel().tolist()\n","        loss.backward() # パラメータの勾配を計算\n","        optimizer.step() # モデル更新\n","        optimizer.zero_grad() # 勾配の初期化\n","                \n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                    'Elapsed {remain:s} '\n","                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                    .format(\n","                        epoch, batch_idx, len(train_loader), batch_time=batch_time, loss=losses,\n","                        remain=timeSince(start, float(batch_idx+1)/len(train_loader)),\n","            ))\n","        del preds, images, targets\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    return losses.avg"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.165502Z","iopub.status.busy":"2023-04-11T00:41:44.164813Z","iopub.status.idle":"2023-04-11T00:41:44.178372Z","shell.execute_reply":"2023-04-11T00:41:44.177351Z","shell.execute_reply.started":"2023-04-11T00:41:44.16546Z"},"trusted":true},"outputs":[],"source":["def valid_fn(model, valid_loader, criterion=None):\n","    model.eval()# モデルを検証モードに設定\n","    test_targets = []\n","    test_preds = []\n","    test_grid_idx = []\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    for batch_idx, (images, targets, grid_idx) in enumerate(valid_loader):\n","        images = images.to(device, non_blocking = True).float()\n","        targets = targets.to(device, non_blocking = True).float()\n","        with torch.no_grad():\n","            preds = model(images)\n","            preds = TF.resize(img=preds, size=(CFG[\"img_size\"][0], CFG[\"img_size\"][1]))\n","            if not criterion is None:\n","                loss = criterion(preds, targets)\n","        if not criterion is None:\n","            losses.update(loss.item(), CFG[\"batch_size\"])\n","        batch_time.update(time.time() - end)\n","\n","        targets = targets.detach().cpu().numpy()\n","        preds = preds.detach().cpu().numpy()\n","        \n","        test_preds.extend([preds[idx, :,:,:].transpose(1,2,0) for idx in range(preds.shape[0])])\n","        test_targets.extend([targets[idx, :,:,:].transpose(1,2,0) for idx in range(targets.shape[0])])\n","        test_grid_idx.extend([[x_idx, y_idx] for x_idx, y_idx in zip(grid_idx[0].tolist(), grid_idx[1].tolist())])\n","\n","        if (batch_idx % CFG[\"print_freq\"] == 0 or batch_idx == (len(valid_loader)-1)) and (not criterion is None):\n","            print('EVAL: [{0}/{1}] '\n","                'Elapsed {remain:s} '\n","                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                .format(\n","                    batch_idx, len(valid_loader), batch_time=batch_time, loss=losses,\n","                    remain=timeSince(start, float(batch_idx+1)/len(valid_loader)),\n","                ))\n","        del preds, images, targets\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    if criterion is None:\n","        return test_targets, test_preds, test_grid_idx\n","    else:\n","        return test_targets, test_preds, test_grid_idx, losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# training loop"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.181856Z","iopub.status.busy":"2023-04-11T00:41:44.181523Z","iopub.status.idle":"2023-04-11T00:41:44.191323Z","shell.execute_reply":"2023-04-11T00:41:44.190204Z","shell.execute_reply.started":"2023-04-11T00:41:44.181823Z"},"trusted":true},"outputs":[],"source":["# def concat_grid_img(img_list, label_list, grid_idx_list, valid_dir_list):\n","#     # concat pred img and label to original size\n","#     img_path = os.path.join(CFG[\"TRAIN_DIR\"], valid_dir_list[0], \"mask.png\")\n","#     img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","#     img = img.reshape(img.shape[0], img.shape[1], 1)\n","#     pred_img = np.zeros_like(img).astype(np.float32)\n","#     label_img = np.zeros_like(img).astype(np.float32)\n","#     for img_idx, grid_idx in enumerate(grid_idx_list):\n","#         pred_img[grid_idx[0]*CFG[\"img_size\"][0]:(grid_idx[0]+1)*CFG[\"img_size\"][0],\n","#                 grid_idx[1]*CFG[\"img_size\"][1]:(grid_idx[1]+1)*CFG[\"img_size\"][1], :] += img_list[img_idx]\n","        \n","#         label_img[grid_idx[0]*CFG[\"img_size\"][0]:(grid_idx[0]+1)*CFG[\"img_size\"][0],\n","#                 grid_idx[1]*CFG[\"img_size\"][1]:(grid_idx[1]+1)*CFG[\"img_size\"][1], :] += label_list[img_idx]\n","#     return pred_img, label_img"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def concat_grid_img(img_list, label_list, grid_idx_list, valid_dir_list, slide_pos=[0,0]):\n","    # concat pred img and label to original size\n","    img_path = os.path.join(CFG[\"TRAIN_DIR\"], valid_dir_list[0], \"mask.png\")\n","    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","    img = img.reshape(img.shape[0], img.shape[1], 1)\n","    pred_img = np.zeros_like(img).astype(np.float32)\n","    label_img = np.zeros_like(img).astype(np.float32)\n","    for img_idx, grid_idx in enumerate(grid_idx_list):\n","        pred_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","                grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += img_list[img_idx]\n","        \n","        label_img[grid_idx[0]*CFG[\"img_size\"][0]+slide_pos[0] : (grid_idx[0]+1)*CFG[\"img_size\"][0]+slide_pos[0],\n","                grid_idx[1]*CFG[\"img_size\"][1]+slide_pos[1] : (grid_idx[1]+1)*CFG[\"img_size\"][1]+slide_pos[1], :] += label_list[img_idx]\n","    return pred_img, label_img"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def save_and_plot_oof(mode, fold, slice_idx, valid_preds_img, valid_targets_img, valid_preds_binary):\n","    cv2.imwrite(os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\", f\"fold{fold}_{mode}_slice{slice_idx}_valid_pred_img.png\"), valid_preds_img*255)\n","    cv2.imwrite(os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\", f\"fold{fold}_{mode}_slice{slice_idx}_valid_predbin_img.png\"), valid_preds_binary*255)\n","    cv2.imwrite(os.path.join(CFG[\"OUTPUT_DIR\"], \"imgs\", f\"fold{fold}_{mode}_slice{slice_idx}_valid_targets_img.png\"), valid_targets_img*255)\n","    \n","    # plot preds & binary preds\n","    # plt.figure(dpi=100)\n","    # plt.subplot(1,3,1)\n","    # plt.imshow(valid_preds_img)\n","    # plt.subplot(1,3,2)\n","    # plt.imshow(valid_preds_binary)\n","    # plt.subplot(1,3,3)\n","    # plt.imshow(valid_targets_img)\n","    # plt.show()\n","                "]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.193974Z","iopub.status.busy":"2023-04-11T00:41:44.193163Z","iopub.status.idle":"2023-04-11T00:41:44.213205Z","shell.execute_reply":"2023-04-11T00:41:44.212125Z","shell.execute_reply.started":"2023-04-11T00:41:44.193933Z"},"trusted":true},"outputs":[],"source":["def training_loop(CFG):\n","    best_score_list = []\n","    best_threshold_list = []\n","    best_epoch_list = []\n","    slice_ave_score_list = []\n","    slice_ave_auc_list = []\n","    slice_ave_score_threshold_list = []\n","    for fold in CFG[\"folds\"]:\n","        print(f\"-- fold{fold} training start --\")\n"," \n","        # set model & learning fn\n","        model = SegModel(CFG)\n","        model = model.to(device)\n","        valid_img_slice = []\n","        # criterion = nn.BCELoss()\n","        criterion = ComboLoss()\n","        optimizer = AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"], amsgrad=False)\n","        scheduler = CosineAnnealingLR(optimizer, T_max=CFG[\"T_max\"], eta_min=CFG[\"min_lr\"], last_epoch=-1)\n","        # scheduler = ExponentialLR(optimizer, gamma=0.60)\n","        \n","        # training\n","        best_score = -np.inf\n","        best_auc = -np.inf\n","        best_valloss = np.inf\n","        best_auc_valloss = np.inf\n","        best_threshold = -1\n","        start_time = time.time()\n","        best_epoch = -1\n","        best_auc_epoch = -1\n","        valid_slice_ave = None       \n","        for slice_idx, surface_list in enumerate(SURFACE_LIST):\n","            print(\"surface_list: \", surface_list)\n","            # separate train/valid data \n","            train_dirs = CFG[\"TRAIN_DIR_LIST\"][fold]\n","            valid_dirs = CFG[\"VALID_DIR_LIST\"][fold]\n","            train_dataset = VCID_Dataset(CFG, train_dirs, surface_list, mode=\"train\", transform=train_transforms)\n","            valid_dataset = VCID_Dataset(CFG, valid_dirs, surface_list, mode=\"valid\", transform=valid_transforms)\n","            train_loader = DataLoader(train_dataset, batch_size=CFG[\"batch_size\"], shuffle = True,\n","                                        num_workers = CFG[\"num_workers\"], pin_memory = True)\n","            valid_loader = DataLoader(valid_dataset, batch_size=CFG[\"batch_size\"], shuffle = False,\n","                                        num_workers = CFG[\"num_workers\"], pin_memory = True)\n","            for epoch in range(1, CFG[\"n_epoch\"] + 1):\n","                epochs_ = epoch + CFG[\"n_epoch\"] * slice_idx\n","                print(f'- epoch:{epochs_} -')\n","                train_loss_avg = train_fn(train_loader, model, criterion, epochs_ ,optimizer, scheduler)\n","                valid_targets, valid_preds, valid_grid_idx, valid_loss_avg = valid_fn(model, valid_loader, criterion)\n","                \n","                # target, predをconcatして元のサイズに戻す\n","                valid_preds_img, valid_targets_img  = concat_grid_img(valid_preds, valid_targets, valid_grid_idx, valid_dirs)\n","                valid_score, valid_threshold, auc, dice_list = calc_cv(valid_targets_img, valid_preds_img)\n","                valid_preds_binary = (valid_preds_img > valid_threshold).astype(np.uint8)\n","                \n","                elapsed = time.time() - start_time\n","                print(f\"\\t epoch:{epochs_}, avg train loss:{train_loss_avg:.4f}, avg valid loss:{valid_loss_avg:.4f}\")\n","                print(f\"\\t score:{valid_score:.4f}(th={valid_threshold:3f}), auc={auc:4f}::: time:{elapsed:.2f}s\")\n","                if not CFG[\"DEBUG\"]:\n","                    logging_metrics_epoch(CFG, fold, epoch, slice_idx, train_loss_avg, valid_loss_avg, valid_score, valid_threshold, auc)\n","                scheduler.step()\n","                # validationスコアがbestを更新したらモデルを保存する\n","                if valid_score > best_score:\n","                    best_epoch = epochs_\n","                    best_valloss = valid_loss_avg\n","                    best_score = valid_score\n","                    best_threshold = valid_threshold\n","                    model_name = CFG[\"model_name\"]\n","                    model_path = os.path.join(CFG[\"OUTPUT_DIR\"], f'{model_name}_fold{fold}.pth')\n","                    torch.save(model.state_dict(), model_path) \n","                    print(f'Epoch {epochs_} - Save Best Score: {best_score:.4f}. Model is saved.')\n","                    print(\"dice_list: \", dice_list)\n","                    # save oof\n","                    save_and_plot_oof(\"score\", fold, slice_idx, valid_preds_img, valid_targets_img, valid_preds_binary)\n","                \n","                if auc > best_auc:\n","                    best_auc = auc\n","                    best_auc_epoch = epochs_\n","                    best_auc_valloss = valid_loss_avg\n","                    model_name = CFG[\"model_name\"]\n","                    model_path = os.path.join(CFG[\"OUTPUT_DIR\"], f'{model_name}_auc_fold{fold}.pth')\n","                    torch.save(model.state_dict(), model_path) \n","                    print(f'Epoch {epochs_} - Save Best AUC: {best_auc:.4f}. Model is saved.')\n","                    # save oof\n","                    save_and_plot_oof(\"auc\", fold, slice_idx, valid_preds_img, valid_targets_img, valid_preds_binary)\n","            # valid_img_slice.append(valid_preds_img)\n","            if valid_slice_ave is None:\n","                valid_slice_ave = valid_preds_img\n","            else:\n","                valid_slice_ave += valid_preds_img\n","        # valid_slice_ave = np.zeros((valid_preds_img.shape[0], valid_preds_img.shape[1], 1))\n","        # for idx in range(len(SURFACE_LIST)):\n","        #     valid_pred_slice = valid_img_slice[idx]\n","        #     valid_slice_ave += valid_pred_slice\n","        valid_slice_ave /= len(SURFACE_LIST)\n","        valid_sliceave_score, valid_sliceave_threshold, ave_auc, dice_list = calc_cv(valid_targets_img, valid_slice_ave)\n","        \n","        slice_ave_score_list.append(valid_sliceave_score)\n","        slice_ave_auc_list.append(ave_auc)\n","        slice_ave_score_threshold_list.append(valid_sliceave_threshold)\n"," \n","        valid_slice_binary = (valid_slice_ave > valid_sliceave_threshold).astype(np.uint8)\n","        save_and_plot_oof(\"average\", fold, 999, valid_slice_ave, valid_targets_img, valid_slice_binary)\n","        print(f'[fold{fold}] slice ave score:{valid_sliceave_score:.4f}(th={valid_sliceave_threshold:3f}), auc={ave_auc:4f}')\n","        \n","        print(f'[fold{fold}] BEST Epoch {best_epoch} - Save Best Score:{best_score:.4f}. Best loss:{best_valloss:.4f}')\n","        print(f'[fold{fold}] BEST AUC Epoch {best_auc_epoch} - Save Best Score:{best_auc:.4f}. Best loss:{best_auc_valloss:.4f}')\n","            \n","        best_score_list.append(best_score)\n","        best_threshold_list.append(best_threshold)\n","        best_epoch_list.append(best_epoch)\n","        del model, train_loader, train_dataset, valid_loader, valid_dataset, valid_preds_img, valid_targets_img, valid_preds_binary\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        \n","    for fold, (best_score, best_threshold, best_epoch) in enumerate(zip(best_score_list, best_threshold_list, best_epoch_list)):\n","        print(f\"fold[{fold}] BEST SCORE = {best_score:.4f} thr={best_threshold} (epoch={best_epoch})\")\n","        print(f\"fold[{fold}] slice ave score:{slice_ave_score_list[fold]:.4f}(th={slice_ave_score_threshold_list[fold]:3f}), auc={slice_ave_auc_list[fold]:4f}\")\n","    return best_score_list, best_threshold_list, best_epoch_list"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# slice inference"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def slide_inference(CFG):\n","    start_time = time.time()\n","    slice_ave_score_list, slice_ave_auc_list, slice_ave_score_threshold_list = [], [], []\n","    for fold in CFG[\"folds\"]:\n","        print(f\"-- fold{fold} slide inference start --\")\n"," \n","        # set model & learning fn\n","        model = SegModel(CFG)\n","        # model_path = os.path.join(CFG[\"OUTPUT_DIR\"], f'{CFG[\"model_name\"]}_fold{fold}.pth')\n","        model_path = os.path.join(CFG[\"OUTPUT_DIR\"], f'{CFG[\"model_name\"]}_auc_fold{fold}.pth')\n","        model.load_state_dict(torch.load(model_path))\n","        model = model.to(device)\n","        valid_img_slice = None\n","        for slice_idx, surface_list in enumerate(SURFACE_LIST):\n","            print(\"surface_list: \", surface_list)\n","            surface_volumes = None\n","            for slide_pos in CFG[\"slide_pos_list\"]:\n","                print(\"slide pos:\", slide_pos)\n","                valid_dirs = CFG[\"VALID_DIR_LIST\"][fold]\n","                valid_dataset = VCID_Dataset(CFG, valid_dirs, surface_list, surface_volumes, slide_pos, mode=\"valid\", transform=valid_transforms)\n","                surface_volumes = valid_dataset.get_surface_volumes()\n","                valid_loader = DataLoader(valid_dataset, batch_size=CFG[\"batch_size\"], shuffle = False,\n","                                            num_workers = CFG[\"num_workers\"], pin_memory = True)\n","\n","                valid_targets, valid_preds, valid_grid_idx = valid_fn(model, valid_loader)\n","                \n","                # target, predをconcatして元のサイズに戻す\n","                valid_preds_img, valid_targets_img  = concat_grid_img(valid_preds, valid_targets, valid_grid_idx, valid_dirs, slide_pos)\n","                valid_score, valid_threshold, auc, dice_list = calc_cv(valid_targets_img, valid_preds_img)\n","                valid_preds_binary = (valid_preds_img > valid_threshold).astype(np.uint8)\n","                save_and_plot_oof(\"slide\", fold, slice_idx, valid_preds_img, valid_targets_img, valid_preds_binary) \n","                \n","                elapsed = time.time() - start_time\n","                print(f\"\\t score:{valid_score:.4f}(th={valid_threshold:3f}), auc={auc:4f}::: time:{elapsed:.2f}s\")\n","                # valid_img_slice.append(valid_preds_img)\n","                if valid_img_slice is None:\n","                    valid_img_slice = valid_preds_img\n","                else:\n","                    valid_img_slice += valid_preds_img\n","            # valid_slice_ave = np.zeros((valid_preds_img.shape[0], valid_preds_img.shape[1], 1))\n","        # for idx in range(len(SURFACE_LIST)*len(CFG[\"slide_pos_list\"])):\n","        #     valid_pred_slice = valid_img_slice[idx]\n","        #     valid_slice_ave += valid_pred_slice\n","        valid_img_slice /= len(SURFACE_LIST)*len(CFG[\"slide_pos_list\"])\n","        valid_sliceave_score, valid_sliceave_threshold, ave_auc, dice_list = calc_cv(valid_targets_img, valid_img_slice)\n","        \n","        slice_ave_score_list.append(valid_sliceave_score)\n","        slice_ave_auc_list.append(ave_auc)\n","        slice_ave_score_threshold_list.append(valid_sliceave_threshold)\n","\n","        valid_slice_binary = (valid_img_slice > valid_sliceave_threshold).astype(np.uint8)\n","        save_and_plot_oof(\"average\", fold, 555, valid_img_slice, valid_targets_img, valid_slice_binary)\n","        print(f'[fold{fold}] slice ave score:{valid_sliceave_score:.4f}(th={valid_sliceave_threshold:3f}), auc={ave_auc:4f}')\n","         \n","        del model, valid_loader, valid_dataset, valid_preds_img, valid_targets_img, valid_preds_binary\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    return slice_ave_score_list, slice_ave_auc_list, slice_ave_score_threshold_list\n"]},{"cell_type":"markdown","metadata":{},"source":["# main"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T00:41:44.21531Z","iopub.status.busy":"2023-04-11T00:41:44.214927Z","iopub.status.idle":"2023-04-11T00:48:24.178417Z","shell.execute_reply":"2023-04-11T00:48:24.176805Z","shell.execute_reply.started":"2023-04-11T00:41:44.215273Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["-- fold0 training start --\n","surface_list:  [26, 29, 32, 35]\n","- epoch:1 -\n","Epoch: [1][0/65] Elapsed 0m 1s (remain 1m 26s) Loss: 0.1543(0.1543) \n","Epoch: [1][64/65] Elapsed 0m 30s (remain 0m 0s) Loss: 0.0568(0.1010) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0201(0.0201) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0693(0.0658) \n","\t epoch:1, avg train loss:0.1010, avg valid loss:0.0658\n","\t score:0.3662(th=0.350000), auc=0.827929::: time:74.65s\n","Epoch 1 - Save Best Score: 0.3662. Model is saved.\n","dice_list:  [0.2267689628380989, 0.2832639781887172, 0.32623275392317935, 0.3519563434438633, 0.363890070159746, 0.36620987132086275, 0.36264272183007984, 0.3549414026689557, 0.34482944630416823, 0.33274241254501147, 0.31802592742089725, 0.3001909883484754, 0.27773917041415724, 0.25086433615780823, 0.21807000624927858, 0.17823191066565988, 0.12781693034175093, 0.07033529051790963, 0.0]\n","Epoch 1 - Save Best AUC: 0.8279. Model is saved.\n","- epoch:2 -\n","Epoch: [2][0/65] Elapsed 0m 1s (remain 1m 27s) Loss: 0.0783(0.0783) \n","Epoch: [2][64/65] Elapsed 0m 30s (remain 0m 0s) Loss: 0.0629(0.0907) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 3s) Loss: 0.0469(0.0469) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0571(0.0675) \n","\t epoch:2, avg train loss:0.0907, avg valid loss:0.0675\n","\t score:0.3460(th=0.500000), auc=0.851692::: time:123.66s\n","Epoch 2 - Save Best AUC: 0.8517. Model is saved.\n","- epoch:3 -\n","Epoch: [3][0/65] Elapsed 0m 1s (remain 1m 15s) Loss: 0.0707(0.0707) \n","Epoch: [3][64/65] Elapsed 0m 30s (remain 0m 0s) Loss: 0.1691(0.0904) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0282(0.0282) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0619(0.0566) \n","\t epoch:3, avg train loss:0.0904, avg valid loss:0.0566\n","\t score:0.4345(th=0.500000), auc=0.871322::: time:171.78s\n","Epoch 3 - Save Best Score: 0.4345. Model is saved.\n","dice_list:  [0.2187280093451135, 0.25158472527197184, 0.286290716349425, 0.3203759186290551, 0.35311227904535586, 0.3825821301387392, 0.40754992204683355, 0.4262927304942741, 0.4345082242094036, 0.4275337740309528, 0.3968119261156309, 0.33121715425518783, 0.2321749687463776, 0.12624953682795304, 0.04827377922044546, 0.010806704121905111, 0.0007170936616077325, 0.0, 0.0]\n","Epoch 3 - Save Best AUC: 0.8713. Model is saved.\n","- epoch:4 -\n","Epoch: [4][0/65] Elapsed 0m 1s (remain 1m 9s) Loss: 0.1059(0.1059) \n","Epoch: [4][64/65] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0641(0.0851) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0337(0.0337) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0566(0.0550) \n","\t epoch:4, avg train loss:0.0851, avg valid loss:0.0550\n","\t score:0.4575(th=0.550000), auc=0.883170::: time:220.28s\n","Epoch 4 - Save Best Score: 0.4575. Model is saved.\n","dice_list:  [0.21719437632543542, 0.27812957175374287, 0.324667045925255, 0.3607611830367805, 0.38838223985261605, 0.40953286005747563, 0.4259043750686701, 0.43982766131690193, 0.45166212552705226, 0.45750608045256597, 0.45150964279146755, 0.4294316504545365, 0.3861148724167055, 0.3171320183726362, 0.21732630198131356, 0.10562540491357453, 0.025570184435456025, 0.000505437355380842, 0.0]\n","Epoch 4 - Save Best AUC: 0.8832. Model is saved.\n","- epoch:5 -\n","Epoch: [5][0/65] Elapsed 0m 1s (remain 1m 22s) Loss: 0.0747(0.0747) \n","Epoch: [5][64/65] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0693(0.0805) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0327(0.0327) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0543(0.0536) \n","\t epoch:5, avg train loss:0.0805, avg valid loss:0.0536\n","\t score:0.4847(th=0.550000), auc=0.886085::: time:268.78s\n","Epoch 5 - Save Best Score: 0.4847. Model is saved.\n","dice_list:  [0.21446891978984495, 0.2815439972045124, 0.3351846113693597, 0.37534900630865176, 0.40415508361425234, 0.42627364840798654, 0.4457917491659466, 0.46317627314804943, 0.47725785723520986, 0.4847023069398895, 0.47955604475107183, 0.45652754078722696, 0.4050048000208916, 0.3186231514428213, 0.20619735794080526, 0.10284637646984256, 0.0361231554686077, 0.002973455423787993, 0.0]\n","Epoch 5 - Save Best AUC: 0.8861. Model is saved.\n","- epoch:6 -\n","Epoch: [6][0/65] Elapsed 0m 1s (remain 1m 21s) Loss: 0.0498(0.0498) \n","Epoch: [6][64/65] Elapsed 0m 29s (remain 0m 0s) Loss: 0.1216(0.0804) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0323(0.0323) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0520(0.0528) \n","\t epoch:6, avg train loss:0.0804, avg valid loss:0.0528\n","\t score:0.4847(th=0.600000), auc=0.887562::: time:316.93s\n","Epoch 6 - Save Best Score: 0.4847. Model is saved.\n","dice_list:  [0.21687172677918234, 0.2760525476316568, 0.3240039834332356, 0.3616676792333807, 0.3909718182898262, 0.4135392788193728, 0.4325192263660403, 0.4500983177885266, 0.46665282304373235, 0.47935694203543566, 0.4847075873684081, 0.4768067098668264, 0.44868898893509124, 0.3897588875277316, 0.28854637291961166, 0.15794861168625182, 0.05659248832014521, 0.006613499593169498, 0.0]\n","Epoch 6 - Save Best AUC: 0.8876. Model is saved.\n","- epoch:7 -\n","Epoch: [7][0/65] Elapsed 0m 1s (remain 1m 18s) Loss: 0.0747(0.0747) \n","Epoch: [7][64/65] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0773(0.0777) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0357(0.0357) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0494(0.0523) \n","\t epoch:7, avg train loss:0.0777, avg valid loss:0.0523\n","\t score:0.4899(th=0.600000), auc=0.886354::: time:364.98s\n","Epoch 7 - Save Best Score: 0.4899. Model is saved.\n","dice_list:  [0.23223022934050577, 0.2934508287003798, 0.34170062666657564, 0.3771666563566208, 0.40454450174572953, 0.4259507341932026, 0.44300688980448166, 0.4573961407987959, 0.470596616537861, 0.482682180250128, 0.4898908659036333, 0.4880462501718262, 0.4732021757246843, 0.43657281638447165, 0.3681064889698578, 0.2510213789670387, 0.10564497815190363, 0.01773190105724596, 0.0]\n","- epoch:8 -\n","Epoch: [8][0/65] Elapsed 0m 1s (remain 1m 22s) Loss: 0.0696(0.0696) \n","Epoch: [8][64/65] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0527(0.0789) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0333(0.0333) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0520(0.0541) \n","\t epoch:8, avg train loss:0.0789, avg valid loss:0.0541\n","\t score:0.4724(th=0.600000), auc=0.883553::: time:411.22s\n","- epoch:9 -\n","Epoch: [9][0/65] Elapsed 0m 1s (remain 1m 26s) Loss: 0.0865(0.0865) \n","Epoch: [9][64/65] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0661(0.0815) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0236(0.0236) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0522(0.0543) \n","\t epoch:9, avg train loss:0.0815, avg valid loss:0.0543\n","\t score:0.4884(th=0.500000), auc=0.881889::: time:455.86s\n","- epoch:10 -\n","Epoch: [10][0/65] Elapsed 0m 1s (remain 1m 25s) Loss: 0.0721(0.0721) \n","Epoch: [10][64/65] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0750(0.0821) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0426(0.0426) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0502(0.0645) \n","\t epoch:10, avg train loss:0.0821, avg valid loss:0.0645\n","\t score:0.4297(th=0.650000), auc=0.859411::: time:500.52s\n","- epoch:11 -\n","Epoch: [11][0/65] Elapsed 0m 1s (remain 1m 22s) Loss: 0.0619(0.0619) \n","Epoch: [11][64/65] Elapsed 0m 29s (remain 0m 0s) Loss: 0.1401(0.0797) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0222(0.0222) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0895(0.0683) \n","\t epoch:11, avg train loss:0.0797, avg valid loss:0.0683\n","\t score:0.3727(th=0.350000), auc=0.824675::: time:545.19s\n","- epoch:12 -\n","Epoch: [12][0/65] Elapsed 0m 1s (remain 1m 30s) Loss: 0.0588(0.0588) \n","Epoch: [12][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0503(0.0807) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0291(0.0291) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0539(0.0597) \n","\t epoch:12, avg train loss:0.0807, avg valid loss:0.0597\n","\t score:0.4221(th=0.450000), auc=0.859525::: time:589.70s\n","- epoch:13 -\n","Epoch: [13][0/65] Elapsed 0m 1s (remain 1m 19s) Loss: 0.1069(0.1069) \n","Epoch: [13][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0605(0.0759) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0172(0.0172) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0608(0.0596) \n","\t epoch:13, avg train loss:0.0759, avg valid loss:0.0596\n","\t score:0.4452(th=0.650000), auc=0.873681::: time:633.44s\n","- epoch:14 -\n","Epoch: [14][0/65] Elapsed 0m 1s (remain 1m 25s) Loss: 0.0728(0.0728) \n","Epoch: [14][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0892(0.0719) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0211(0.0211) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0477(0.0557) \n","\t epoch:14, avg train loss:0.0719, avg valid loss:0.0557\n","\t score:0.5279(th=0.650000), auc=0.870022::: time:677.17s\n","Epoch 14 - Save Best Score: 0.5279. Model is saved.\n","dice_list:  [0.20075493271311404, 0.23188470177059076, 0.26485484149226013, 0.30129325374372934, 0.33863825966280087, 0.37462000682243096, 0.41269752711191404, 0.4482253750480325, 0.4776707762725634, 0.5016658895540484, 0.5205567055965574, 0.5279129304722086, 0.5183794239009573, 0.4940621955280202, 0.42637752181001837, 0.3072990575910904, 0.14917590103720998, 0.006135383612620646, 0.0]\n","- epoch:15 -\n","Epoch: [15][0/65] Elapsed 0m 1s (remain 1m 24s) Loss: 0.0692(0.0692) \n","Epoch: [15][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0530(0.0672) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0205(0.0205) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0534(0.0535) \n","\t epoch:15, avg train loss:0.0672, avg valid loss:0.0535\n","\t score:0.5322(th=0.700000), auc=0.872449::: time:722.30s\n","Epoch 15 - Save Best Score: 0.5322. Model is saved.\n","dice_list:  [0.2193072972866333, 0.2513328368474682, 0.2889132540212816, 0.33236171737060693, 0.37349944598676305, 0.4095511149750982, 0.440536747410618, 0.4677788475475349, 0.4896904090236136, 0.5072114030377358, 0.5198620352216259, 0.529945007078183, 0.5322467288994688, 0.5142550820854832, 0.4692196610995419, 0.3739612454664316, 0.2147910940786591, 0.03640061886974551, 0.0]\n","- epoch:16 -\n","Epoch: [16][0/65] Elapsed 0m 1s (remain 1m 24s) Loss: 0.0531(0.0531) \n","Epoch: [16][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.4352(0.0711) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0178(0.0178) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0550(0.0520) \n","\t epoch:16, avg train loss:0.0711, avg valid loss:0.0520\n","\t score:0.5335(th=0.650000), auc=0.875293::: time:767.44s\n","Epoch 16 - Save Best Score: 0.5335. Model is saved.\n","dice_list:  [0.23214094135660363, 0.2708669349143595, 0.31683936882044306, 0.3630127309765315, 0.4018591570607314, 0.4327016174121017, 0.4585463792658843, 0.48136736183105494, 0.5009368499321046, 0.5167989584012794, 0.5269012762705093, 0.53353646503756, 0.5299536160849182, 0.5035375022463994, 0.4483839804567568, 0.34451988416580265, 0.194684138143619, 0.030448271694292973, 0.0]\n","- epoch:17 -\n","Epoch: [17][0/65] Elapsed 0m 1s (remain 1m 28s) Loss: 0.0874(0.0874) \n","Epoch: [17][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0583(0.0670) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0240(0.0240) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0495(0.0533) \n","\t epoch:17, avg train loss:0.0670, avg valid loss:0.0533\n","\t score:0.5245(th=0.650000), auc=0.870079::: time:812.41s\n","- epoch:18 -\n","Epoch: [18][0/65] Elapsed 0m 1s (remain 1m 21s) Loss: 0.0586(0.0586) \n","Epoch: [18][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0542(0.0682) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0335(0.0335) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0438(0.0524) \n","\t epoch:18, avg train loss:0.0682, avg valid loss:0.0524\n","\t score:0.5247(th=0.700000), auc=0.882233::: time:856.31s\n","- epoch:19 -\n","Epoch: [19][0/65] Elapsed 0m 1s (remain 1m 28s) Loss: 0.0909(0.0909) \n","Epoch: [19][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.3990(0.0747) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0355(0.0355) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0421(0.0577) \n","\t epoch:19, avg train loss:0.0747, avg valid loss:0.0577\n","\t score:0.4658(th=0.700000), auc=0.872059::: time:900.59s\n","- epoch:20 -\n","Epoch: [20][0/65] Elapsed 0m 1s (remain 1m 20s) Loss: 0.0618(0.0618) \n","Epoch: [20][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0811(0.0749) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0350(0.0350) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0453(0.0542) \n","\t epoch:20, avg train loss:0.0749, avg valid loss:0.0542\n","\t score:0.4798(th=0.550000), auc=0.876234::: time:944.36s\n","surface_list:  [27, 30, 33, 36]\n","- epoch:21 -\n","Epoch: [21][0/65] Elapsed 0m 1s (remain 1m 25s) Loss: 0.0497(0.0497) \n","Epoch: [21][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.1694(0.0750) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0149(0.0149) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0540(0.0524) \n","\t epoch:21, avg train loss:0.0750, avg valid loss:0.0524\n","\t score:0.4892(th=0.500000), auc=0.879444::: time:1013.95s\n","- epoch:22 -\n","Epoch: [22][0/65] Elapsed 0m 1s (remain 1m 19s) Loss: 0.0591(0.0591) \n","Epoch: [22][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0566(0.0730) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0104(0.0104) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0598(0.0539) \n","\t epoch:22, avg train loss:0.0730, avg valid loss:0.0539\n","\t score:0.5039(th=0.500000), auc=0.866879::: time:1057.33s\n","- epoch:23 -\n","Epoch: [23][0/65] Elapsed 0m 1s (remain 1m 21s) Loss: 0.0543(0.0543) \n","Epoch: [23][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0382(0.0672) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0147(0.0147) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0548(0.0517) \n","\t epoch:23, avg train loss:0.0672, avg valid loss:0.0517\n","\t score:0.5209(th=0.600000), auc=0.879377::: time:1100.96s\n","- epoch:24 -\n","Epoch: [24][0/65] Elapsed 0m 1s (remain 1m 19s) Loss: 0.0570(0.0570) \n","Epoch: [24][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.1114(0.0652) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0183(0.0183) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0394(0.0521) \n","\t epoch:24, avg train loss:0.0652, avg valid loss:0.0521\n","\t score:0.5168(th=0.650000), auc=0.880379::: time:1144.52s\n","- epoch:25 -\n","Epoch: [25][0/65] Elapsed 0m 1s (remain 1m 20s) Loss: 0.0608(0.0608) \n","Epoch: [25][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.1990(0.0620) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0153(0.0153) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0396(0.0511) \n","\t epoch:25, avg train loss:0.0620, avg valid loss:0.0511\n","\t score:0.5229(th=0.650000), auc=0.880750::: time:1188.32s\n","- epoch:26 -\n","Epoch: [26][0/65] Elapsed 0m 1s (remain 1m 19s) Loss: 0.0943(0.0943) \n","Epoch: [26][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.2817(0.0607) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0168(0.0168) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0387(0.0519) \n","\t epoch:26, avg train loss:0.0607, avg valid loss:0.0519\n","\t score:0.5196(th=0.650000), auc=0.879939::: time:1232.36s\n","- epoch:27 -\n","Epoch: [27][0/65] Elapsed 0m 1s (remain 1m 28s) Loss: 0.0825(0.0825) \n","Epoch: [27][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0519(0.0592) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0102(0.0102) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0443(0.0516) \n","\t epoch:27, avg train loss:0.0592, avg valid loss:0.0516\n","\t score:0.5299(th=0.600000), auc=0.873394::: time:1276.33s\n","- epoch:28 -\n","Epoch: [28][0/65] Elapsed 0m 1s (remain 1m 29s) Loss: 0.0504(0.0504) \n","Epoch: [28][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.1773(0.0609) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0120(0.0120) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0520(0.0530) \n","\t epoch:28, avg train loss:0.0609, avg valid loss:0.0530\n","\t score:0.4987(th=0.450000), auc=0.876412::: time:1320.14s\n","- epoch:29 -\n","Epoch: [29][0/65] Elapsed 0m 1s (remain 1m 27s) Loss: 0.0340(0.0340) \n","Epoch: [29][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.3163(0.0711) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0234(0.0234) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0526(0.0563) \n","\t epoch:29, avg train loss:0.0711, avg valid loss:0.0563\n","\t score:0.4793(th=0.700000), auc=0.869923::: time:1364.22s\n","- epoch:30 -\n","Epoch: [30][0/65] Elapsed 0m 1s (remain 1m 23s) Loss: 0.0659(0.0659) \n","Epoch: [30][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0513(0.0684) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0472(0.0472) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0527(0.0682) \n","\t epoch:30, avg train loss:0.0684, avg valid loss:0.0682\n","\t score:0.4700(th=0.800000), auc=0.872653::: time:1407.83s\n","- epoch:31 -\n","Epoch: [31][0/65] Elapsed 0m 1s (remain 1m 18s) Loss: 0.0471(0.0471) \n","Epoch: [31][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0894(0.0679) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0662(0.0662) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0456(0.0635) \n","\t epoch:31, avg train loss:0.0679, avg valid loss:0.0635\n","\t score:0.4640(th=0.750000), auc=0.876647::: time:1451.60s\n","- epoch:32 -\n","Epoch: [32][0/65] Elapsed 0m 1s (remain 1m 21s) Loss: 0.0762(0.0762) \n","Epoch: [32][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.1508(0.0690) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0406(0.0406) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0541(0.0580) \n","\t epoch:32, avg train loss:0.0690, avg valid loss:0.0580\n","\t score:0.4742(th=0.700000), auc=0.880173::: time:1495.24s\n","- epoch:33 -\n","Epoch: [33][0/65] Elapsed 0m 1s (remain 1m 29s) Loss: 0.0614(0.0614) \n","Epoch: [33][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.3107(0.0671) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0230(0.0230) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0553(0.0520) \n","\t epoch:33, avg train loss:0.0671, avg valid loss:0.0520\n","\t score:0.5093(th=0.600000), auc=0.877004::: time:1539.52s\n","- epoch:34 -\n","Epoch: [34][0/65] Elapsed 0m 1s (remain 1m 22s) Loss: 0.0441(0.0441) \n","Epoch: [34][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0499(0.0591) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0266(0.0266) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0539(0.0529) \n","\t epoch:34, avg train loss:0.0591, avg valid loss:0.0529\n","\t score:0.5086(th=0.650000), auc=0.875589::: time:1583.16s\n","- epoch:35 -\n","Epoch: [35][0/65] Elapsed 0m 1s (remain 1m 20s) Loss: 0.0455(0.0455) \n","Epoch: [35][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0374(0.0563) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0214(0.0214) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0556(0.0522) \n","\t epoch:35, avg train loss:0.0563, avg valid loss:0.0522\n","\t score:0.5165(th=0.650000), auc=0.877727::: time:1626.65s\n","- epoch:36 -\n","Epoch: [36][0/65] Elapsed 0m 1s (remain 1m 27s) Loss: 0.0524(0.0524) \n","Epoch: [36][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0712(0.0566) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0220(0.0220) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0561(0.0522) \n","\t epoch:36, avg train loss:0.0566, avg valid loss:0.0522\n","\t score:0.5217(th=0.650000), auc=0.879233::: time:1670.32s\n","- epoch:37 -\n","Epoch: [37][0/65] Elapsed 0m 1s (remain 1m 22s) Loss: 0.0335(0.0335) \n","Epoch: [37][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0694(0.0524) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0205(0.0205) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0576(0.0515) \n","\t epoch:37, avg train loss:0.0524, avg valid loss:0.0515\n","\t score:0.5186(th=0.650000), auc=0.879651::: time:1713.68s\n","- epoch:38 -\n","Epoch: [38][0/65] Elapsed 0m 1s (remain 1m 22s) Loss: 0.0578(0.0578) \n","Epoch: [38][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0504(0.0553) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0370(0.0370) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0519(0.0628) \n","\t epoch:38, avg train loss:0.0553, avg valid loss:0.0628\n","\t score:0.4880(th=0.800000), auc=0.876347::: time:1758.10s\n","- epoch:39 -\n","Epoch: [39][0/65] Elapsed 0m 1s (remain 1m 33s) Loss: 0.0493(0.0493) \n","Epoch: [39][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0556(0.0602) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0495(0.0495) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0537(0.0710) \n","\t epoch:39, avg train loss:0.0602, avg valid loss:0.0710\n","\t score:0.4795(th=0.800000), auc=0.880186::: time:1802.12s\n","- epoch:40 -\n","Epoch: [40][0/65] Elapsed 0m 1s (remain 1m 31s) Loss: 0.0380(0.0380) \n","Epoch: [40][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0487(0.0602) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0511(0.0511) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0467(0.0682) \n","\t epoch:40, avg train loss:0.0602, avg valid loss:0.0682\n","\t score:0.4378(th=0.750000), auc=0.874976::: time:1845.61s\n","surface_list:  [25, 28, 31, 34]\n","- epoch:41 -\n","Epoch: [41][0/65] Elapsed 0m 1s (remain 1m 25s) Loss: 0.0627(0.0627) \n","Epoch: [41][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0567(0.0662) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0354(0.0354) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0555(0.0580) \n","\t epoch:41, avg train loss:0.0662, avg valid loss:0.0580\n","\t score:0.5061(th=0.600000), auc=0.872006::: time:1917.64s\n","- epoch:42 -\n","Epoch: [42][0/65] Elapsed 0m 1s (remain 1m 20s) Loss: 0.0568(0.0568) \n","Epoch: [42][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.1846(0.0688) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0069(0.0069) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0753(0.0609) \n","\t epoch:42, avg train loss:0.0688, avg valid loss:0.0609\n","\t score:0.4659(th=0.450000), auc=0.848742::: time:1961.95s\n","- epoch:43 -\n","Epoch: [43][0/65] Elapsed 0m 1s (remain 1m 27s) Loss: 0.0591(0.0591) \n","Epoch: [43][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0618(0.0696) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0373(0.0373) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0589(0.0598) \n","\t epoch:43, avg train loss:0.0696, avg valid loss:0.0598\n","\t score:0.4977(th=0.700000), auc=0.878989::: time:2005.66s\n","- epoch:44 -\n","Epoch: [44][0/65] Elapsed 0m 1s (remain 1m 29s) Loss: 0.0682(0.0682) \n","Epoch: [44][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0482(0.0643) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0313(0.0313) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0590(0.0572) \n","\t epoch:44, avg train loss:0.0643, avg valid loss:0.0572\n","\t score:0.4876(th=0.600000), auc=0.860766::: time:2049.81s\n","- epoch:45 -\n","Epoch: [45][0/65] Elapsed 0m 1s (remain 1m 32s) Loss: 0.0592(0.0592) \n","Epoch: [45][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0625(0.0567) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0313(0.0313) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0560(0.0574) \n","\t epoch:45, avg train loss:0.0567, avg valid loss:0.0574\n","\t score:0.5136(th=0.700000), auc=0.865796::: time:2093.52s\n","- epoch:46 -\n","Epoch: [46][0/65] Elapsed 0m 1s (remain 1m 24s) Loss: 0.0589(0.0589) \n","Epoch: [46][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0213(0.0559) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0287(0.0287) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0574(0.0556) \n","\t epoch:46, avg train loss:0.0559, avg valid loss:0.0556\n","\t score:0.5008(th=0.650000), auc=0.866396::: time:2137.13s\n","- epoch:47 -\n","Epoch: [47][0/65] Elapsed 0m 1s (remain 1m 22s) Loss: 0.0465(0.0465) \n","Epoch: [47][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0155(0.0554) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0293(0.0293) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0600(0.0553) \n","\t epoch:47, avg train loss:0.0554, avg valid loss:0.0553\n","\t score:0.5067(th=0.650000), auc=0.866068::: time:2180.89s\n","- epoch:48 -\n","Epoch: [48][0/65] Elapsed 0m 1s (remain 1m 23s) Loss: 0.0520(0.0520) \n","Epoch: [48][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0655(0.0565) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0467(0.0467) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0565(0.0648) \n","\t epoch:48, avg train loss:0.0565, avg valid loss:0.0648\n","\t score:0.4891(th=0.800000), auc=0.866406::: time:2224.98s\n","- epoch:49 -\n","Epoch: [49][0/65] Elapsed 0m 1s (remain 1m 29s) Loss: 0.0466(0.0466) \n","Epoch: [49][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0616(0.0566) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0238(0.0238) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0543(0.0553) \n","\t epoch:49, avg train loss:0.0566, avg valid loss:0.0553\n","\t score:0.5059(th=0.650000), auc=0.865707::: time:2268.68s\n","- epoch:50 -\n","Epoch: [50][0/65] Elapsed 0m 1s (remain 1m 22s) Loss: 0.0500(0.0500) \n","Epoch: [50][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0722(0.0589) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0292(0.0292) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0576(0.0535) \n","\t epoch:50, avg train loss:0.0589, avg valid loss:0.0535\n","\t score:0.5232(th=0.700000), auc=0.879014::: time:2312.41s\n","- epoch:51 -\n","Epoch: [51][0/65] Elapsed 0m 1s (remain 1m 25s) Loss: 0.0491(0.0491) \n","Epoch: [51][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0549(0.0610) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0345(0.0345) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0675(0.0577) \n","\t epoch:51, avg train loss:0.0610, avg valid loss:0.0577\n","\t score:0.4930(th=0.700000), auc=0.863563::: time:2356.36s\n","- epoch:52 -\n","Epoch: [52][0/65] Elapsed 0m 1s (remain 1m 29s) Loss: 0.0776(0.0776) \n","Epoch: [52][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0625(0.0619) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0284(0.0284) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0630(0.0559) \n","\t epoch:52, avg train loss:0.0619, avg valid loss:0.0559\n","\t score:0.4764(th=0.650000), auc=0.870051::: time:2400.04s\n","- epoch:53 -\n","Epoch: [53][0/65] Elapsed 0m 1s (remain 1m 22s) Loss: 0.0505(0.0505) \n","Epoch: [53][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0425(0.0546) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0123(0.0123) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0756(0.0522) \n","\t epoch:53, avg train loss:0.0546, avg valid loss:0.0522\n","\t score:0.5006(th=0.600000), auc=0.877792::: time:2443.62s\n","- epoch:54 -\n","Epoch: [54][0/65] Elapsed 0m 1s (remain 1m 23s) Loss: 0.0127(0.0127) \n","Epoch: [54][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0456(0.0537) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0145(0.0145) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0636(0.0524) \n","\t epoch:54, avg train loss:0.0537, avg valid loss:0.0524\n","\t score:0.5106(th=0.600000), auc=0.877635::: time:2487.23s\n","- epoch:55 -\n","Epoch: [55][0/65] Elapsed 0m 1s (remain 1m 23s) Loss: 0.0574(0.0574) \n","Epoch: [55][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0915(0.0467) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0139(0.0139) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0646(0.0537) \n","\t epoch:55, avg train loss:0.0467, avg valid loss:0.0537\n","\t score:0.5199(th=0.650000), auc=0.872484::: time:2530.52s\n","- epoch:56 -\n","Epoch: [56][0/65] Elapsed 0m 1s (remain 1m 27s) Loss: 0.0577(0.0577) \n","Epoch: [56][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0545(0.0501) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0187(0.0187) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0642(0.0544) \n","\t epoch:56, avg train loss:0.0501, avg valid loss:0.0544\n","\t score:0.5240(th=0.700000), auc=0.871717::: time:2574.52s\n","- epoch:57 -\n","Epoch: [57][0/65] Elapsed 0m 1s (remain 1m 27s) Loss: 0.0294(0.0294) \n","Epoch: [57][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0650(0.0472) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0146(0.0146) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0689(0.0534) \n","\t epoch:57, avg train loss:0.0472, avg valid loss:0.0534\n","\t score:0.5156(th=0.600000), auc=0.871982::: time:2618.66s\n","- epoch:58 -\n","Epoch: [58][0/65] Elapsed 0m 1s (remain 1m 30s) Loss: 0.0373(0.0373) \n","Epoch: [58][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.1315(0.0527) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0081(0.0081) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0632(0.0546) \n","\t epoch:58, avg train loss:0.0527, avg valid loss:0.0546\n","\t score:0.5088(th=0.600000), auc=0.868912::: time:2662.74s\n","- epoch:59 -\n","Epoch: [59][0/65] Elapsed 0m 1s (remain 1m 21s) Loss: 0.0301(0.0301) \n","Epoch: [59][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0743(0.0511) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0391(0.0391) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0621(0.0593) \n","\t epoch:59, avg train loss:0.0511, avg valid loss:0.0593\n","\t score:0.4788(th=0.700000), auc=0.857552::: time:2706.74s\n","- epoch:60 -\n","Epoch: [60][0/65] Elapsed 0m 1s (remain 1m 19s) Loss: 0.0677(0.0677) \n","Epoch: [60][64/65] Elapsed 0m 28s (remain 0m 0s) Loss: 0.0862(0.0529) \n","EVAL: [0/14] Elapsed 0m 0s (remain 0m 4s) Loss: 0.0273(0.0273) \n","EVAL: [13/14] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0625(0.0579) \n","\t epoch:60, avg train loss:0.0529, avg valid loss:0.0579\n","\t score:0.4773(th=0.700000), auc=0.878301::: time:2750.31s\n","[fold0] slice ave score:0.5063(th=0.650000), auc=0.885303\n","[fold0] BEST Epoch 16 - Save Best Score:0.5335. Best loss:0.0520\n","[fold0] BEST AUC Epoch 6 - Save Best Score:0.8876. Best loss:0.0528\n","-- fold1 training start --\n","surface_list:  [26, 29, 32, 35]\n","- epoch:1 -\n","Epoch: [1][0/60] Elapsed 0m 1s (remain 1m 13s) Loss: 0.3496(0.3496) \n","Epoch: [1][59/60] Elapsed 0m 27s (remain 0m 0s) Loss: nan(nan) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 5s) Loss: nan(nan) \n","EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) Loss: nan(nan) \n"]},{"ename":"ValueError","evalue":"Input contains NaN, infinity or a value too large for dtype('float32').","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_11924/3139865769.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(CFG)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;31m# target, predをconcatして元のサイズに戻す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mvalid_preds_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_targets_img\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mconcat_grid_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_grid_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mvalid_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_targets_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_preds_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mvalid_preds_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_preds_img\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mvalid_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_11924/963134502.py\u001b[0m in \u001b[0;36mcalc_cv\u001b[0;34m(mask_gt, mask_pred)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mbest_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_fbeta_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_11924/963134502.py\u001b[0m in \u001b[0;36mcalc_fbeta_auc\u001b[0;34m(mask, mask_pred)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mbest_th\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     if y_type == \"multiclass\" or (\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."]}],"source":["%%time\n","best_score_list, best_threshold_list, best_epoch_list = training_loop(CFG)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["> \u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m(116)\u001b[0;36m_assert_all_finite\u001b[0;34m()\u001b[0m\n","\u001b[0;32m    114 \u001b[0;31m            raise ValueError(\n","\u001b[0m\u001b[0;32m    115 \u001b[0;31m                msg_err.format(\n","\u001b[0m\u001b[0;32m--> 116 \u001b[0;31m                    \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    117 \u001b[0;31m                )\n","\u001b[0m\u001b[0;32m    118 \u001b[0;31m            )\n","\u001b[0m\n","> \u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m(800)\u001b[0;36mcheck_array\u001b[0;34m()\u001b[0m\n","\u001b[0;32m    798 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    799 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m--> 800 \u001b[0;31m            \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    801 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    802 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n","> \u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m(546)\u001b[0;36mroc_auc_score\u001b[0;34m()\u001b[0m\n","\u001b[0;32m    544 \u001b[0;31m    \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    545 \u001b[0;31m    \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m--> 546 \u001b[0;31m    \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    547 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    548 \u001b[0;31m    if y_type == \"multiclass\" or (\n","\u001b[0m\n","> \u001b[0;32m/tmp/ipykernel_11924/963134502.py\u001b[0m(30)\u001b[0;36mcalc_fbeta_auc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m     28 \u001b[0;31m            \u001b[0mbest_th\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m     29 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m---> 30 \u001b[0;31m    \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m     31 \u001b[0;31m    \u001b[0;31m# Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m     32 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mbest_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n","> \u001b[0;32m/tmp/ipykernel_11924/963134502.py\u001b[0m(36)\u001b[0;36mcalc_cv\u001b[0;34m()\u001b[0m\n","\u001b[0;32m     34 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m     35 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mcalc_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m---> 36 \u001b[0;31m    \u001b[0mbest_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_fbeta_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m     37 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m     38 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mbest_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n","> \u001b[0;32m/tmp/ipykernel_11924/3139865769.py\u001b[0m(50)\u001b[0;36mtraining_loop\u001b[0;34m()\u001b[0m\n","\u001b[0;32m     48 \u001b[0;31m                \u001b[0;31m# target, predをconcatして元のサイズに戻す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m     49 \u001b[0;31m                \u001b[0mvalid_preds_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_targets_img\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mconcat_grid_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_grid_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m---> 50 \u001b[0;31m                \u001b[0mvalid_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_targets_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_preds_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m     51 \u001b[0;31m                \u001b[0mvalid_preds_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_preds_img\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mvalid_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m     52 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n","array([[[nan],\n","        [nan],\n","        [nan],\n","        ...,\n","        [ 0.],\n","        [ 0.],\n","        [ 0.]],\n","\n","       [[nan],\n","        [nan],\n","        [nan],\n","        ...,\n","        [ 0.],\n","        [ 0.],\n","        [ 0.]],\n","\n","       [[nan],\n","        [nan],\n","        [nan],\n","        ...,\n","        [ 0.],\n","        [ 0.],\n","        [ 0.]],\n","\n","       ...,\n","\n","       [[ 0.],\n","        [ 0.],\n","        [ 0.],\n","        ...,\n","        [ 0.],\n","        [ 0.],\n","        [ 0.]],\n","\n","       [[ 0.],\n","        [ 0.],\n","        [ 0.],\n","        ...,\n","        [ 0.],\n","        [ 0.],\n","        [ 0.]],\n","\n","       [[ 0.],\n","        [ 0.],\n","        [ 0.],\n","        ...,\n","        [ 0.],\n","        [ 0.],\n","        [ 0.]]], dtype=float32)\n","*** NameError: name 'valid_target_img' is not defined\n","array([[[0.],\n","        [0.],\n","        [0.],\n","        ...,\n","        [0.],\n","        [0.],\n","        [0.]],\n","\n","       [[0.],\n","        [0.],\n","        [0.],\n","        ...,\n","        [0.],\n","        [0.],\n","        [0.]],\n","\n","       [[0.],\n","        [0.],\n","        [0.],\n","        ...,\n","        [0.],\n","        [0.],\n","        [0.]],\n","\n","       ...,\n","\n","       [[0.],\n","        [0.],\n","        [0.],\n","        ...,\n","        [0.],\n","        [0.],\n","        [0.]],\n","\n","       [[0.],\n","        [0.],\n","        [0.],\n","        ...,\n","        [0.],\n","        [0.],\n","        [0.]],\n","\n","       [[0.],\n","        [0.],\n","        [0.],\n","        ...,\n","        [0.],\n","        [0.],\n","        [0.]]], dtype=float32)\n","nan\n","nan\n"]}],"source":["%debug"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","# OOF SCORE INFER"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","slice_ave_score_list, slice_ave_auc_list, slice_ave_score_threshold_list = slide_inference(CFG)\n","for fold in CFG[\"folds\"]:\n","    print(f\"fold[{fold}] slice ave score:{slice_ave_score_list[fold]:.4f}(th={slice_ave_score_threshold_list[fold]:3f}), auc={slice_ave_auc_list[fold]:4f}\")\n","    wandb.log({\"OOF SCORE\" : {f\"slice average score\":slice_ave_score_list[fold],\n","                            f\"slice average threshold\":slice_ave_score_threshold_list[fold],\n","                            f\"slice_average auc\":slice_ave_auc_list[fold],\n","                            }})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-04-11T00:48:24.180209Z","iopub.status.idle":"2023-04-11T00:48:24.181024Z","shell.execute_reply":"2023-04-11T00:48:24.180784Z","shell.execute_reply.started":"2023-04-11T00:48:24.18074Z"},"trusted":true},"outputs":[],"source":["import yaml\n","with open(os.path.join(CFG[\"OUTPUT_DIR\"], \"Config.yaml\"), \"w\") as f:\n","    yaml.dump(CFG, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not CFG[\"DEBUG\"]:\n","    wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
